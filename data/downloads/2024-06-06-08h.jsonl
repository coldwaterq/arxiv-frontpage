{"created":"2024-06-05 17:59:40","title":"Wings: Learning Multimodal LLMs without Text-only Forgetting","abstract":"Multimodal large language models (MLLMs), initiated with a trained LLM, first align images with text and then fine-tune on multimodal mixed inputs. However, the MLLM catastrophically forgets the text-only instructions, which do not include images and can be addressed within the initial LLM. In this paper, we present Wings, a novel MLLM that excels in both text-only dialogues and multimodal comprehension. Analyzing MLLM attention in multimodal instructions reveals that text-only forgetting is related to the attention shifts from pre-image to post-image text. From that, we construct extra modules that act as the boosted learner to compensate for the attention shift. The complementary visual and textual learners, like \"wings\" on either side, are connected in parallel within each layer's attention block. Initially, image and text inputs are aligned with visual learners operating alongside the main attention, balancing focus on visual elements. Textual learners are later collaboratively integrated with attention-based routing to blend the outputs of the visual and textual learners. We design the Low-Rank Residual Attention (LoRRA) to guarantee high efficiency for learners. Our experimental results demonstrate that Wings outperforms equally-scaled MLLMs in both text-only and visual question-answering tasks. On a newly constructed Interleaved Image-Text (IIT) benchmark, Wings exhibits superior performance from text-only-rich to multimodal-rich question-answering tasks.","sentences":["Multimodal large language models (MLLMs), initiated with a trained LLM, first align images with text and then fine-tune on multimodal mixed inputs.","However, the MLLM catastrophically forgets the text-only instructions, which do not include images and can be addressed within the initial LLM.","In this paper, we present Wings, a novel MLLM that excels in both text-only dialogues and multimodal comprehension.","Analyzing MLLM attention in multimodal instructions reveals that text-only forgetting is related to the attention shifts from pre-image to post-image text.","From that, we construct extra modules that act as the boosted learner to compensate for the attention shift.","The complementary visual and textual learners, like \"wings\" on either side, are connected in parallel within each layer's attention block.","Initially, image and text inputs are aligned with visual learners operating alongside the main attention, balancing focus on visual elements.","Textual learners are later collaboratively integrated with attention-based routing to blend the outputs of the visual and textual learners.","We design the Low-Rank Residual Attention (LoRRA) to guarantee high efficiency for learners.","Our experimental results demonstrate that Wings outperforms equally-scaled MLLMs in both text-only and visual question-answering tasks.","On a newly constructed Interleaved Image-Text (IIT) benchmark, Wings exhibits superior performance from text-only-rich to multimodal-rich question-answering tasks."],"url":"http://arxiv.org/abs/2406.03496v1"}
{"created":"2024-06-05 17:59:35","title":"Grokking Modular Polynomials","abstract":"Neural networks readily learn a subset of the modular arithmetic tasks, while failing to generalize on the rest. This limitation remains unmoved by the choice of architecture and training strategies. On the other hand, an analytical solution for the weights of Multi-layer Perceptron (MLP) networks that generalize on the modular addition task is known in the literature. In this work, we (i) extend the class of analytical solutions to include modular multiplication as well as modular addition with many terms. Additionally, we show that real networks trained on these datasets learn similar solutions upon generalization (grokking). (ii) We combine these \"expert\" solutions to construct networks that generalize on arbitrary modular polynomials. (iii) We hypothesize a classification of modular polynomials into learnable and non-learnable via neural networks training; and provide experimental evidence supporting our claims.","sentences":["Neural networks readily learn a subset of the modular arithmetic tasks, while failing to generalize on the rest.","This limitation remains unmoved by the choice of architecture and training strategies.","On the other hand, an analytical solution for the weights of Multi-layer Perceptron (MLP) networks that generalize on the modular addition task is known in the literature.","In this work, we (i) extend the class of analytical solutions to include modular multiplication as well as modular addition with many terms.","Additionally, we show that real networks trained on these datasets learn similar solutions upon generalization (grokking).","(ii) We combine these \"expert\" solutions to construct networks that generalize on arbitrary modular polynomials.","(iii) We hypothesize a classification of modular polynomials into learnable and non-learnable via neural networks training; and provide experimental evidence supporting our claims."],"url":"http://arxiv.org/abs/2406.03495v1"}
{"created":"2024-06-05 17:59:22","title":"Solving Poisson Equations using Neural Walk-on-Spheres","abstract":"We propose Neural Walk-on-Spheres (NWoS), a novel neural PDE solver for the efficient solution of high-dimensional Poisson equations. Leveraging stochastic representations and Walk-on-Spheres methods, we develop novel losses for neural networks based on the recursive solution of Poisson equations on spheres inside the domain. The resulting method is highly parallelizable and does not require spatial gradients for the loss. We provide a comprehensive comparison against competing methods based on PINNs, the Deep Ritz method, and (backward) stochastic differential equations. In several challenging, high-dimensional numerical examples, we demonstrate the superiority of NWoS in accuracy, speed, and computational costs. Compared to commonly used PINNs, our approach can reduce memory usage and errors by orders of magnitude. Furthermore, we apply NWoS to problems in PDE-constrained optimization and molecular dynamics to show its efficiency in practical applications.","sentences":["We propose Neural Walk-on-Spheres (NWoS), a novel neural PDE solver for the efficient solution of high-dimensional Poisson equations.","Leveraging stochastic representations and Walk-on-Spheres methods, we develop novel losses for neural networks based on the recursive solution of Poisson equations on spheres inside the domain.","The resulting method is highly parallelizable and does not require spatial gradients for the loss.","We provide a comprehensive comparison against competing methods based on PINNs, the Deep Ritz method, and (backward) stochastic differential equations.","In several challenging, high-dimensional numerical examples, we demonstrate the superiority of NWoS in accuracy, speed, and computational costs.","Compared to commonly used PINNs, our approach can reduce memory usage and errors by orders of magnitude.","Furthermore, we apply NWoS to problems in PDE-constrained optimization and molecular dynamics to show its efficiency in practical applications."],"url":"http://arxiv.org/abs/2406.03494v1"}
{"created":"2024-06-05 17:57:58","title":"The Logarithmic Memristor-Based Bayesian Machine","abstract":"The demand for explainable and energy-efficient artificial intelligence (AI) systems for edge computing has led to significant interest in electronic systems dedicated to Bayesian inference. Traditional designs of such systems often rely on stochastic computing, which offers high energy efficiency but suffers from latency issues and struggles with low-probability values. In this paper, we introduce the logarithmic memristor-based Bayesian machine, an innovative design that leverages the unique properties of memristors and logarithmic computing as an alternative to stochastic computing. We present a prototype machine fabricated in a hybrid CMOS/hafnium-oxide memristor process. We validate the versatility and robustness of our system through experimental validation and extensive simulations in two distinct applications: gesture recognition and sleep stage classification. The logarithmic approach simplifies the computational model by converting multiplications into additions and enhances the handling of low-probability events, which are crucial in time-dependent tasks. Our results demonstrate that the logarithmic Bayesian machine achieves superior performance in terms of accuracy and energy efficiency compared to its stochastic counterpart, particularly in scenarios involving complex probabilistic models. This work paves the way for the deployment of advanced AI capabilities in edge devices, where power efficiency and reliability are paramount.","sentences":["The demand for explainable and energy-efficient artificial intelligence (AI) systems for edge computing has led to significant interest in electronic systems dedicated to Bayesian inference.","Traditional designs of such systems often rely on stochastic computing, which offers high energy efficiency but suffers from latency issues and struggles with low-probability values.","In this paper, we introduce the logarithmic memristor-based Bayesian machine, an innovative design that leverages the unique properties of memristors and logarithmic computing as an alternative to stochastic computing.","We present a prototype machine fabricated in a hybrid CMOS/hafnium-oxide memristor process.","We validate the versatility and robustness of our system through experimental validation and extensive simulations in two distinct applications: gesture recognition and sleep stage classification.","The logarithmic approach simplifies the computational model by converting multiplications into additions and enhances the handling of low-probability events, which are crucial in time-dependent tasks.","Our results demonstrate that the logarithmic Bayesian machine achieves superior performance in terms of accuracy and energy efficiency compared to its stochastic counterpart, particularly in scenarios involving complex probabilistic models.","This work paves the way for the deployment of advanced AI capabilities in edge devices, where power efficiency and reliability are paramount."],"url":"http://arxiv.org/abs/2406.03492v1"}
{"created":"2024-06-05 17:50:03","title":"Seq1F1B: Efficient Sequence-Level Pipeline Parallelism for Large Language Model Training","abstract":"The emergence of large language models (LLMs) relies heavily on distributed training strategies, among which pipeline parallelism plays a crucial role. As LLMs' training sequence length extends to 32k or even 128k, the current pipeline parallel methods face severe bottlenecks, including high memory footprints and substantial pipeline bubbles, greatly hindering model scalability and training throughput. To enhance memory efficiency and training throughput, in this work, we introduce an efficient sequence-level one-forward-one-backward (1F1B) pipeline scheduling method tailored for training LLMs on long sequences named Seq1F1B. Seq1F1B decomposes batch-level schedulable units into finer sequence-level units, reducing bubble size and memory footprint. Considering that Seq1F1B may produce slight extra bubbles if sequences are split evenly, we design a computation-wise strategy to partition input sequences and mitigate this side effect. Compared to competitive pipeline baseline methods such as Megatron 1F1B pipeline parallelism, our method achieves higher training throughput with less memory footprint. Notably, Seq1F1B efficiently trains a LLM with 30B parameters on sequences up to 64k using 64 NVIDIA A100 GPUs without recomputation strategies, a feat unachievable with existing methods. Our source code is based on Megatron-LM, and now is avaiable at: https://github.com/MayDomine/Seq1F1B.git.","sentences":["The emergence of large language models (LLMs) relies heavily on distributed training strategies, among which pipeline parallelism plays a crucial role.","As LLMs' training sequence length extends to 32k or even 128k, the current pipeline parallel methods face severe bottlenecks, including high memory footprints and substantial pipeline bubbles, greatly hindering model scalability and training throughput.","To enhance memory efficiency and training throughput, in this work, we introduce an efficient sequence-level one-forward-one-backward (1F1B) pipeline scheduling method tailored for training LLMs on long sequences named Seq1F1B. Seq1F1B","decomposes batch-level schedulable units into finer sequence-level units, reducing bubble size and memory footprint.","Considering that Seq1F1B may produce slight extra bubbles if sequences are split evenly, we design a computation-wise strategy to partition input sequences and mitigate this side effect.","Compared to competitive pipeline baseline methods such as Megatron 1F1B pipeline parallelism, our method achieves higher training throughput with less memory footprint.","Notably, Seq1F1B efficiently trains a LLM with 30B parameters on sequences up to 64k using 64 NVIDIA A100 GPUs without recomputation strategies, a feat unachievable with existing methods.","Our source code is based on Megatron-LM, and now is avaiable at: https://github.com/MayDomine/Seq1F1B.git."],"url":"http://arxiv.org/abs/2406.03488v1"}
{"created":"2024-06-05 17:49:47","title":"Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends","abstract":"Recent advancements in large language models (LLMs) have considerably advanced the capabilities of summarization systems. However, they continue to face concerns about hallucinations. While prior work has evaluated LLMs extensively in news domains, most evaluation of dialogue summarization has focused on BART-based models, leaving a gap in our understanding of their faithfulness. Our work benchmarks the faithfulness of LLMs for dialogue summarization, using human annotations and focusing on identifying and categorizing span-level inconsistencies. Specifically, we focus on two prominent LLMs: GPT-4 and Alpaca-13B. Our evaluation reveals subtleties as to what constitutes a hallucination: LLMs often generate plausible inferences, supported by circumstantial evidence in the conversation, that lack direct evidence, a pattern that is less prevalent in older models. We propose a refined taxonomy of errors, coining the category of \"Circumstantial Inference\" to bucket these LLM behaviors and release the dataset. Using our taxonomy, we compare the behavioral differences between LLMs and older fine-tuned models. Additionally, we systematically assess the efficacy of automatic error detection methods on LLM summaries and find that they struggle to detect these nuanced errors. To address this, we introduce two prompt-based approaches for fine-grained error detection that outperform existing metrics, particularly for identifying \"Circumstantial Inference.\"","sentences":["Recent advancements in large language models (LLMs) have considerably advanced the capabilities of summarization systems.","However, they continue to face concerns about hallucinations.","While prior work has evaluated LLMs extensively in news domains, most evaluation of dialogue summarization has focused on BART-based models, leaving a gap in our understanding of their faithfulness.","Our work benchmarks the faithfulness of LLMs for dialogue summarization, using human annotations and focusing on identifying and categorizing span-level inconsistencies.","Specifically, we focus on two prominent LLMs: GPT-4 and Alpaca-13B. Our evaluation reveals subtleties as to what constitutes a hallucination: LLMs often generate plausible inferences, supported by circumstantial evidence in the conversation, that lack direct evidence, a pattern that is less prevalent in older models.","We propose a refined taxonomy of errors, coining the category of \"Circumstantial Inference\" to bucket these LLM behaviors and release the dataset.","Using our taxonomy, we compare the behavioral differences between LLMs and older fine-tuned models.","Additionally, we systematically assess the efficacy of automatic error detection methods on LLM summaries and find that they struggle to detect these nuanced errors.","To address this, we introduce two prompt-based approaches for fine-grained error detection that outperform existing metrics, particularly for identifying \"Circumstantial Inference.\""],"url":"http://arxiv.org/abs/2406.03487v1"}
{"created":"2024-06-05 17:49:24","title":"BIPED: Pedagogically Informed Tutoring System for ESL Education","abstract":"Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient Conversational Intelligent Tutoring Systems (CITS) for teaching L2 learners of English. Existing CITS, however, are designed to teach only simple concepts or lack the pedagogical depth necessary to address diverse learning strategies. To develop a more pedagogically informed CITS capable of teaching complex concepts, we construct a BIlingual PEDagogically-informed Tutoring Dataset (BIPED) of one-on-one, human-to-human English tutoring interactions. Through post-hoc analysis of the tutoring interactions, we come up with a lexicon of dialogue acts (34 tutor acts and 9 student acts), which we use to further annotate the collected dataset. Based on a two-step framework of first predicting the appropriate tutor act then generating the corresponding response, we implemented two CITS models using GPT-4 and SOLAR-KO, respectively. We experimentally demonstrate that the implemented models not only replicate the style of human teachers but also employ diverse and contextually appropriate pedagogical strategies.","sentences":["Large Language Models (LLMs) have a great potential to serve as readily available and cost-efficient Conversational Intelligent Tutoring Systems (CITS) for teaching L2 learners of English.","Existing CITS, however, are designed to teach only simple concepts or lack the pedagogical depth necessary to address diverse learning strategies.","To develop a more pedagogically informed CITS capable of teaching complex concepts, we construct a BIlingual PEDagogically-informed Tutoring Dataset (BIPED) of one-on-one, human-to-human English tutoring interactions.","Through post-hoc analysis of the tutoring interactions, we come up with a lexicon of dialogue acts (34 tutor acts and 9 student acts), which we use to further annotate the collected dataset.","Based on a two-step framework of first predicting the appropriate tutor act then generating the corresponding response, we implemented two CITS models using GPT-4 and SOLAR-KO, respectively.","We experimentally demonstrate that the implemented models not only replicate the style of human teachers but also employ diverse and contextually appropriate pedagogical strategies."],"url":"http://arxiv.org/abs/2406.03486v1"}
{"created":"2024-06-05 17:46:26","title":"Highway Value Iteration Networks","abstract":"Value iteration networks (VINs) enable end-to-end learning for planning tasks by employing a differentiable \"planning module\" that approximates the value iteration algorithm. However, long-term planning remains a challenge because training very deep VINs is difficult. To address this problem, we embed highway value iteration -- a recent algorithm designed to facilitate long-term credit assignment -- into the structure of VINs. This improvement augments the \"planning module\" of the VIN with three additional components: 1) an \"aggregate gate,\" which constructs skip connections to improve information flow across many layers; 2) an \"exploration module,\" crafted to increase the diversity of information and gradient flow in spatial dimensions; 3) a \"filter gate\" designed to ensure safe exploration. The resulting novel highway VIN can be trained effectively with hundreds of layers using standard backpropagation. In long-term planning tasks requiring hundreds of planning steps, deep highway VINs outperform both traditional VINs and several advanced, very deep NNs.","sentences":["Value iteration networks (VINs) enable end-to-end learning for planning tasks by employing a differentiable \"planning module\" that approximates the value iteration algorithm.","However, long-term planning remains a challenge because training very deep VINs is difficult.","To address this problem, we embed highway value iteration -- a recent algorithm designed to facilitate long-term credit assignment -- into the structure of VINs.","This improvement augments the \"planning module\" of the VIN with three additional components: 1) an \"aggregate gate,\" which constructs skip connections to improve information flow across many layers; 2) an \"exploration module,\" crafted to increase the diversity of information and gradient flow in spatial dimensions; 3) a \"filter gate\" designed to ensure safe exploration.","The resulting novel highway VIN can be trained effectively with hundreds of layers using standard backpropagation.","In long-term planning tasks requiring hundreds of planning steps, deep highway VINs outperform both traditional VINs and several advanced, very deep NNs."],"url":"http://arxiv.org/abs/2406.03485v1"}
{"created":"2024-06-05 17:42:05","title":"QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead","abstract":"Serving LLMs requires substantial memory due to the storage requirements of Key-Value (KV) embeddings in the KV cache, which grows with sequence length. An effective approach to compress KV cache is quantization. However, traditional quantization methods face significant memory overhead due to the need to store quantization constants (at least a zero point and a scale) in full precision per data block. Depending on the block size, this overhead can add 1 or 2 bits per quantized number. We introduce QJL, a new quantization approach that consists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit quantization. In contrast to existing methods, QJL eliminates memory overheads by removing the need for storing quantization constants. We propose an asymmetric estimator for the inner product of two vectors and demonstrate that applying QJL to one vector and a standard JL transform without quantization to the other provides an unbiased estimator with minimal distortion. We have developed an efficient implementation of the QJL sketch and its corresponding inner product estimator, incorporating a lightweight CUDA kernel for optimized computation. When applied across various LLMs and NLP tasks to quantize the KV cache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV cache memory usage without compromising accuracy, all while achieving faster runtime. Codes are available at \\url{https://github.com/amirzandieh/QJL}.","sentences":["Serving LLMs requires substantial memory due to the storage requirements of Key-Value (KV) embeddings in the KV cache, which grows with sequence length.","An effective approach to compress KV cache is quantization.","However, traditional quantization methods face significant memory overhead due to the need to store quantization constants (at least a zero point and a scale) in full precision per data block.","Depending on the block size, this overhead can add 1 or 2 bits per quantized number.","We introduce QJL, a new quantization approach that consists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit quantization.","In contrast to existing methods, QJL eliminates memory overheads by removing the need for storing quantization constants.","We propose an asymmetric estimator for the inner product of two vectors and demonstrate that applying QJL to one vector and a standard JL transform without quantization to the other provides an unbiased estimator with minimal distortion.","We have developed an efficient implementation of the QJL sketch and its corresponding inner product estimator, incorporating a lightweight CUDA kernel for optimized computation.","When applied across various LLMs and NLP tasks to quantize the KV cache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV cache memory usage without compromising accuracy, all while achieving faster runtime.","Codes are available at \\url{https://github.com/amirzandieh/QJL}."],"url":"http://arxiv.org/abs/2406.03482v1"}
{"created":"2024-06-05 17:37:21","title":"Unpacking Approaches to Learning and Teaching Machine Learning in K-12 Education: Transparency, Ethics, and Design Activities","abstract":"In this conceptual paper, we review existing literature on artificial intelligence/machine learning (AI/ML) education to identify three approaches to how learning and teaching ML could be conceptualized. One of them, a data-driven approach, emphasizes providing young people with opportunities to create data sets, train, and test models. A second approach, learning algorithm-driven, prioritizes learning about how the learning algorithms or engines behind how ML models work. In addition, we identify efforts within a third approach that integrates the previous two. In our review, we focus on how the approaches: (1) glassbox and blackbox different aspects of ML, (2) build on learner interests and provide opportunities for designing applications, (3) integrate ethics and justice. In the discussion, we address the challenges and opportunities of current approaches and suggest future directions for the design of learning activities.","sentences":["In this conceptual paper, we review existing literature on artificial intelligence/machine learning (AI/ML) education to identify three approaches to how learning and teaching ML could be conceptualized.","One of them, a data-driven approach, emphasizes providing young people with opportunities to create data sets, train, and test models.","A second approach, learning algorithm-driven, prioritizes learning about how the learning algorithms or engines behind how ML models work.","In addition, we identify efforts within a third approach that integrates the previous two.","In our review, we focus on how the approaches: (1) glassbox and blackbox different aspects of ML, (2) build on learner interests and provide opportunities for designing applications, (3) integrate ethics and justice.","In the discussion, we address the challenges and opportunities of current approaches and suggest future directions for the design of learning activities."],"url":"http://arxiv.org/abs/2406.03480v1"}
{"created":"2024-06-05 17:32:28","title":"MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization","abstract":"The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out. Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text. We introduce a novel multi-objective learning framework employing a Longformer-Encoder-Decoder for this task. The framework optimizes aspect number prediction, minimizes disparity between generated and reference summaries for each aspect, and maximizes dissimilarity across aspect-specific summaries. Extensive experiments show our method significantly outperforms baselines on three diverse datasets, largely due to the effective alignment of generated and reference aspect counts without sacrificing single-aspect summarization quality.","sentences":["The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out.","Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text.","We introduce a novel multi-objective learning framework employing a Longformer-Encoder-Decoder for this task.","The framework optimizes aspect number prediction, minimizes disparity between generated and reference summaries for each aspect, and maximizes dissimilarity across aspect-specific summaries.","Extensive experiments show our method significantly outperforms baselines on three diverse datasets, largely due to the effective alignment of generated and reference aspect counts without sacrificing single-aspect summarization quality."],"url":"http://arxiv.org/abs/2406.03479v1"}
{"created":"2024-06-05 17:32:22","title":"Convolutional Neural Networks and Vision Transformers for Fashion MNIST Classification: A Literature Review","abstract":"Our review explores the comparative analysis between Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) in the domain of image classification, with a particular focus on clothing classification within the e-commerce sector. Utilizing the Fashion MNIST dataset, we delve into the unique attributes of CNNs and ViTs. While CNNs have long been the cornerstone of image classification, ViTs introduce an innovative self-attention mechanism enabling nuanced weighting of different input data components. Historically, transformers have primarily been associated with Natural Language Processing (NLP) tasks. Through a comprehensive examination of existing literature, our aim is to unveil the distinctions between ViTs and CNNs in the context of image classification. Our analysis meticulously scrutinizes state-of-the-art methodologies employing both architectures, striving to identify the factors influencing their performance. These factors encompass dataset characteristics, image dimensions, the number of target classes, hardware infrastructure, and the specific architectures along with their respective top results. Our key goal is to determine the most appropriate architecture between ViT and CNN for classifying images in the Fashion MNIST dataset within the e-commerce industry, while taking into account specific conditions and needs. We highlight the importance of combining these two architectures with different forms to enhance overall performance. By uniting these architectures, we can take advantage of their unique strengths, which may lead to more precise and reliable models for e-commerce applications. CNNs are skilled at recognizing local patterns, while ViTs are effective at grasping overall context, making their combination a promising strategy for boosting image classification performance.","sentences":["Our review explores the comparative analysis between Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) in the domain of image classification, with a particular focus on clothing classification within the e-commerce sector.","Utilizing the Fashion MNIST dataset, we delve into the unique attributes of CNNs and ViTs.","While CNNs have long been the cornerstone of image classification, ViTs introduce an innovative self-attention mechanism enabling nuanced weighting of different input data components.","Historically, transformers have primarily been associated with Natural Language Processing (NLP) tasks.","Through a comprehensive examination of existing literature, our aim is to unveil the distinctions between ViTs and CNNs in the context of image classification.","Our analysis meticulously scrutinizes state-of-the-art methodologies employing both architectures, striving to identify the factors influencing their performance.","These factors encompass dataset characteristics, image dimensions, the number of target classes, hardware infrastructure, and the specific architectures along with their respective top results.","Our key goal is to determine the most appropriate architecture between ViT and CNN for classifying images in the Fashion MNIST dataset within the e-commerce industry, while taking into account specific conditions and needs.","We highlight the importance of combining these two architectures with different forms to enhance overall performance.","By uniting these architectures, we can take advantage of their unique strengths, which may lead to more precise and reliable models for e-commerce applications.","CNNs are skilled at recognizing local patterns, while ViTs are effective at grasping overall context, making their combination a promising strategy for boosting image classification performance."],"url":"http://arxiv.org/abs/2406.03478v1"}
{"created":"2024-06-05 17:29:15","title":"Does your data spark joy? Performance gains from domain upsampling at the end of training","abstract":"Pretraining datasets for large language models (LLMs) have grown to trillions of tokens composed of large amounts of CommonCrawl (CC) web scrape along with smaller, domain-specific datasets. It is expensive to understand the impact of these domain-specific datasets on model capabilities as training at large FLOP scales is required to reveal significant changes to difficult and emergent benchmarks. Given the increasing cost of experimenting with pretraining data, how does one determine the optimal balance between the diversity in general web scrapes and the information density of domain specific data? In this work, we show how to leverage the smaller domain specific datasets by upsampling them relative to CC at the end of training to drive performance improvements on difficult benchmarks. This simple technique allows us to improve up to 6.90 pp on MMLU, 8.26 pp on GSM8K, and 6.17 pp on HumanEval relative to the base data mix for a 7B model trained for 1 trillion (T) tokens, thus rivaling Llama-2 (7B)$\\unicode{x2014}$a model trained for twice as long. We experiment with ablating the duration of domain upsampling from 5% to 30% of training and find that 10% to 20% percent is optimal for navigating the tradeoff between general language modeling capabilities and targeted benchmarks. We also use domain upsampling to characterize at scale the utility of individual datasets for improving various benchmarks by removing them during this final phase of training. This tool opens up the ability to experiment with the impact of different pretraining datasets at scale, but at an order of magnitude lower cost compared to full pretraining runs.","sentences":["Pretraining datasets for large language models (LLMs) have grown to trillions of tokens composed of large amounts of CommonCrawl (CC) web scrape along with smaller, domain-specific datasets.","It is expensive to understand the impact of these domain-specific datasets on model capabilities as training at large FLOP scales is required to reveal significant changes to difficult and emergent benchmarks.","Given the increasing cost of experimenting with pretraining data, how does one determine the optimal balance between the diversity in general web scrapes and the information density of domain specific data?","In this work, we show how to leverage the smaller domain specific datasets by upsampling them relative to CC at the end of training to drive performance improvements on difficult benchmarks.","This simple technique allows us to improve up to 6.90 pp on MMLU, 8.26 pp on GSM8K, and 6.17 pp on HumanEval relative to the base data mix for a 7B model trained for 1 trillion (T) tokens, thus rivaling Llama-2 (7B)$\\unicode{x2014}$a model trained for twice as long.","We experiment with ablating the duration of domain upsampling from 5% to 30% of training and find that 10% to 20% percent is optimal for navigating the tradeoff between general language modeling capabilities and targeted benchmarks.","We also use domain upsampling to characterize at scale the utility of individual datasets for improving various benchmarks by removing them during this final phase of training.","This tool opens up the ability to experiment with the impact of different pretraining datasets at scale, but at an order of magnitude lower cost compared to full pretraining runs."],"url":"http://arxiv.org/abs/2406.03476v1"}
{"created":"2024-06-05 17:25:46","title":"AD-H: Autonomous Driving with Hierarchical Agents","abstract":"Due to the impressive capabilities of multimodal large language models (MLLMs), recent works have focused on employing MLLM-based agents for autonomous driving in large-scale and dynamic environments. However, prevalent approaches often directly translate high-level instructions into low-level vehicle control signals, which deviates from the inherent language generation paradigm of MLLMs and fails to fully harness their emergent powers. As a result, the generalizability of these methods is highly restricted by autonomous driving datasets used during fine-tuning. To tackle this challenge, we propose to connect high-level instructions and low-level control signals with mid-level language-driven commands, which are more fine-grained than high-level instructions but more universal and explainable than control signals, and thus can effectively bridge the gap in between. We implement this idea through a hierarchical multi-agent driving system named AD-H, including a MLLM planner for high-level reasoning and a lightweight controller for low-level execution. The hierarchical design liberates the MLLM from low-level control signal decoding and therefore fully releases their emergent capability in high-level perception, reasoning, and planning. We build a new dataset with action hierarchy annotations. Comprehensive closed-loop evaluations demonstrate several key advantages of our proposed AD-H system. First, AD-H can notably outperform state-of-the-art methods in achieving exceptional driving performance, even exhibiting self-correction capabilities during vehicle operation, a scenario not encountered in the training dataset. Second, AD-H demonstrates superior generalization under long-horizon instructions and novel environmental conditions, significantly surpassing current state-of-the-art methods. We will make our data and code publicly accessible at https://github.com/zhangzaibin/AD-H","sentences":["Due to the impressive capabilities of multimodal large language models (MLLMs), recent works have focused on employing MLLM-based agents for autonomous driving in large-scale and dynamic environments.","However, prevalent approaches often directly translate high-level instructions into low-level vehicle control signals, which deviates from the inherent language generation paradigm of MLLMs and fails to fully harness their emergent powers.","As a result, the generalizability of these methods is highly restricted by autonomous driving datasets used during fine-tuning.","To tackle this challenge, we propose to connect high-level instructions and low-level control signals with mid-level language-driven commands, which are more fine-grained than high-level instructions but more universal and explainable than control signals, and thus can effectively bridge the gap in between.","We implement this idea through a hierarchical multi-agent driving system named AD-H, including a MLLM planner for high-level reasoning and a lightweight controller for low-level execution.","The hierarchical design liberates the MLLM from low-level control signal decoding and therefore fully releases their emergent capability in high-level perception, reasoning, and planning.","We build a new dataset with action hierarchy annotations.","Comprehensive closed-loop evaluations demonstrate several key advantages of our proposed AD-H system.","First, AD-H can notably outperform state-of-the-art methods in achieving exceptional driving performance, even exhibiting self-correction capabilities during vehicle operation, a scenario not encountered in the training dataset.","Second, AD-H demonstrates superior generalization under long-horizon instructions and novel environmental conditions, significantly surpassing current state-of-the-art methods.","We will make our data and code publicly accessible at https://github.com/zhangzaibin/AD-H"],"url":"http://arxiv.org/abs/2406.03474v1"}
{"created":"2024-06-05 17:25:29","title":"Solving Differential Equations using Physics-Informed Deep Equilibrium Models","abstract":"This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) for solving initial value problems (IVPs) of ordinary differential equations (ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) and physics-informed neural networks (PINNs), PIDEQs combine the implicit output representation of DEQs with physics-informed training techniques. We validate PIDEQs using the Van der Pol oscillator as a benchmark problem, demonstrating their efficiency and effectiveness in solving IVPs. Our analysis includes key hyperparameter considerations for optimizing PIDEQ performance. By bridging deep learning and physics-based modeling, this work advances computational techniques for solving IVPs, with implications for scientific computing and engineering applications.","sentences":["This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) for solving initial value problems (IVPs) of ordinary differential equations (ODEs).","Leveraging recent advancements in deep equilibrium models (DEQs) and physics-informed neural networks (PINNs), PIDEQs combine the implicit output representation of DEQs with physics-informed training techniques.","We validate PIDEQs using the Van der Pol oscillator as a benchmark problem, demonstrating their efficiency and effectiveness in solving IVPs.","Our analysis includes key hyperparameter considerations for optimizing PIDEQ performance.","By bridging deep learning and physics-based modeling, this work advances computational techniques for solving IVPs, with implications for scientific computing and engineering applications."],"url":"http://arxiv.org/abs/2406.03472v1"}
{"created":"2024-06-05 17:24:07","title":"SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN","abstract":"Spiking neural network (SNN) has attracted great attention due to its characteristic of high efficiency and accuracy. Currently, the ANN-to-SNN conversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8 time-steps) in CNN structure on computer vision (CV) tasks. However, as Transformer-based networks have achieved prevailing precision on both CV and natural language processing (NLP), the Transformer-based SNNs are still encounting the lower accuracy w.r.t the ANN counterparts. In this work, we introduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANN and SNN are exactly equivalent, thus incurring no accuracy degradation. SpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79% accuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-based SNNs. The code is available in GitHub: https://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer","sentences":["Spiking neural network (SNN) has attracted great attention due to its characteristic of high efficiency and accuracy.","Currently, the ANN-to-SNN conversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8 time-steps) in CNN structure on computer vision (CV) tasks.","However, as Transformer-based networks have achieved prevailing precision on both CV and natural language processing (NLP), the Transformer-based SNNs are still encounting the lower accuracy w.r.t the ANN counterparts.","In this work, we introduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANN and SNN are exactly equivalent, thus incurring no accuracy degradation.","SpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79% accuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-based SNNs.","The code is available in GitHub: https://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer"],"url":"http://arxiv.org/abs/2406.03470v1"}
{"created":"2024-06-05 17:12:38","title":"Node-wise Filtering in Graph Neural Networks: A Mixture of Experts Approach","abstract":"Graph Neural Networks (GNNs) have proven to be highly effective for node classification tasks across diverse graph structural patterns. Traditionally, GNNs employ a uniform global filter, typically a low-pass filter for homophilic graphs and a high-pass filter for heterophilic graphs. However, real-world graphs often exhibit a complex mix of homophilic and heterophilic patterns, rendering a single global filter approach suboptimal. In this work, we theoretically demonstrate that a global filter optimized for one pattern can adversely affect performance on nodes with differing patterns. To address this, we introduce a novel GNN framework Node-MoE that utilizes a mixture of experts to adaptively select the appropriate filters for different nodes. Extensive experiments demonstrate the effectiveness of Node-MoE on both homophilic and heterophilic graphs.","sentences":["Graph Neural Networks (GNNs) have proven to be highly effective for node classification tasks across diverse graph structural patterns.","Traditionally, GNNs employ a uniform global filter, typically a low-pass filter for homophilic graphs and a high-pass filter for heterophilic graphs.","However, real-world graphs often exhibit a complex mix of homophilic and heterophilic patterns, rendering a single global filter approach suboptimal.","In this work, we theoretically demonstrate that a global filter optimized for one pattern can adversely affect performance on nodes with differing patterns.","To address this, we introduce a novel GNN framework Node-MoE that utilizes a mixture of experts to adaptively select the appropriate filters for different nodes.","Extensive experiments demonstrate the effectiveness of Node-MoE on both homophilic and heterophilic graphs."],"url":"http://arxiv.org/abs/2406.03464v1"}
{"created":"2024-06-05 17:09:51","title":"Polarization Wavefront Lidar: Learning Large Scene Reconstruction from Polarized Wavefronts","abstract":"Lidar has become a cornerstone sensing modality for 3D vision, especially for large outdoor scenarios and autonomous driving. Conventional lidar sensors are capable of providing centimeter-accurate distance information by emitting laser pulses into a scene and measuring the time-of-flight (ToF) of the reflection. However, the polarization of the received light that depends on the surface orientation and material properties is usually not considered. As such, the polarization modality has the potential to improve scene reconstruction beyond distance measurements. In this work, we introduce a novel long-range polarization wavefront lidar sensor (PolLidar) that modulates the polarization of the emitted and received light. Departing from conventional lidar sensors, PolLidar allows access to the raw time-resolved polarimetric wavefronts. We leverage polarimetric wavefronts to estimate normals, distance, and material properties in outdoor scenarios with a novel learned reconstruction method. To train and evaluate the method, we introduce a simulated and real-world long-range dataset with paired raw lidar data, ground truth distance, and normal maps. We find that the proposed method improves normal and distance reconstruction by 53\\% mean angular error and 41\\% mean absolute error compared to existing shape-from-polarization (SfP) and ToF methods. Code and data are open-sourced at https://light.princeton.edu/pollidar.","sentences":["Lidar has become a cornerstone sensing modality for 3D vision, especially for large outdoor scenarios and autonomous driving.","Conventional lidar sensors are capable of providing centimeter-accurate distance information by emitting laser pulses into a scene and measuring the time-of-flight (ToF) of the reflection.","However, the polarization of the received light that depends on the surface orientation and material properties is usually not considered.","As such, the polarization modality has the potential to improve scene reconstruction beyond distance measurements.","In this work, we introduce a novel long-range polarization wavefront lidar sensor (PolLidar) that modulates the polarization of the emitted and received light.","Departing from conventional lidar sensors, PolLidar allows access to the raw time-resolved polarimetric wavefronts.","We leverage polarimetric wavefronts to estimate normals, distance, and material properties in outdoor scenarios with a novel learned reconstruction method.","To train and evaluate the method, we introduce a simulated and real-world long-range dataset with paired raw lidar data, ground truth distance, and normal maps.","We find that the proposed method improves normal and distance reconstruction by 53\\% mean angular error and 41\\% mean absolute error compared to existing shape-from-polarization (SfP) and","ToF methods.","Code and data are open-sourced at https://light.princeton.edu/pollidar."],"url":"http://arxiv.org/abs/2406.03461v1"}
{"created":"2024-06-05 17:07:24","title":"LW-DETR: A Transformer Replacement to YOLO for Real-Time Detection","abstract":"In this paper, we present a light-weight detection transformer, LW-DETR, which outperforms YOLOs for real-time object detection. The architecture is a simple stack of a ViT encoder, a projector, and a shallow DETR decoder. Our approach leverages recent advanced techniques, such as training-effective techniques, e.g., improved loss and pretraining, and interleaved window and global attentions for reducing the ViT encoder complexity. We improve the ViT encoder by aggregating multi-level feature maps, and the intermediate and final feature maps in the ViT encoder, forming richer feature maps, and introduce window-major feature map organization for improving the efficiency of interleaved attention computation. Experimental results demonstrate that the proposed approach is superior over existing real-time detectors, e.g., YOLO and its variants, on COCO and other benchmark datasets. Code and models are available at (https://github.com/Atten4Vis/LW-DETR).","sentences":["In this paper, we present a light-weight detection transformer, LW-DETR, which outperforms YOLOs for real-time object detection.","The architecture is a simple stack of a ViT encoder, a projector, and a shallow DETR decoder.","Our approach leverages recent advanced techniques, such as training-effective techniques, e.g., improved loss and pretraining, and interleaved window and global attentions for reducing the ViT encoder complexity.","We improve the ViT encoder by aggregating multi-level feature maps, and the intermediate and final feature maps in the ViT encoder, forming richer feature maps, and introduce window-major feature map organization for improving the efficiency of interleaved attention computation.","Experimental results demonstrate that the proposed approach is superior over existing real-time detectors, e.g., YOLO and its variants, on COCO and other benchmark datasets.","Code and models are available at (https://github.com/Atten4Vis/LW-DETR)."],"url":"http://arxiv.org/abs/2406.03459v1"}
{"created":"2024-06-05 17:03:47","title":"Distributional Adversarial Loss","abstract":"A major challenge in defending against adversarial attacks is the enormous space of possible attacks that even a simple adversary might perform. To address this, prior work has proposed a variety of defenses that effectively reduce the size of this space. These include randomized smoothing methods that add noise to the input to take away some of the adversary's impact. Another approach is input discretization which limits the adversary's possible number of actions.   Motivated by these two approaches, we introduce a new notion of adversarial loss which we call distributional adversarial loss, to unify these two forms of effectively weakening an adversary. In this notion, we assume for each original example, the allowed adversarial perturbation set is a family of distributions (e.g., induced by a smoothing procedure), and the adversarial loss over each example is the maximum loss over all the associated distributions. The goal is to minimize the overall adversarial loss.   We show generalization guarantees for our notion of adversarial loss in terms of the VC-dimension of the hypothesis class and the size of the set of allowed adversarial distributions associated with each input. We also investigate the role of randomness in achieving robustness against adversarial attacks in the methods described above. We show a general derandomization technique that preserves the extent of a randomized classifier's robustness against adversarial attacks. We corroborate the procedure experimentally via derandomizing the Random Projection Filters framework of \\cite{dong2023adversarial}. Our procedure also improves the robustness of the model against various adversarial attacks.","sentences":["A major challenge in defending against adversarial attacks is the enormous space of possible attacks that even a simple adversary might perform.","To address this, prior work has proposed a variety of defenses that effectively reduce the size of this space.","These include randomized smoothing methods that add noise to the input to take away some of the adversary's impact.","Another approach is input discretization which limits the adversary's possible number of actions.   ","Motivated by these two approaches, we introduce a new notion of adversarial loss which we call distributional adversarial loss, to unify these two forms of effectively weakening an adversary.","In this notion, we assume for each original example, the allowed adversarial perturbation set is a family of distributions (e.g., induced by a smoothing procedure), and the adversarial loss over each example is the maximum loss over all the associated distributions.","The goal is to minimize the overall adversarial loss.   ","We show generalization guarantees for our notion of adversarial loss in terms of the VC-dimension of the hypothesis class and the size of the set of allowed adversarial distributions associated with each input.","We also investigate the role of randomness in achieving robustness against adversarial attacks in the methods described above.","We show a general derandomization technique that preserves the extent of a randomized classifier's robustness against adversarial attacks.","We corroborate the procedure experimentally via derandomizing the Random Projection Filters framework of \\cite{dong2023adversarial}.","Our procedure also improves the robustness of the model against various adversarial attacks."],"url":"http://arxiv.org/abs/2406.03458v1"}
{"created":"2024-06-05 16:57:57","title":"Mission Design for Unmanned Aerial Vehicles using Hybrid Probabilistic Logic Program","abstract":"Advanced Air Mobility (AAM) is a growing field that demands a deep understanding of legal, spatial and temporal concepts in navigation. Hence, any implementation of AAM is forced to deal with the inherent uncertainties of human-inhabited spaces. Enabling growth and innovation requires the creation of a system for safe and robust mission design, i.e., the way we formalize intentions and decide their execution as trajectories for the Unmanned Aerial Vehicle (UAV). Although legal frameworks have emerged to govern urban air spaces, their full integration into the decision process of autonomous agents and operators remains an open task. In this work we present ProMis, a system architecture for probabilistic mission design. It links the data available from various static and dynamic data sources with legal text and operator requirements by following principles of formal verification and probabilistic modeling. Hereby, ProMis enables the combination of low-level perception and high-level rules in AAM to infer validity over the UAV's state-space. To this end, we employ Hybrid Probabilistic Logic Programs (HPLP) as a unifying, intermediate representation between perception and action-taking. Furthermore, we present methods to connect ProMis with crowd-sourced map data by generating HPLP atoms that represent spatial relations in a probabilistic fashion. Our claims of the utility and generality of ProMis are supported by experiments on a diverse set of scenarios and a discussion of the computational demands associated with probabilistic missions.","sentences":["Advanced Air Mobility (AAM) is a growing field that demands a deep understanding of legal, spatial and temporal concepts in navigation.","Hence, any implementation of AAM is forced to deal with the inherent uncertainties of human-inhabited spaces.","Enabling growth and innovation requires the creation of a system for safe and robust mission design, i.e., the way we formalize intentions and decide their execution as trajectories for the Unmanned Aerial Vehicle (UAV).","Although legal frameworks have emerged to govern urban air spaces, their full integration into the decision process of autonomous agents and operators remains an open task.","In this work we present ProMis, a system architecture for probabilistic mission design.","It links the data available from various static and dynamic data sources with legal text and operator requirements by following principles of formal verification and probabilistic modeling.","Hereby, ProMis enables the combination of low-level perception and high-level rules in AAM to infer validity over the UAV's state-space.","To this end, we employ Hybrid Probabilistic Logic Programs (HPLP) as a unifying, intermediate representation between perception and action-taking.","Furthermore, we present methods to connect ProMis with crowd-sourced map data by generating HPLP atoms that represent spatial relations in a probabilistic fashion.","Our claims of the utility and generality of ProMis are supported by experiments on a diverse set of scenarios and a discussion of the computational demands associated with probabilistic missions."],"url":"http://arxiv.org/abs/2406.03454v1"}
{"created":"2024-06-05 16:52:21","title":"Using Synchronic Definitions and Semantic Relations to Classify Semantic Change Types","abstract":"There is abundant evidence of the fact that the way words change their meaning can be classified in different types of change, highlighting the relationship between the old and new meanings (among which generalization, specialization and co-hyponymy transfer). In this paper, we present a way of detecting these types of change by constructing a model that leverages information both from synchronic lexical relations and definitions of word meanings. Specifically, we use synset definitions and hierarchy information from WordNet and test it on a digitized version of Blank's (1997) dataset of semantic change types. Finally, we show how the sense relationships can improve models for both approximation of human judgments of semantic relatedness as well as binary Lexical Semantic Change Detection.","sentences":["There is abundant evidence of the fact that the way words change their meaning can be classified in different types of change, highlighting the relationship between the old and new meanings (among which generalization, specialization and co-hyponymy transfer).","In this paper, we present a way of detecting these types of change by constructing a model that leverages information both from synchronic lexical relations and definitions of word meanings.","Specifically, we use synset definitions and hierarchy information from WordNet and test it on a digitized version of Blank's (1997) dataset of semantic change types.","Finally, we show how the sense relationships can improve models for both approximation of human judgments of semantic relatedness as well as binary Lexical Semantic Change Detection."],"url":"http://arxiv.org/abs/2406.03452v1"}
{"created":"2024-06-05 16:48:26","title":"What is the Best Way for ChatGPT to Translate Poetry?","abstract":"Machine translation (MT) has historically faced significant challenges when applied to literary works, particularly in the domain of poetry translation. The advent of Large Language Models such as ChatGPT holds potential for innovation in this field. This study examines ChatGPT's capabilities in English-Chinese poetry translation tasks, utilizing targeted prompts and small sample scenarios to ascertain optimal performance. Despite promising outcomes, our analysis reveals persistent issues in the translations generated by ChatGPT that warrant attention. To address these shortcomings, we propose an Explanation-Assisted Poetry Machine Translation (EAPMT) method, which leverages monolingual poetry explanation as a guiding information for the translation process. Furthermore, we refine existing evaluation criteria to better suit the nuances of modern poetry translation. We engaged a panel of professional poets for assessments, complemented evaluations by using GPT-4. The results from both human and machine evaluations demonstrate that our EAPMT method outperforms traditional translation methods of ChatGPT and the existing online systems. This paper validates the efficacy of our method and contributes a novel perspective to machine-assisted literary translation.","sentences":["Machine translation (MT) has historically faced significant challenges when applied to literary works, particularly in the domain of poetry translation.","The advent of Large Language Models such as ChatGPT holds potential for innovation in this field.","This study examines ChatGPT's capabilities in English-Chinese poetry translation tasks, utilizing targeted prompts and small sample scenarios to ascertain optimal performance.","Despite promising outcomes, our analysis reveals persistent issues in the translations generated by ChatGPT that warrant attention.","To address these shortcomings, we propose an Explanation-Assisted Poetry Machine Translation (EAPMT) method, which leverages monolingual poetry explanation as a guiding information for the translation process.","Furthermore, we refine existing evaluation criteria to better suit the nuances of modern poetry translation.","We engaged a panel of professional poets for assessments, complemented evaluations by using GPT-4.","The results from both human and machine evaluations demonstrate that our EAPMT method outperforms traditional translation methods of ChatGPT and the existing online systems.","This paper validates the efficacy of our method and contributes a novel perspective to machine-assisted literary translation."],"url":"http://arxiv.org/abs/2406.03450v1"}
{"created":"2024-06-05 16:44:06","title":"FILS: Self-Supervised Video Feature Prediction In Semantic Language Space","abstract":"This paper demonstrates a self-supervised approach for learning semantic video representations. Recent vision studies show that a masking strategy for vision and natural language supervision has contributed to developing transferable visual pretraining. Our goal is to achieve a more semantic video representation by leveraging the text related to the video content during the pretraining in a fully self-supervised manner. To this end, we present FILS, a novel self-supervised video Feature prediction In semantic Language Space (FILS). The vision model can capture valuable structured information by correctly predicting masked feature semantics in language space. It is learned using a patch-wise video-text contrastive strategy, in which the text representations act as prototypes for transforming vision features into a language space, which are then used as targets for semantically meaningful feature prediction using our masked encoder-decoder structure. FILS demonstrates remarkable transferability on downstream action recognition tasks, achieving state-of-the-art on challenging egocentric datasets, like Epic-Kitchens, Something-SomethingV2, Charades-Ego, and EGTEA, using ViT-Base. Our efficient method requires less computation and smaller batches compared to previous works.","sentences":["This paper demonstrates a self-supervised approach for learning semantic video representations.","Recent vision studies show that a masking strategy for vision and natural language supervision has contributed to developing transferable visual pretraining.","Our goal is to achieve a more semantic video representation by leveraging the text related to the video content during the pretraining in a fully self-supervised manner.","To this end, we present FILS, a novel self-supervised video Feature prediction In semantic Language Space (FILS).","The vision model can capture valuable structured information by correctly predicting masked feature semantics in language space.","It is learned using a patch-wise video-text contrastive strategy, in which the text representations act as prototypes for transforming vision features into a language space, which are then used as targets for semantically meaningful feature prediction using our masked encoder-decoder structure.","FILS demonstrates remarkable transferability on downstream action recognition tasks, achieving state-of-the-art on challenging egocentric datasets, like Epic-Kitchens, Something-SomethingV2, Charades-Ego, and EGTEA, using ViT-Base.","Our efficient method requires less computation and smaller batches compared to previous works."],"url":"http://arxiv.org/abs/2406.03447v1"}
{"created":"2024-06-05 16:40:53","title":"Pre-trained Large Language Models Use Fourier Features to Compute Addition","abstract":"Pre-trained large language models (LLMs) exhibit impressive mathematical reasoning capabilities, yet how they compute basic arithmetic, such as addition, remains unclear. This paper shows that pre-trained LLMs add numbers using Fourier features -- dimensions in the hidden state that represent numbers via a set of features sparse in the frequency domain. Within the model, MLP and attention layers use Fourier features in complementary ways: MLP layers primarily approximate the magnitude of the answer using low-frequency features, while attention layers primarily perform modular addition (e.g., computing whether the answer is even or odd) using high-frequency features. Pre-training is crucial for this mechanism: models trained from scratch to add numbers only exploit low-frequency features, leading to lower accuracy. Introducing pre-trained token embeddings to a randomly initialized model rescues its performance. Overall, our analysis demonstrates that appropriate pre-trained representations (e.g., Fourier features) can unlock the ability of Transformers to learn precise mechanisms for algorithmic tasks.","sentences":["Pre-trained large language models (LLMs) exhibit impressive mathematical reasoning capabilities, yet how they compute basic arithmetic, such as addition, remains unclear.","This paper shows that pre-trained LLMs add numbers using Fourier features -- dimensions in the hidden state that represent numbers via a set of features sparse in the frequency domain.","Within the model, MLP and attention layers use Fourier features in complementary ways: MLP layers primarily approximate the magnitude of the answer using low-frequency features, while attention layers primarily perform modular addition (e.g., computing whether the answer is even or odd) using high-frequency features.","Pre-training is crucial for this mechanism: models trained from scratch to add numbers only exploit low-frequency features, leading to lower accuracy.","Introducing pre-trained token embeddings to a randomly initialized model rescues its performance.","Overall, our analysis demonstrates that appropriate pre-trained representations (e.g., Fourier features) can unlock the ability of Transformers to learn precise mechanisms for algorithmic tasks."],"url":"http://arxiv.org/abs/2406.03445v1"}
{"created":"2024-06-05 16:36:57","title":"Investigating the Relationship Between User Specialization and Toxicity on Reddit: A Sentiment Analysis Approach","abstract":"Online platforms host a diverse user base, which can be broadly categorized into \"specialist users\" with focused interests and \"generalist users\" who engage in a wide range of topics. This study explores the behavioral differences between these two user types on the popular platform Reddit, focusing on the level of toxicity in their posts and the associated sentiment scores across 24 emotional categories and a neutral state. By employing community embeddings to represent users in a high-dimensional space, we measure activity diversity using the GS score. We analyze a dataset of 16,291,992 posts from 4,926,237 users spanning the period from 2019 to 2021, assessing the degree of toxicity and sentiment scores for each post. Our findings indicate that specialist users exhibit higher levels of toxic behavior compared to generalist users. Furthermore, specialist users demonstrate elevated scores for annoyance, sadness, and fear, while generalist users show higher scores for curiosity, admiration, and love. These insights contribute to a better understanding of user behavior on online platforms and can inform strategies for fostering healthier online communities.","sentences":["Online platforms host a diverse user base, which can be broadly categorized into \"specialist users\" with focused interests and \"generalist users\" who engage in a wide range of topics.","This study explores the behavioral differences between these two user types on the popular platform Reddit, focusing on the level of toxicity in their posts and the associated sentiment scores across 24 emotional categories and a neutral state.","By employing community embeddings to represent users in a high-dimensional space, we measure activity diversity using the GS score.","We analyze a dataset of 16,291,992 posts from 4,926,237 users spanning the period from 2019 to 2021, assessing the degree of toxicity and sentiment scores for each post.","Our findings indicate that specialist users exhibit higher levels of toxic behavior compared to generalist users.","Furthermore, specialist users demonstrate elevated scores for annoyance, sadness, and fear, while generalist users show higher scores for curiosity, admiration, and love.","These insights contribute to a better understanding of user behavior on online platforms and can inform strategies for fostering healthier online communities."],"url":"http://arxiv.org/abs/2406.03443v1"}
{"created":"2024-06-05 16:36:21","title":"Are language models rational? The case of coherence norms and belief revision","abstract":"Do norms of rationality apply to machine learning models, in particular language models? In this paper we investigate this question by focusing on a special subset of rational norms: coherence norms. We consider both logical coherence norms as well as coherence norms tied to the strength of belief. To make sense of the latter, we introduce the Minimal Assent Connection (MAC) and propose a new account of credence, which captures the strength of belief in language models. This proposal uniformly assigns strength of belief simply on the basis of model internal next token probabilities. We argue that rational norms tied to coherence do apply to some language models, but not to others. This issue is significant since rationality is closely tied to predicting and explaining behavior, and thus it is connected to considerations about AI safety and alignment, as well as understanding model behavior more generally.","sentences":["Do norms of rationality apply to machine learning models, in particular language models?","In this paper we investigate this question by focusing on a special subset of rational norms: coherence norms.","We consider both logical coherence norms as well as coherence norms tied to the strength of belief.","To make sense of the latter, we introduce the Minimal Assent Connection (MAC) and propose a new account of credence, which captures the strength of belief in language models.","This proposal uniformly assigns strength of belief simply on the basis of model internal next token probabilities.","We argue that rational norms tied to coherence do apply to some language models, but not to others.","This issue is significant since rationality is closely tied to predicting and explaining behavior, and thus it is connected to considerations about AI safety and alignment, as well as understanding model behavior more generally."],"url":"http://arxiv.org/abs/2406.03442v1"}
{"created":"2024-06-05 16:35:30","title":"Cycles of Thought: Measuring LLM Confidence through Stable Explanations","abstract":"In many high-risk machine learning applications it is essential for a model to indicate when it is uncertain about a prediction. While large language models (LLMs) can reach and even surpass human-level accuracy on a variety of benchmarks, their overconfidence in incorrect responses is still a well-documented failure mode. Traditional methods for ML uncertainty quantification can be difficult to directly adapt to LLMs due to the computational cost of implementation and closed-source nature of many models. A variety of black-box methods have recently been proposed, but these often rely on heuristics such as self-verbalized confidence. We instead propose a framework for measuring an LLM's uncertainty with respect to the distribution of generated explanations for an answer. While utilizing explanations is not a new idea in and of itself, by interpreting each possible model+explanation pair as a test-time classifier we can calculate a posterior answer distribution over the most likely of these classifiers. We demonstrate how a specific instance of this framework using explanation entailment as our classifier likelihood improves confidence score metrics (in particular AURC and AUROC) over baselines across five different datasets. We believe these results indicate that our framework is both a well-principled and effective way of quantifying uncertainty in LLMs.","sentences":["In many high-risk machine learning applications it is essential for a model to indicate when it is uncertain about a prediction.","While large language models (LLMs) can reach and even surpass human-level accuracy on a variety of benchmarks, their overconfidence in incorrect responses is still a well-documented failure mode.","Traditional methods for ML uncertainty quantification can be difficult to directly adapt to LLMs due to the computational cost of implementation and closed-source nature of many models.","A variety of black-box methods have recently been proposed, but these often rely on heuristics such as self-verbalized confidence.","We instead propose a framework for measuring an LLM's uncertainty with respect to the distribution of generated explanations for an answer.","While utilizing explanations is not a new idea in and of itself, by interpreting each possible model+explanation pair as a test-time classifier we can calculate a posterior answer distribution over the most likely of these classifiers.","We demonstrate how a specific instance of this framework using explanation entailment as our classifier likelihood improves confidence score metrics (in particular AURC and AUROC) over baselines across five different datasets.","We believe these results indicate that our framework is both a well-principled and effective way of quantifying uncertainty in LLMs."],"url":"http://arxiv.org/abs/2406.03441v1"}
{"created":"2024-06-05 16:34:12","title":"Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input","abstract":"Event cameras are advantageous for tasks that require vision sensors with low-latency and sparse output responses. However, the development of deep network algorithms using event cameras has been slow because of the lack of large labelled event camera datasets for network training. This paper reports a method for creating new labelled event datasets by using a text-to-X model, where X is one or multiple output modalities, in the case of this work, events. Our proposed text-to-events model produces synthetic event frames directly from text prompts. It uses an autoencoder which is trained to produce sparse event frames representing event camera outputs. By combining the pretrained autoencoder with a diffusion model architecture, the new text-to-events model is able to generate smooth synthetic event streams of moving objects. The autoencoder was first trained on an event camera dataset of diverse scenes. In the combined training with the diffusion model, the DVS gesture dataset was used. We demonstrate that the model can generate realistic event sequences of human gestures prompted by different text statements. The classification accuracy of the generated sequences, using a classifier trained on the real dataset, ranges between 42% to 92%, depending on the gesture group. The results demonstrate the capability of this method in synthesizing event datasets.","sentences":["Event cameras are advantageous for tasks that require vision sensors with low-latency and sparse output responses.","However, the development of deep network algorithms using event cameras has been slow because of the lack of large labelled event camera datasets for network training.","This paper reports a method for creating new labelled event datasets by using a text-to-X model, where X is one or multiple output modalities, in the case of this work, events.","Our proposed text-to-events model produces synthetic event frames directly from text prompts.","It uses an autoencoder which is trained to produce sparse event frames representing event camera outputs.","By combining the pretrained autoencoder with a diffusion model architecture, the new text-to-events model is able to generate smooth synthetic event streams of moving objects.","The autoencoder was first trained on an event camera dataset of diverse scenes.","In the combined training with the diffusion model, the DVS gesture dataset was used.","We demonstrate that the model can generate realistic event sequences of human gestures prompted by different text statements.","The classification accuracy of the generated sequences, using a classifier trained on the real dataset, ranges between 42% to 92%, depending on the gesture group.","The results demonstrate the capability of this method in synthesizing event datasets."],"url":"http://arxiv.org/abs/2406.03439v1"}
{"created":"2024-06-05 16:33:35","title":"CSI-GPT: Integrating Generative Pre-Trained Transformer with Federated-Tuning to Acquire Downlink Massive MIMO Channels","abstract":"In massive multiple-input multiple-output (MIMO) systems, how to reliably acquire downlink channel state information (CSI) with low overhead is challenging. In this work, by integrating the generative pre-trained Transformer (GPT) with federated-tuning, we propose a CSI-GPT approach to realize efficient downlink CSI acquisition. Specifically, we first propose a Swin Transformer-based channel acquisition network (SWTCAN) to acquire downlink CSI, where pilot signals, downlink channel estimation, and uplink CSI feedback are jointly designed. Furthermore, to solve the problem of insufficient training data, we propose a variational auto-encoder-based channel sample generator (VAE-CSG), which can generate sufficient CSI samples based on a limited number of high-quality CSI data obtained from the current cell. The CSI dataset generated from VAE-CSG will be used for pre-training SWTCAN. To fine-tune the pre-trained SWTCAN for improved performance, we propose an online federated-tuning method, where only a small amount of SWTCAN parameters are unfrozen and updated using over-the-air computation, avoiding the high communication overhead caused by aggregating the complete CSI samples from user equipment (UEs) to the BS for centralized fine-tuning. Simulation results verify the advantages of the proposed SWTCAN and the communication efficiency of the proposed federated-tuning method.","sentences":["In massive multiple-input multiple-output (MIMO) systems, how to reliably acquire downlink channel state information (CSI) with low overhead is challenging.","In this work, by integrating the generative pre-trained Transformer (GPT) with federated-tuning, we propose a CSI-GPT approach to realize efficient downlink CSI acquisition.","Specifically, we first propose a Swin Transformer-based channel acquisition network (SWTCAN) to acquire downlink CSI, where pilot signals, downlink channel estimation, and uplink CSI feedback are jointly designed.","Furthermore, to solve the problem of insufficient training data, we propose a variational auto-encoder-based channel sample generator (VAE-CSG), which can generate sufficient CSI samples based on a limited number of high-quality CSI data obtained from the current cell.","The CSI dataset generated from VAE-CSG will be used for pre-training SWTCAN.","To fine-tune the pre-trained SWTCAN for improved performance, we propose an online federated-tuning method, where only a small amount of SWTCAN parameters are unfrozen and updated using over-the-air computation, avoiding the high communication overhead caused by aggregating the complete CSI samples from user equipment (UEs) to the BS for centralized fine-tuning.","Simulation results verify the advantages of the proposed SWTCAN and the communication efficiency of the proposed federated-tuning method."],"url":"http://arxiv.org/abs/2406.03438v1"}
{"created":"2024-06-05 16:33:30","title":"Transfer Learning for Latent Variable Network Models","abstract":"We study transfer learning for estimation in latent variable network models. In our setting, the conditional edge probability matrices given the latent variables are represented by $P$ for the source and $Q$ for the target. We wish to estimate $Q$ given two kinds of data: (1) edge data from a subgraph induced by an $o(1)$ fraction of the nodes of $Q$, and (2) edge data from all of $P$. If the source $P$ has no relation to the target $Q$, the estimation error must be $\\Omega(1)$. However, we show that if the latent variables are shared, then vanishing error is possible. We give an efficient algorithm that utilizes the ordering of a suitably defined graph distance. Our algorithm achieves $o(1)$ error and does not assume a parametric form on the source or target networks. Next, for the specific case of Stochastic Block Models we prove a minimax lower bound and show that a simple algorithm achieves this rate. Finally, we empirically demonstrate our algorithm's use on real-world and simulated graph transfer problems.","sentences":["We study transfer learning for estimation in latent variable network models.","In our setting, the conditional edge probability matrices given the latent variables are represented by $P$ for the source and $Q$ for the target.","We wish to estimate $Q$ given two kinds of data: (1) edge data from a subgraph induced by an $o(1)$ fraction of the nodes of $Q$, and (2) edge data from all of $P$. If the source $P$ has no relation to the target $Q$, the estimation error must be $\\Omega(1)$. However, we show that if the latent variables are shared, then vanishing error is possible.","We give an efficient algorithm that utilizes the ordering of a suitably defined graph distance.","Our algorithm achieves $o(1)$ error and does not assume a parametric form on the source or target networks.","Next, for the specific case of Stochastic Block Models we prove a minimax lower bound and show that a simple algorithm achieves this rate.","Finally, we empirically demonstrate our algorithm's use on real-world and simulated graph transfer problems."],"url":"http://arxiv.org/abs/2406.03437v1"}
{"created":"2024-06-05 16:32:14","title":"Unified PAC-Bayesian Study of Pessimism for Offline Policy Learning with Regularized Importance Sampling","abstract":"Off-policy learning (OPL) often involves minimizing a risk estimator based on importance weighting to correct bias from the logging policy used to collect data. However, this method can produce an estimator with a high variance. A common solution is to regularize the importance weights and learn the policy by minimizing an estimator with penalties derived from generalization bounds specific to the estimator. This approach, known as pessimism, has gained recent attention but lacks a unified framework for analysis. To address this gap, we introduce a comprehensive PAC-Bayesian framework to examine pessimism with regularized importance weighting. We derive a tractable PAC-Bayesian generalization bound that universally applies to common importance weight regularizations, enabling their comparison within a single framework. Our empirical results challenge common understanding, demonstrating the effectiveness of standard IW regularization techniques.","sentences":["Off-policy learning (OPL) often involves minimizing a risk estimator based on importance weighting to correct bias from the logging policy used to collect data.","However, this method can produce an estimator with a high variance.","A common solution is to regularize the importance weights and learn the policy by minimizing an estimator with penalties derived from generalization bounds specific to the estimator.","This approach, known as pessimism, has gained recent attention but lacks a unified framework for analysis.","To address this gap, we introduce a comprehensive PAC-Bayesian framework to examine pessimism with regularized importance weighting.","We derive a tractable PAC-Bayesian generalization bound that universally applies to common importance weight regularizations, enabling their comparison within a single framework.","Our empirical results challenge common understanding, demonstrating the effectiveness of standard IW regularization techniques."],"url":"http://arxiv.org/abs/2406.03434v1"}
{"created":"2024-06-05 16:29:13","title":"CattleFace-RGBT: RGB-T Cattle Facial Landmark Benchmark","abstract":"To address this challenge, we introduce CattleFace-RGBT, a RGB-T Cattle Facial Landmark dataset consisting of 2,300 RGB-T image pairs, a total of 4,600 images. Creating a landmark dataset is time-consuming, but AI-assisted annotation can help. However, applying AI to thermal images is challenging due to suboptimal results from direct thermal training and infeasible RGB-thermal alignment due to different camera views. Therefore, we opt to transfer models trained on RGB to thermal images and refine them using our AI-assisted annotation tool following a semi-automatic annotation approach. Accurately localizing facial key points on both RGB and thermal images enables us to not only discern the cattle's respiratory signs but also measure temperatures to assess the animal's thermal state. To the best of our knowledge, this is the first dataset for the cattle facial landmark on RGB-T images. We conduct benchmarking of the CattleFace-RGBT dataset across various backbone architectures, with the objective of establishing baselines for future research, analysis, and comparison. The dataset and models are at https://github.com/UARK-AICV/CattleFace-RGBT-benchmark","sentences":["To address this challenge, we introduce CattleFace-RGBT, a RGB-T Cattle Facial Landmark dataset consisting of 2,300 RGB-T image pairs, a total of 4,600 images.","Creating a landmark dataset is time-consuming, but AI-assisted annotation can help.","However, applying AI to thermal images is challenging due to suboptimal results from direct thermal training and infeasible RGB-thermal alignment due to different camera views.","Therefore, we opt to transfer models trained on RGB to thermal images and refine them using our AI-assisted annotation tool following a semi-automatic annotation approach.","Accurately localizing facial key points on both RGB and thermal images enables us to not only discern the cattle's respiratory signs but also measure temperatures to assess the animal's thermal state.","To the best of our knowledge, this is the first dataset for the cattle facial landmark on RGB-T images.","We conduct benchmarking of the CattleFace-RGBT dataset across various backbone architectures, with the objective of establishing baselines for future research, analysis, and comparison.","The dataset and models are at https://github.com/UARK-AICV/CattleFace-RGBT-benchmark"],"url":"http://arxiv.org/abs/2406.03431v1"}
{"created":"2024-06-05 16:25:57","title":"HelloFresh: LLM Evaluations on Streams of Real-World Human Editorial Actions across X Community Notes and Wikipedia edits","abstract":"Benchmarks have been essential for driving progress in machine learning. A better understanding of LLM capabilities on real world tasks is vital for safe development. Designing adequate LLM benchmarks is challenging: Data from real-world tasks is hard to collect, public availability of static evaluation data results in test data contamination and benchmark overfitting, and periodically generating new evaluation data is tedious and may result in temporally inconsistent results. We introduce HelloFresh, based on continuous streams of real-world data generated by intrinsically motivated human labelers. It covers recent events from X (formerly Twitter) community notes and edits of Wikipedia pages, mitigating the risk of test data contamination and benchmark overfitting. Any X user can propose an X note to add additional context to a misleading post (formerly tweet); if the community classifies it as helpful, it is shown with the post. Similarly, Wikipedia relies on community-based consensus, allowing users to edit articles or revert edits made by other users. Verifying whether an X note is helpful or whether a Wikipedia edit should be accepted are hard tasks that require grounding by querying the web. We backtest state-of-the-art LLMs supplemented with simple web search access and find that HelloFresh yields a temporally consistent ranking. To enable continuous evaluation on HelloFresh, we host a public leaderboard and periodically updated evaluation data at https://tinyurl.com/hello-fresh-LLM.","sentences":["Benchmarks have been essential for driving progress in machine learning.","A better understanding of LLM capabilities on real world tasks is vital for safe development.","Designing adequate LLM benchmarks is challenging: Data from real-world tasks is hard to collect, public availability of static evaluation data results in test data contamination and benchmark overfitting, and periodically generating new evaluation data is tedious and may result in temporally inconsistent results.","We introduce HelloFresh, based on continuous streams of real-world data generated by intrinsically motivated human labelers.","It covers recent events from X (formerly Twitter) community notes and edits of Wikipedia pages, mitigating the risk of test data contamination and benchmark overfitting.","Any X user can propose an X note to add additional context to a misleading post (formerly tweet); if the community classifies it as helpful, it is shown with the post.","Similarly, Wikipedia relies on community-based consensus, allowing users to edit articles or revert edits made by other users.","Verifying whether an X note is helpful or whether a Wikipedia edit should be accepted are hard tasks that require grounding by querying the web.","We backtest state-of-the-art LLMs supplemented with simple web search access and find that HelloFresh yields a temporally consistent ranking.","To enable continuous evaluation on HelloFresh, we host a public leaderboard and periodically updated evaluation data at https://tinyurl.com/hello-fresh-LLM."],"url":"http://arxiv.org/abs/2406.03428v1"}
{"created":"2024-06-05 16:25:45","title":"The strong data processing inequality under the heat flow","abstract":"Let $\\nu$ and $\\mu$ be probability distributions on $\\mathbb{R}^n$, and $\\nu_s,\\mu_s$ be their evolution under the heat flow, that is, the probability distributions resulting from convolving their density with the density of an isotropic Gaussian random vector with variance $s$ in each entry. This paper studies the rate of decay of $s\\mapsto D(\\nu_s\\|\\mu_s)$ for various divergences, including the $\\chi^2$ and Kullback-Leibler (KL) divergences. We prove upper and lower bounds on the strong data-processing inequality (SDPI) coefficients corresponding to the source $\\mu$ and the Gaussian channel. We also prove generalizations of de Brujin's identity, and Costa's result on the concavity in $s$ of the differential entropy of $\\nu_s$. As a byproduct of our analysis, we obtain new lower bounds on the mutual information between $X$ and $Y=X+\\sqrt{s} Z$, where $Z$ is a standard Gaussian vector in $\\mathbb{R}^n$, independent of $X$, and on the minimum mean-square error (MMSE) in estimating $X$ from $Y$, in terms of the Poincar\\'e constant of $X$.","sentences":["Let $\\nu$ and $\\mu$ be probability distributions on $\\mathbb{R}^n$, and $\\nu_s,\\mu_s$ be their evolution under the heat flow, that is, the probability distributions resulting from convolving their density with the density of an isotropic Gaussian random vector with variance $s$ in each entry.","This paper studies the rate of decay of $s\\mapsto D(\\nu_s\\|\\mu_s)$ for various divergences, including the $\\chi^2$ and Kullback-Leibler (KL) divergences.","We prove upper and lower bounds on the strong data-processing inequality (SDPI) coefficients corresponding to the source $\\mu$ and the Gaussian channel.","We also prove generalizations of de Brujin's identity, and Costa's result on the concavity in $s$ of the differential entropy of $\\nu_s$. As a byproduct of our analysis, we obtain new lower bounds on the mutual information between $X$ and $Y=X+\\sqrt{s} Z$, where $Z$ is a standard Gaussian vector in $\\mathbb{R}^n$, independent of $X$, and on the minimum mean-square error (MMSE) in estimating $X$ from $Y$, in terms of the Poincar\\'e constant of $X$."],"url":"http://arxiv.org/abs/2406.03427v1"}
{"created":"2024-06-05 16:19:24","title":"Improving Users' Passwords with DPAR: a Data-driven Password Recommendation System","abstract":"Passwords are the primary authentication method online, but even with password policies and meters, users still find it hard to create strong and memorable passwords. In this paper, we propose DPAR: a Data-driven PAssword Recommendation system based on a dataset of 905 million leaked passwords. DPAR generates password recommendations by analyzing the user's given password and suggesting specific tweaks that would make it stronger while still keeping it memorable and similar to the original password. We conducted two studies to evaluate our approach: verifying the memorability of generated passwords (n=317), and evaluating the strength and recall of DPAR recommendations against password meters (n=441). In a randomized experiment, we show that DPAR increased password strength by 34.8 bits on average and did not significantly affect the ability to recall their password. Furthermore, 36.6% of users accepted DPAR's recommendations verbatim. We discuss our findings and their implications for enhancing password management with recommendation systems.","sentences":["Passwords are the primary authentication method online, but even with password policies and meters, users still find it hard to create strong and memorable passwords.","In this paper, we propose DPAR: a Data-driven PAssword Recommendation system based on a dataset of 905 million leaked passwords.","DPAR generates password recommendations by analyzing the user's given password and suggesting specific tweaks that would make it stronger while still keeping it memorable and similar to the original password.","We conducted two studies to evaluate our approach: verifying the memorability of generated passwords (n=317), and evaluating the strength and recall of DPAR recommendations against password meters (n=441).","In a randomized experiment, we show that DPAR increased password strength by 34.8 bits on average and did not significantly affect the ability to recall their password.","Furthermore, 36.6% of users accepted DPAR's recommendations verbatim.","We discuss our findings and their implications for enhancing password management with recommendation systems."],"url":"http://arxiv.org/abs/2406.03423v1"}
{"created":"2024-06-05 16:16:45","title":"Causal Inference from Competing Treatments","abstract":"Many applications of RCTs involve the presence of multiple treatment administrators -- from field experiments to online advertising -- that compete for the subjects' attention. In the face of competition, estimating a causal effect becomes difficult, as the position at which a subject sees a treatment influences their response, and thus the treatment effect. In this paper, we build a game-theoretic model of agents who wish to estimate causal effects in the presence of competition, through a bidding system and a utility function that minimizes estimation error. Our main technical result establishes an approximation with a tractable objective that maximizes the sample value obtained through strategically allocating budget on subjects. This allows us to find an equilibrium in our model: we show that the tractable objective has a pure Nash equilibrium, and that any Nash equilibrium is an approximate equilibrium for our general objective that minimizes estimation error under broad conditions. Conceptually, our work successfully combines elements from causal inference and game theory to shed light on the equilibrium behavior of experimentation under competition.","sentences":["Many applications of RCTs involve the presence of multiple treatment administrators -- from field experiments to online advertising -- that compete for the subjects' attention.","In the face of competition, estimating a causal effect becomes difficult, as the position at which a subject sees a treatment influences their response, and thus the treatment effect.","In this paper, we build a game-theoretic model of agents who wish to estimate causal effects in the presence of competition, through a bidding system and a utility function that minimizes estimation error.","Our main technical result establishes an approximation with a tractable objective that maximizes the sample value obtained through strategically allocating budget on subjects.","This allows us to find an equilibrium in our model: we show that the tractable objective has a pure Nash equilibrium, and that any Nash equilibrium is an approximate equilibrium for our general objective that minimizes estimation error under broad conditions.","Conceptually, our work successfully combines elements from causal inference and game theory to shed light on the equilibrium behavior of experimentation under competition."],"url":"http://arxiv.org/abs/2406.03422v1"}
{"created":"2024-06-05 16:16:03","title":"Post-hoc Part-prototype Networks","abstract":"Post-hoc explainability methods such as Grad-CAM are popular because they do not influence the performance of a trained model. However, they mainly reveal \"where\" a model looks at for a given input, fail to explain \"what\" the model looks for (e.g., what is important to classify a bird image to a Scott Oriole?). Existing part-prototype networks leverage part-prototypes (e.g., characteristic Scott Oriole's wing and head) to answer both \"where\" and \"what\", but often under-perform their black box counterparts in the accuracy. Therefore, a natural question is: can one construct a network that answers both \"where\" and \"what\" in a post-hoc manner to guarantee the model's performance? To this end, we propose the first post-hoc part-prototype network via decomposing the classification head of a trained model into a set of interpretable part-prototypes. Concretely, we propose an unsupervised prototype discovery and refining strategy to obtain prototypes that can precisely reconstruct the classification head, yet being interpretable. Besides guaranteeing the performance, we show that our network offers more faithful explanations qualitatively and yields even better part-prototypes quantitatively than prior part-prototype networks.","sentences":["Post-hoc explainability methods such as Grad-CAM are popular because they do not influence the performance of a trained model.","However, they mainly reveal \"where\" a model looks at for a given input, fail to explain \"what\" the model looks for (e.g., what is important to classify a bird image to a Scott Oriole?).","Existing part-prototype networks leverage part-prototypes (e.g., characteristic Scott Oriole's wing and head) to answer both \"where\" and \"what\", but often under-perform their black box counterparts in the accuracy.","Therefore, a natural question is: can one construct a network that answers both \"where\" and \"what\" in a post-hoc manner to guarantee the model's performance?","To this end, we propose the first post-hoc part-prototype network via decomposing the classification head of a trained model into a set of interpretable part-prototypes.","Concretely, we propose an unsupervised prototype discovery and refining strategy to obtain prototypes that can precisely reconstruct the classification head, yet being interpretable.","Besides guaranteeing the performance, we show that our network offers more faithful explanations qualitatively and yields even better part-prototypes quantitatively than prior part-prototype networks."],"url":"http://arxiv.org/abs/2406.03421v1"}
{"created":"2024-06-05 16:12:19","title":"CoFie: Learning Compact Neural Surface Representations with Coordinate Fields","abstract":"This paper introduces CoFie, a novel local geometry-aware neural surface representation. CoFie is motivated by the theoretical analysis of local SDFs with quadratic approximation. We find that local shapes are highly compressive in an aligned coordinate frame defined by the normal and tangent directions of local shapes. Accordingly, we introduce Coordinate Field, which is a composition of coordinate frames of all local shapes. The Coordinate Field is optimizable and is used to transform the local shapes from the world coordinate frame to the aligned shape coordinate frame. It largely reduces the complexity of local shapes and benefits the learning of MLP-based implicit representations. Moreover, we introduce quadratic layers into the MLP to enhance expressiveness concerning local shape geometry. CoFie is a generalizable surface representation. It is trained on a curated set of 3D shapes and works on novel shape instances during testing. When using the same amount of parameters with prior works, CoFie reduces the shape error by 48% and 56% on novel instances of both training and unseen shape categories. Moreover, CoFie demonstrates comparable performance to prior works when using only 70% fewer parameters.","sentences":["This paper introduces CoFie, a novel local geometry-aware neural surface representation.","CoFie is motivated by the theoretical analysis of local SDFs with quadratic approximation.","We find that local shapes are highly compressive in an aligned coordinate frame defined by the normal and tangent directions of local shapes.","Accordingly, we introduce Coordinate Field, which is a composition of coordinate frames of all local shapes.","The Coordinate Field is optimizable and is used to transform the local shapes from the world coordinate frame to the aligned shape coordinate frame.","It largely reduces the complexity of local shapes and benefits the learning of MLP-based implicit representations.","Moreover, we introduce quadratic layers into the MLP to enhance expressiveness concerning local shape geometry.","CoFie is a generalizable surface representation.","It is trained on a curated set of 3D shapes and works on novel shape instances during testing.","When using the same amount of parameters with prior works, CoFie reduces the shape error by 48% and 56% on novel instances of both training and unseen shape categories.","Moreover, CoFie demonstrates comparable performance to prior works when using only 70% fewer parameters."],"url":"http://arxiv.org/abs/2406.03417v1"}
{"created":"2024-06-05 16:11:15","title":"RemixTape: Enriching Narratives about Metrics with Semantic Alignment and Contextual Recommendation","abstract":"The temporal dynamics of quantitative metrics or key performance indicators (KPIs) are central to decision making within enterprise organizations. Recently, major business intelligence providers have introduced new infrastructure for defining, sharing, and monitoring metric values. However, these values are often presented in isolation and appropriate context is seldom externalized. In this design study, we present RemixTape, an application for constructing structured narratives around metrics. With design imperatives grounded in an formative interview study, RemixTape provides a hierarchical canvas for collecting and coordinating sequences of line chart representations of metrics, along with the ability to externalize situational context around them. RemixTape incorporates affordances to semantically align and annotate juxtaposed charts and text, as well as recommendations of complementary charts based on metrics already present on the canvas. We evaluated RemixTape in a user study in which six enterprise data professionals reproduced and extended partial narratives, with participants appreciating RemixTape as a novel alternative to dashboards, galleries, and slide presentations for supporting conversations about metrics. We conclude with a reflection on how aspects of RemixTape could generalize beyond metrics, with a call to define a conceptual foundation for remixing in the context of visualization.","sentences":["The temporal dynamics of quantitative metrics or key performance indicators (KPIs) are central to decision making within enterprise organizations.","Recently, major business intelligence providers have introduced new infrastructure for defining, sharing, and monitoring metric values.","However, these values are often presented in isolation and appropriate context is seldom externalized.","In this design study, we present RemixTape, an application for constructing structured narratives around metrics.","With design imperatives grounded in an formative interview study, RemixTape provides a hierarchical canvas for collecting and coordinating sequences of line chart representations of metrics, along with the ability to externalize situational context around them.","RemixTape incorporates affordances to semantically align and annotate juxtaposed charts and text, as well as recommendations of complementary charts based on metrics already present on the canvas.","We evaluated RemixTape in a user study in which six enterprise data professionals reproduced and extended partial narratives, with participants appreciating RemixTape as a novel alternative to dashboards, galleries, and slide presentations for supporting conversations about metrics.","We conclude with a reflection on how aspects of RemixTape could generalize beyond metrics, with a call to define a conceptual foundation for remixing in the context of visualization."],"url":"http://arxiv.org/abs/2406.03415v1"}
{"created":"2024-06-05 16:09:01","title":"Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach","abstract":"In this paper, we primarily address the issue of dialogue-form context query within the interactive text-to-image retrieval task. Our methodology, PlugIR, actively utilizes the general instruction-following capability of LLMs in two ways. First, by reformulating the dialogue-form context, we eliminate the necessity of fine-tuning a retrieval model on existing visual dialogue data, thereby enabling the use of any arbitrary black-box model. Second, we construct the LLM questioner to generate non-redundant questions about the attributes of the target image, based on the information of retrieval candidate images in the current context. This approach mitigates the issues of noisiness and redundancy in the generated questions. Beyond our methodology, we propose a novel evaluation metric, Best log Rank Integral (BRI), for a comprehensive assessment of the interactive retrieval system. PlugIR demonstrates superior performance compared to both zero-shot and fine-tuned baselines in various benchmarks. Additionally, the two methodologies comprising PlugIR can be flexibly applied together or separately in various situations. Our codes are available at https://github.com/Saehyung-Lee/PlugIR.","sentences":["In this paper, we primarily address the issue of dialogue-form context query within the interactive text-to-image retrieval task.","Our methodology, PlugIR, actively utilizes the general instruction-following capability of LLMs in two ways.","First, by reformulating the dialogue-form context, we eliminate the necessity of fine-tuning a retrieval model on existing visual dialogue data, thereby enabling the use of any arbitrary black-box model.","Second, we construct the LLM questioner to generate non-redundant questions about the attributes of the target image, based on the information of retrieval candidate images in the current context.","This approach mitigates the issues of noisiness and redundancy in the generated questions.","Beyond our methodology, we propose a novel evaluation metric, Best log Rank Integral (BRI), for a comprehensive assessment of the interactive retrieval system.","PlugIR demonstrates superior performance compared to both zero-shot and fine-tuned baselines in various benchmarks.","Additionally, the two methodologies comprising PlugIR can be flexibly applied together or separately in various situations.","Our codes are available at https://github.com/Saehyung-Lee/PlugIR."],"url":"http://arxiv.org/abs/2406.03411v1"}
{"created":"2024-06-05 16:03:40","title":"CROSSCON: Cross-platform Open Security Stack for Connected Devices","abstract":"The proliferation of Internet of Things (IoT) embedded devices is expected to reach 30 billion by 2030, creating a dynamic landscape where diverse devices must coexist. This presents challenges due to the rapid expansion of different architectures and platforms. Addressing these challenges requires a unifi ed solution capable of accommodating various devices while offering a broad range of services to connect them to the Internet effectively. This white paper introduces CROSSCON, a three-year Research and Innovation Action funded under Horizon Europe. CROSSCON aims to tackle current IoT challenges by developing a new open, modular, and universally compatible IoT security stack. This stack is designed to be highly portable and vendor-independent, enabling its deployment across different devices with heterogeneous embedded hardware architectures, including ARM and RISC-V. The CROSSCON consortium consists of 11 partners spanning 8 European countries. This consortium includes 4 academic institutions, 1 major industrial partner, and 5 small to medium-sized enterprises (SMEs).","sentences":["The proliferation of Internet of Things (IoT) embedded devices is expected to reach 30 billion by 2030, creating a dynamic landscape where diverse devices must coexist.","This presents challenges due to the rapid expansion of different architectures and platforms.","Addressing these challenges requires a unifi ed solution capable of accommodating various devices while offering a broad range of services to connect them to the Internet effectively.","This white paper introduces CROSSCON, a three-year Research and Innovation Action funded under Horizon Europe.","CROSSCON aims to tackle current IoT challenges by developing a new open, modular, and universally compatible IoT security stack.","This stack is designed to be highly portable and vendor-independent, enabling its deployment across different devices with heterogeneous embedded hardware architectures, including ARM and RISC-V.","The CROSSCON consortium consists of 11 partners spanning 8 European countries.","This consortium includes 4 academic institutions, 1 major industrial partner, and 5 small to medium-sized enterprises (SMEs)."],"url":"http://arxiv.org/abs/2406.03401v1"}
{"created":"2024-06-05 15:55:08","title":"Methods for Class-Imbalanced Learning with Support Vector Machines: A Review and an Empirical Evaluation","abstract":"This paper presents a review on methods for class-imbalanced learning with the Support Vector Machine (SVM) and its variants. We first explain the structure of SVM and its variants and discuss their inefficiency in learning with class-imbalanced data sets. We introduce a hierarchical categorization of SVM-based models with respect to class-imbalanced learning. Specifically, we categorize SVM-based models into re-sampling, algorithmic, and fusion methods, and discuss the principles of the representative models in each category. In addition, we conduct a series of empirical evaluations to compare the performances of various representative SVM-based models in each category using benchmark imbalanced data sets, ranging from low to high imbalanced ratios. Our findings reveal that while algorithmic methods are less time-consuming owing to no data pre-processing requirements, fusion methods, which combine both re-sampling and algorithmic approaches, generally perform the best, but with a higher computational load. A discussion on research gaps and future research directions is provided.","sentences":["This paper presents a review on methods for class-imbalanced learning with the Support Vector Machine (SVM) and its variants.","We first explain the structure of SVM and its variants and discuss their inefficiency in learning with class-imbalanced data sets.","We introduce a hierarchical categorization of SVM-based models with respect to class-imbalanced learning.","Specifically, we categorize SVM-based models into re-sampling, algorithmic, and fusion methods, and discuss the principles of the representative models in each category.","In addition, we conduct a series of empirical evaluations to compare the performances of various representative SVM-based models in each category using benchmark imbalanced data sets, ranging from low to high imbalanced ratios.","Our findings reveal that while algorithmic methods are less time-consuming owing to no data pre-processing requirements, fusion methods, which combine both re-sampling and algorithmic approaches, generally perform the best, but with a higher computational load.","A discussion on research gaps and future research directions is provided."],"url":"http://arxiv.org/abs/2406.03398v1"}
{"created":"2024-06-05 15:54:50","title":"Automating Turkish Educational Quiz Generation Using Large Language Models","abstract":"Crafting quizzes from educational content is a pivotal activity that benefits both teachers and students by reinforcing learning and evaluating understanding. In this study, we introduce a novel approach to generate quizzes from Turkish educational texts, marking a pioneering endeavor in educational technology specifically tailored to the Turkish educational context. We present a specialized dataset, named the Turkish-Quiz-Instruct, comprising an extensive collection of Turkish educational texts accompanied by multiple-choice and short-answer quizzes. This research leverages the capabilities of Large Language Models (LLMs), including GPT-4-Turbo, GPT-3.5-Turbo, Llama-2-7b-chat-hf, and Llama-2-13b-chat-hf, to automatically generate quiz questions and answers from the Turkish educational content. Our work delineates the methodology for employing these LLMs in the context of Turkish educational material, thereby opening new avenues for automated Turkish quiz generation. The study not only demonstrates the efficacy of using such models for generating coherent and relevant quiz content but also sets a precedent for future research in the domain of automated educational content creation for languages other than English. The Turkish-Quiz-Instruct dataset is introduced as a valuable resource for researchers and practitioners aiming to explore the boundaries of educational technology and language-specific applications of LLMs in Turkish. By addressing the challenges of quiz generation in a non-English context specifically Turkish, this study contributes significantly to the field of Turkish educational technology, providing insights into the potential of leveraging LLMs for educational purposes across diverse linguistic landscapes.","sentences":["Crafting quizzes from educational content is a pivotal activity that benefits both teachers and students by reinforcing learning and evaluating understanding.","In this study, we introduce a novel approach to generate quizzes from Turkish educational texts, marking a pioneering endeavor in educational technology specifically tailored to the Turkish educational context.","We present a specialized dataset, named the Turkish-Quiz-Instruct, comprising an extensive collection of Turkish educational texts accompanied by multiple-choice and short-answer quizzes.","This research leverages the capabilities of Large Language Models (LLMs), including GPT-4-Turbo, GPT-3.5-Turbo, Llama-2-7b-chat-hf, and Llama-2-13b-chat-hf, to automatically generate quiz questions and answers from the Turkish educational content.","Our work delineates the methodology for employing these LLMs in the context of Turkish educational material, thereby opening new avenues for automated Turkish quiz generation.","The study not only demonstrates the efficacy of using such models for generating coherent and relevant quiz content but also sets a precedent for future research in the domain of automated educational content creation for languages other than English.","The Turkish-Quiz-Instruct dataset is introduced as a valuable resource for researchers and practitioners aiming to explore the boundaries of educational technology and language-specific applications of LLMs in Turkish.","By addressing the challenges of quiz generation in a non-English context specifically Turkish, this study contributes significantly to the field of Turkish educational technology, providing insights into the potential of leveraging LLMs for educational purposes across diverse linguistic landscapes."],"url":"http://arxiv.org/abs/2406.03397v1"}
{"created":"2024-06-05 15:53:25","title":"Noisy Data Visualization using Functional Data Analysis","abstract":"Data visualization via dimensionality reduction is an important tool in exploratory data analysis. However, when the data are noisy, many existing methods fail to capture the underlying structure of the data. The method called Empirical Intrinsic Geometry (EIG) was previously proposed for performing dimensionality reduction on high dimensional dynamical processes while theoretically eliminating all noise. However, implementing EIG in practice requires the construction of high-dimensional histograms, which suffer from the curse of dimensionality. Here we propose a new data visualization method called Functional Information Geometry (FIG) for dynamical processes that adapts the EIG framework while using approaches from functional data analysis to mitigate the curse of dimensionality. We experimentally demonstrate that the resulting method outperforms a variant of EIG designed for visualization in terms of capturing the true structure, hyperparameter robustness, and computational speed. We then use our method to visualize EEG brain measurements of sleep activity.","sentences":["Data visualization via dimensionality reduction is an important tool in exploratory data analysis.","However, when the data are noisy, many existing methods fail to capture the underlying structure of the data.","The method called Empirical Intrinsic Geometry (EIG) was previously proposed for performing dimensionality reduction on high dimensional dynamical processes while theoretically eliminating all noise.","However, implementing EIG in practice requires the construction of high-dimensional histograms, which suffer from the curse of dimensionality.","Here we propose a new data visualization method called Functional Information Geometry (FIG) for dynamical processes that adapts the EIG framework while using approaches from functional data analysis to mitigate the curse of dimensionality.","We experimentally demonstrate that the resulting method outperforms a variant of EIG designed for visualization in terms of capturing the true structure, hyperparameter robustness, and computational speed.","We then use our method to visualize EEG brain measurements of sleep activity."],"url":"http://arxiv.org/abs/2406.03396v1"}
{"created":"2024-06-05 15:44:54","title":"Gaussian Representation for Deformable Image Registration","abstract":"Deformable image registration (DIR) is a fundamental task in radiotherapy, with existing methods often struggling to balance computational efficiency, registration accuracy, and speed effectively. We introduce a novel DIR approach employing parametric 3D Gaussian control points achieving a better tradeoff. It provides an explicit and flexible representation for spatial deformation fields between 3D volumetric medical images, producing a displacement vector field (DVF) across all volumetric positions. The movement of individual voxels is derived using linear blend skinning (LBS) through localized interpolation of transformations associated with neighboring Gaussians. This interpolation strategy not only simplifies the determination of voxel motions but also acts as an effective regularization technique. Our approach incorporates a unified optimization process through backpropagation, enabling iterative learning of both the parameters of the 3D Gaussians and their transformations. Additionally, the density of Gaussians is adjusted adaptively during the learning phase to accommodate varying degrees of motion complexity. We validated our approach on the 4D-CT lung DIR-Lab and cardiac ACDC datasets, achieving an average target registration error (TRE) of 1.06 mm within a much-improved processing time of 2.43 seconds for the DIR-Lab dataset over existing methods, demonstrating significant advancements in both accuracy and efficiency.","sentences":["Deformable image registration (DIR) is a fundamental task in radiotherapy, with existing methods often struggling to balance computational efficiency, registration accuracy, and speed effectively.","We introduce a novel DIR approach employing parametric 3D Gaussian control points achieving a better tradeoff.","It provides an explicit and flexible representation for spatial deformation fields between 3D volumetric medical images, producing a displacement vector field (DVF) across all volumetric positions.","The movement of individual voxels is derived using linear blend skinning (LBS) through localized interpolation of transformations associated with neighboring Gaussians.","This interpolation strategy not only simplifies the determination of voxel motions but also acts as an effective regularization technique.","Our approach incorporates a unified optimization process through backpropagation, enabling iterative learning of both the parameters of the 3D Gaussians and their transformations.","Additionally, the density of Gaussians is adjusted adaptively during the learning phase to accommodate varying degrees of motion complexity.","We validated our approach on the 4D-CT lung DIR-Lab and cardiac ACDC datasets, achieving an average target registration error (TRE) of 1.06 mm within a much-improved processing time of 2.43 seconds for the DIR-Lab dataset over existing methods, demonstrating significant advancements in both accuracy and efficiency."],"url":"http://arxiv.org/abs/2406.03394v1"}
{"created":"2024-06-05 15:41:02","title":"Author, Content or Sharers? Estimating Spread Dynamics with Bayesian Mixture Hawkes","abstract":"The spread of content on social media is shaped by intertwining factors on three levels: the source, the content itself, and the pathways of content spread. At the lowest level, the popularity of the sharing user determines its eventual reach. However, higher-level factors such as the nature of the online item and the credibility of its source also play crucial roles in determining how widely and rapidly the online item spreads. In this work, we propose the Bayesian Mixture Hawkes (BMH) model to jointly learn the influence of source, content and spread. We formulate the BMH model as a hierarchical mixture model of separable Hawkes processes, accommodating different classes of Hawkes dynamics and the influence of feature sets on these classes. We test the BMH model on two learning tasks, cold-start popularity prediction and temporal profile generalization performance, applying to two real-world retweet cascade datasets referencing articles from controversial and traditional media publishers. The BMH model outperforms the state-of-the-art models and predictive baselines on both datasets and utilizes cascade- and item-level information better than the alternatives. Lastly, we perform a counter-factual analysis where we apply the trained publisher-level BMH models to a set of article headlines and show that effectiveness of headline writing style (neutral, clickbait, inflammatory) varies across publishers. The BMH model unveils differences in style effectiveness between controversial and reputable publishers, where we find clickbait to be notably more effective for reputable publishers as opposed to controversial ones, which links to the latter's overuse of clickbait.","sentences":["The spread of content on social media is shaped by intertwining factors on three levels: the source, the content itself, and the pathways of content spread.","At the lowest level, the popularity of the sharing user determines its eventual reach.","However, higher-level factors such as the nature of the online item and the credibility of its source also play crucial roles in determining how widely and rapidly the online item spreads.","In this work, we propose the Bayesian Mixture Hawkes (BMH) model to jointly learn the influence of source, content and spread.","We formulate the BMH model as a hierarchical mixture model of separable Hawkes processes, accommodating different classes of Hawkes dynamics and the influence of feature sets on these classes.","We test the BMH model on two learning tasks, cold-start popularity prediction and temporal profile generalization performance, applying to two real-world retweet cascade datasets referencing articles from controversial and traditional media publishers.","The BMH model outperforms the state-of-the-art models and predictive baselines on both datasets and utilizes cascade- and item-level information better than the alternatives.","Lastly, we perform a counter-factual analysis where we apply the trained publisher-level BMH models to a set of article headlines and show that effectiveness of headline writing style (neutral, clickbait, inflammatory) varies across publishers.","The BMH model unveils differences in style effectiveness between controversial and reputable publishers, where we find clickbait to be notably more effective for reputable publishers as opposed to controversial ones, which links to the latter's overuse of clickbait."],"url":"http://arxiv.org/abs/2406.03390v1"}
{"created":"2024-06-05 15:38:02","title":"SelfReDepth: Self-Supervised Real-Time Depth Restoration for Consumer-Grade Sensors","abstract":"Depth maps produced by consumer-grade sensors suffer from inaccurate measurements and missing data from either system or scene-specific sources. Data-driven denoising algorithms can mitigate such problems. However, they require vast amounts of ground truth depth data. Recent research has tackled this limitation using self-supervised learning techniques, but it requires multiple RGB-D sensors. Moreover, most existing approaches focus on denoising single isolated depth maps or specific subjects of interest, highlighting a need for methods to effectively denoise depth maps in real-time dynamic environments. This paper extends state-of-the-art approaches for depth-denoising commodity depth devices, proposing SelfReDepth, a self-supervised deep learning technique for depth restoration, via denoising and hole-filling by inpainting full-depth maps captured with RGB-D sensors. The algorithm targets depth data in video streams, utilizing multiple sequential depth frames coupled with color data to achieve high-quality depth videos with temporal coherence. Finally, SelfReDepth is designed to be compatible with various RGB-D sensors and usable in real-time scenarios as a pre-processing step before applying other depth-dependent algorithms. Our results demonstrate our approach's real-time performance on real-world datasets. They show that it outperforms state-of-the-art denoising and restoration performance at over 30fps on Commercial Depth Cameras, with potential benefits for augmented and mixed-reality applications.","sentences":["Depth maps produced by consumer-grade sensors suffer from inaccurate measurements and missing data from either system or scene-specific sources.","Data-driven denoising algorithms can mitigate such problems.","However, they require vast amounts of ground truth depth data.","Recent research has tackled this limitation using self-supervised learning techniques, but it requires multiple RGB-D sensors.","Moreover, most existing approaches focus on denoising single isolated depth maps or specific subjects of interest, highlighting a need for methods to effectively denoise depth maps in real-time dynamic environments.","This paper extends state-of-the-art approaches for depth-denoising commodity depth devices, proposing SelfReDepth, a self-supervised deep learning technique for depth restoration, via denoising and hole-filling by inpainting full-depth maps captured with RGB-D sensors.","The algorithm targets depth data in video streams, utilizing multiple sequential depth frames coupled with color data to achieve high-quality depth videos with temporal coherence.","Finally, SelfReDepth is designed to be compatible with various RGB-D sensors and usable in real-time scenarios as a pre-processing step before applying other depth-dependent algorithms.","Our results demonstrate our approach's real-time performance on real-world datasets.","They show that it outperforms state-of-the-art denoising and restoration performance at over 30fps on Commercial Depth Cameras, with potential benefits for augmented and mixed-reality applications."],"url":"http://arxiv.org/abs/2406.03388v1"}
{"created":"2024-06-05 15:36:57","title":"Learning Long Range Dependencies on Graphs via Random Walks","abstract":"Message-passing graph neural networks (GNNs), while excelling at capturing local relationships, often struggle with long-range dependencies on graphs. Conversely, graph transformers (GTs) enable information exchange between all nodes but oversimplify the graph structure by treating them as a set of fixed-length vectors. This work proposes a novel architecture, NeuralWalker, that overcomes the limitations of both methods by combining random walks with message passing. NeuralWalker achieves this by treating random walks as sequences, allowing for the application of recent advances in sequence models in order to capture long-range dependencies within these walks. Based on this concept, we propose a framework that offers (1) more expressive graph representations through random walk sequences, (2) the ability to utilize any sequence model for capturing long-range dependencies, and (3) the flexibility by integrating various GNN and GT architectures. Our experimental evaluations demonstrate that NeuralWalker achieves significant performance improvements on 19 graph and node benchmark datasets, notably outperforming existing methods by up to 13% on the PascalVoc-SP and COCO-SP datasets. Code is available at https://github.com/BorgwardtLab/NeuralWalker.","sentences":["Message-passing graph neural networks (GNNs), while excelling at capturing local relationships, often struggle with long-range dependencies on graphs.","Conversely, graph transformers (GTs) enable information exchange between all nodes but oversimplify the graph structure by treating them as a set of fixed-length vectors.","This work proposes a novel architecture, NeuralWalker, that overcomes the limitations of both methods by combining random walks with message passing.","NeuralWalker achieves this by treating random walks as sequences, allowing for the application of recent advances in sequence models in order to capture long-range dependencies within these walks.","Based on this concept, we propose a framework that offers (1) more expressive graph representations through random walk sequences, (2) the ability to utilize any sequence model for capturing long-range dependencies, and (3) the flexibility by integrating various GNN and GT architectures.","Our experimental evaluations demonstrate that NeuralWalker achieves significant performance improvements on 19 graph and node benchmark datasets, notably outperforming existing methods by up to 13% on the PascalVoc-SP and COCO-SP datasets.","Code is available at https://github.com/BorgwardtLab/NeuralWalker."],"url":"http://arxiv.org/abs/2406.03386v1"}
{"created":"2024-06-05 15:31:43","title":"Log Parsing with Self-Generated In-Context Learning and Self-Correction","abstract":"Log parsing transforms log messages into structured formats, serving as a crucial step for log analysis. Despite a variety of log parsing methods that have been proposed, their performance on evolving log data remains unsatisfactory due to reliance on human-crafted rules or learning-based models with limited training data. The recent emergence of large language models (LLMs) has demonstrated strong abilities in understanding natural language and code, making it promising to apply LLMs for log parsing. Consequently, several studies have proposed LLM-based log parsers. However, LLMs may produce inaccurate templates, and existing LLM-based log parsers directly use the template generated by the LLM as the parsing result, hindering the accuracy of log parsing. Furthermore, these log parsers depend heavily on historical log data as demonstrations, which poses challenges in maintaining accuracy when dealing with scarce historical log data or evolving log data. To address these challenges, we propose AdaParser, an effective and adaptive log parsing framework using LLMs with self-generated in-context learning (SG-ICL) and self-correction. To facilitate accurate log parsing, AdaParser incorporates a novel component, a template corrector, which utilizes the LLM to correct potential parsing errors in the templates it generates. In addition, AdaParser maintains a dynamic candidate set composed of previously generated templates as demonstrations to adapt evolving log data. Extensive experiments on public large-scale datasets show that AdaParser outperforms state-of-the-art methods across all metrics, even in zero-shot scenarios. Moreover, when integrated with different LLMs, AdaParser consistently enhances the performance of the utilized LLMs by a large margin.","sentences":["Log parsing transforms log messages into structured formats, serving as a crucial step for log analysis.","Despite a variety of log parsing methods that have been proposed, their performance on evolving log data remains unsatisfactory due to reliance on human-crafted rules or learning-based models with limited training data.","The recent emergence of large language models (LLMs) has demonstrated strong abilities in understanding natural language and code, making it promising to apply LLMs for log parsing.","Consequently, several studies have proposed LLM-based log parsers.","However, LLMs may produce inaccurate templates, and existing LLM-based log parsers directly use the template generated by the LLM as the parsing result, hindering the accuracy of log parsing.","Furthermore, these log parsers depend heavily on historical log data as demonstrations, which poses challenges in maintaining accuracy when dealing with scarce historical log data or evolving log data.","To address these challenges, we propose AdaParser, an effective and adaptive log parsing framework using LLMs with self-generated in-context learning (SG-ICL) and self-correction.","To facilitate accurate log parsing, AdaParser incorporates a novel component, a template corrector, which utilizes the LLM to correct potential parsing errors in the templates it generates.","In addition, AdaParser maintains a dynamic candidate set composed of previously generated templates as demonstrations to adapt evolving log data.","Extensive experiments on public large-scale datasets show that AdaParser outperforms state-of-the-art methods across all metrics, even in zero-shot scenarios.","Moreover, when integrated with different LLMs, AdaParser consistently enhances the performance of the utilized LLMs by a large margin."],"url":"http://arxiv.org/abs/2406.03376v1"}
{"created":"2024-06-05 15:30:56","title":"A discrete dislocation analysis of size-dependent plasticity in torsion","abstract":"A method for solving three dimensional discrete dislocation plasticity boundary-value problems using a monopole representation of the dislocations is presented. At each time step, the displacement, strain and stress fields in a finite body are obtained by superposition of infinite body dislocation fields and an image field that enforces the boundary conditions. The three dimensional infinite body fields are obtained by representing dislocations as being comprised of points, termed monopoles, that carry dislocation line and Burgers vector information. The image fields are obtained from a three dimensional linear elastic finite element calculation. The implementation of the coupling of the monopole representation with the finite element method, including the interaction of curved dislocations with free surfaces, is presented in some detail because it differs significantly from an implementation with a line based dislocation representation. Numerical convergence and the modeling of dislocation loop nucleation for large scale computations are investigated. The monopole discrete dislocation plasticity framework is used to investigate the effect of size and initial dislocation density on the torsion of wires with diameters varying over three orders of magnitude. Depending on the initial dislocation source density and the wire diameter, three regimes of torsion-twist response are obtained: (i) for wires with a sufficiently small diameter, plastic deformation is nucleation controlled and is strongly size dependent; (ii) for wires with larger diameters dislocation plasticity is dislocation interaction controlled, with the emergence of geometrically necessary dislocations and dislocation pile-ups playing a key role, and is strongly size dependent; and (iii) for wires with sufficiently large diameters plastic deformation becomes less heterogeneous and the dependence on size is greatly diminished.","sentences":["A method for solving three dimensional discrete dislocation plasticity boundary-value problems using a monopole representation of the dislocations is presented.","At each time step, the displacement, strain and stress fields in a finite body are obtained by superposition of infinite body dislocation fields and an image field that enforces the boundary conditions.","The three dimensional infinite body fields are obtained by representing dislocations as being comprised of points, termed monopoles, that carry dislocation line and Burgers vector information.","The image fields are obtained from a three dimensional linear elastic finite element calculation.","The implementation of the coupling of the monopole representation with the finite element method, including the interaction of curved dislocations with free surfaces, is presented in some detail because it differs significantly from an implementation with a line based dislocation representation.","Numerical convergence and the modeling of dislocation loop nucleation for large scale computations are investigated.","The monopole discrete dislocation plasticity framework is used to investigate the effect of size and initial dislocation density on the torsion of wires with diameters varying over three orders of magnitude.","Depending on the initial dislocation source density and the wire diameter, three regimes of torsion-twist response are obtained: (i) for wires with a sufficiently small diameter, plastic deformation is nucleation controlled and is strongly size dependent; (ii) for wires with larger diameters dislocation plasticity is dislocation interaction controlled, with the emergence of geometrically necessary dislocations and dislocation pile-ups playing a key role, and is strongly size dependent; and (iii) for wires with sufficiently large diameters plastic deformation becomes less heterogeneous and the dependence on size is greatly diminished."],"url":"http://arxiv.org/abs/2406.03375v1"}
{"created":"2024-06-05 15:23:08","title":"IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models","abstract":"Despite the widespread adoption of Large language models (LLMs), their remarkable capabilities remain limited to a few high-resource languages. Additionally, many low-resource languages (e.g. African languages) are often evaluated only on basic text classification tasks due to the lack of appropriate or comprehensive benchmarks outside of high-resource languages. In this paper, we introduce IrokoBench -- a human-translated benchmark dataset for 16 typologically-diverse low-resource African languages covering three tasks: natural language inference~(AfriXNLI), mathematical reasoning~(AfriMGSM), and multi-choice knowledge-based QA~(AfriMMLU). We use IrokoBench to evaluate zero-shot, few-shot, and translate-test settings~(where test sets are translated into English) across 10 open and four proprietary LLMs. Our evaluation reveals a significant performance gap between high-resource languages~(such as English and French) and low-resource African languages. We observe a significant performance gap between open and proprietary models, with the highest performing open model, Aya-101 only at 58\\% of the best-performing proprietary model GPT-4o performance. Machine translating the test set to English before evaluation helped to close the gap for larger models that are English-centric, like LLaMa 3 70B. These findings suggest that more efforts are needed to develop and adapt LLMs for African languages.","sentences":["Despite the widespread adoption of Large language models (LLMs), their remarkable capabilities remain limited to a few high-resource languages.","Additionally, many low-resource languages (e.g. African languages) are often evaluated only on basic text classification tasks due to the lack of appropriate or comprehensive benchmarks outside of high-resource languages.","In this paper, we introduce IrokoBench -- a human-translated benchmark dataset for 16 typologically-diverse low-resource African languages covering three tasks: natural language inference~(AfriXNLI), mathematical reasoning~(AfriMGSM), and multi-choice knowledge-based QA~(AfriMMLU).","We use IrokoBench to evaluate zero-shot, few-shot, and translate-test settings~(where test sets are translated into English) across 10 open and four proprietary LLMs.","Our evaluation reveals a significant performance gap between high-resource languages~(such as English and French) and low-resource African languages.","We observe a significant performance gap between open and proprietary models, with the highest performing open model, Aya-101 only at 58\\% of the best-performing proprietary model GPT-4o performance.","Machine translating the test set to English before evaluation helped to close the gap for larger models that are English-centric, like LLaMa 3 70B. These findings suggest that more efforts are needed to develop and adapt LLMs for African languages."],"url":"http://arxiv.org/abs/2406.03368v1"}
{"created":"2024-06-05 15:21:44","title":"CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning","abstract":"Large Language Models (LLMs) possess extensive foundational knowledge and moderate reasoning abilities, making them suitable for general task planning in open-world scenarios. However, it is challenging to ground a LLM-generated plan to be executable for the specified robot with certain restrictions. This paper introduces CLMASP, an approach that couples LLMs with Answer Set Programming (ASP) to overcome the limitations, where ASP is a non-monotonic logic programming formalism renowned for its capacity to represent and reason about a robot's action knowledge. CLMASP initiates with a LLM generating a basic skeleton plan, which is subsequently tailored to the specific scenario using a vector database. This plan is then refined by an ASP program with a robot's action knowledge, which integrates implementation details into the skeleton, grounding the LLM's abstract outputs in practical robot contexts. Our experiments conducted on the VirtualHome platform demonstrate CLMASP's efficacy. Compared to the baseline executable rate of under 2% with LLM approaches, CLMASP significantly improves this to over 90%.","sentences":["Large Language Models (LLMs) possess extensive foundational knowledge and moderate reasoning abilities, making them suitable for general task planning in open-world scenarios.","However, it is challenging to ground a LLM-generated plan to be executable for the specified robot with certain restrictions.","This paper introduces CLMASP, an approach that couples LLMs with Answer Set Programming (ASP) to overcome the limitations, where ASP is a non-monotonic logic programming formalism renowned for its capacity to represent and reason about a robot's action knowledge.","CLMASP initiates with a LLM generating a basic skeleton plan, which is subsequently tailored to the specific scenario using a vector database.","This plan is then refined by an ASP program with a robot's action knowledge, which integrates implementation details into the skeleton, grounding the LLM's abstract outputs in practical robot contexts.","Our experiments conducted on the VirtualHome platform demonstrate CLMASP's efficacy.","Compared to the baseline executable rate of under 2% with LLM approaches, CLMASP significantly improves this to over 90%."],"url":"http://arxiv.org/abs/2406.03367v1"}
{"created":"2024-06-05 15:18:08","title":"LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback","abstract":"Ensuring that online discussions are civil and productive is a major challenge for social media platforms. Such platforms usually rely both on users and on automated detection tools to flag inappropriate arguments of other users, which moderators then review. However, this kind of post-hoc moderation is expensive and time-consuming, and moderators are often overwhelmed by the amount and severity of flagged content. Instead, a promising alternative is to prevent negative behavior during content creation. This paper studies how inappropriate language in arguments can be computationally mitigated. We propose a reinforcement learning-based rewriting approach that balances content preservation and appropriateness based on existing classifiers, prompting an instruction-finetuned large language model (LLM) as our initial policy. Unlike related style transfer tasks, rewriting inappropriate arguments allows deleting and adding content permanently. It is therefore tackled on document level rather than sentence level. We evaluate different weighting schemes for the reward function in both absolute and relative human assessment studies. Systematic experiments on non-parallel data provide evidence that our approach can mitigate the inappropriateness of arguments while largely preserving their content. It significantly outperforms competitive baselines, including few-shot learning, prompting, and humans.","sentences":["Ensuring that online discussions are civil and productive is a major challenge for social media platforms.","Such platforms usually rely both on users and on automated detection tools to flag inappropriate arguments of other users, which moderators then review.","However, this kind of post-hoc moderation is expensive and time-consuming, and moderators are often overwhelmed by the amount and severity of flagged content.","Instead, a promising alternative is to prevent negative behavior during content creation.","This paper studies how inappropriate language in arguments can be computationally mitigated.","We propose a reinforcement learning-based rewriting approach that balances content preservation and appropriateness based on existing classifiers, prompting an instruction-finetuned large language model (LLM) as our initial policy.","Unlike related style transfer tasks, rewriting inappropriate arguments allows deleting and adding content permanently.","It is therefore tackled on document level rather than sentence level.","We evaluate different weighting schemes for the reward function in both absolute and relative human assessment studies.","Systematic experiments on non-parallel data provide evidence that our approach can mitigate the inappropriateness of arguments while largely preserving their content.","It significantly outperforms competitive baselines, including few-shot learning, prompting, and humans."],"url":"http://arxiv.org/abs/2406.03363v1"}
{"created":"2024-06-05 15:14:58","title":"What Matters in Hierarchical Search for Combinatorial Reasoning Problems?","abstract":"Efficiently tackling combinatorial reasoning problems, particularly the notorious NP-hard tasks, remains a significant challenge for AI research. Recent efforts have sought to enhance planning by incorporating hierarchical high-level search strategies, known as subgoal methods. While promising, their performance against traditional low-level planners is inconsistent, raising questions about their application contexts. In this study, we conduct an in-depth exploration of subgoal-planning methods for combinatorial reasoning. We identify the attributes pivotal for leveraging the advantages of high-level search: hard-to-learn value functions, complex action spaces, presence of dead ends in the environment, or using data collected from diverse experts. We propose a consistent evaluation methodology to achieve meaningful comparisons between methods and reevaluate the state-of-the-art algorithms.","sentences":["Efficiently tackling combinatorial reasoning problems, particularly the notorious NP-hard tasks, remains a significant challenge for AI research.","Recent efforts have sought to enhance planning by incorporating hierarchical high-level search strategies, known as subgoal methods.","While promising, their performance against traditional low-level planners is inconsistent, raising questions about their application contexts.","In this study, we conduct an in-depth exploration of subgoal-planning methods for combinatorial reasoning.","We identify the attributes pivotal for leveraging the advantages of high-level search: hard-to-learn value functions, complex action spaces, presence of dead ends in the environment, or using data collected from diverse experts.","We propose a consistent evaluation methodology to achieve meaningful comparisons between methods and reevaluate the state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2406.03361v1"}
{"created":"2024-06-05 15:12:29","title":"Cooperative learning of Pl@ntNet's Artificial Intelligence algorithm: how does it work and how can we improve it?","abstract":"Deep learning models for plant species identification rely on large annotated datasets. The PlantNet system enables global data collection by allowing users to upload and annotate plant observations, leading to noisy labels due to diverse user skills. Achieving consensus is crucial for training, but the vast scale of collected data makes traditional label aggregation strategies challenging. Existing methods either retain all observations, resulting in noisy training data or selectively keep those with sufficient votes, discarding valuable information. Additionally, as many species are rarely observed, user expertise can not be evaluated as an inter-user agreement: otherwise, botanical experts would have a lower weight in the AI training step than the average user. Our proposed label aggregation strategy aims to cooperatively train plant identification AI models. This strategy estimates user expertise as a trust score per user based on their ability to identify plant species from crowdsourced data. The trust score is recursively estimated from correctly identified species given the current estimated labels. This interpretable score exploits botanical experts' knowledge and the heterogeneity of users. Subsequently, our strategy removes unreliable observations but retains those with limited trusted annotations, unlike other approaches. We evaluate PlantNet's strategy on a released large subset of the PlantNet database focused on European flora, comprising over 6M observations and 800K users. We demonstrate that estimating users' skills based on the diversity of their expertise enhances labeling performance. Our findings emphasize the synergy of human annotation and data filtering in improving AI performance for a refined dataset. We explore incorporating AI-based votes alongside human input. This can further enhance human-AI interactions to detect unreliable observations.","sentences":["Deep learning models for plant species identification rely on large annotated datasets.","The PlantNet system enables global data collection by allowing users to upload and annotate plant observations, leading to noisy labels due to diverse user skills.","Achieving consensus is crucial for training, but the vast scale of collected data makes traditional label aggregation strategies challenging.","Existing methods either retain all observations, resulting in noisy training data or selectively keep those with sufficient votes, discarding valuable information.","Additionally, as many species are rarely observed, user expertise can not be evaluated as an inter-user agreement: otherwise, botanical experts would have a lower weight in the AI training step than the average user.","Our proposed label aggregation strategy aims to cooperatively train plant identification AI models.","This strategy estimates user expertise as a trust score per user based on their ability to identify plant species from crowdsourced data.","The trust score is recursively estimated from correctly identified species given the current estimated labels.","This interpretable score exploits botanical experts' knowledge and the heterogeneity of users.","Subsequently, our strategy removes unreliable observations but retains those with limited trusted annotations, unlike other approaches.","We evaluate PlantNet's strategy on a released large subset of the PlantNet database focused on European flora, comprising over 6M observations and 800K users.","We demonstrate that estimating users' skills based on the diversity of their expertise enhances labeling performance.","Our findings emphasize the synergy of human annotation and data filtering in improving AI performance for a refined dataset.","We explore incorporating AI-based votes alongside human input.","This can further enhance human-AI interactions to detect unreliable observations."],"url":"http://arxiv.org/abs/2406.03356v1"}
{"created":"2024-06-05 15:10:29","title":"Can Social Media Platforms Transcend Political Labels? An Analysis of Neutral Conservations on Truth Social","abstract":"There is a prevailing perception that content on a social media platform generally have the same political leaning. These platforms are often viewed as ideologically congruent entities, reflecting the majority opinion of their users; a prime example of this is Truth Social. While this perception may exist, it is essential to verify the platform's credibility, acknowledging that such platforms contain meaningful insights with neutral stances. To this end, we examine the dissemination of Wikipedia links on the alt-right platform, Truth Social. Wikipedia is recognized for enforcing content neutrality and serves as a unique lens to analyze the objectivity of user-generated content on Truth Social. By scrutinizing Truths with and without Wikipedia links, identifying toxicity trends & recognizing coordinated networks, we observe a lower level of engagement and a tendency for Truths shared on Truth Social to cover more neutral topics when it includes Wikipedia links (Wiki Truths). Given the significantly different engagement and nature of content shared of Wiki Truths against Non-Wiki Truths, we emphasize that we should not generalize the techno-political affiliation of a social media platform, but rather should investigate the content closely.","sentences":["There is a prevailing perception that content on a social media platform generally have the same political leaning.","These platforms are often viewed as ideologically congruent entities, reflecting the majority opinion of their users; a prime example of this is Truth Social.","While this perception may exist, it is essential to verify the platform's credibility, acknowledging that such platforms contain meaningful insights with neutral stances.","To this end, we examine the dissemination of Wikipedia links on the alt-right platform, Truth Social.","Wikipedia is recognized for enforcing content neutrality and serves as a unique lens to analyze the objectivity of user-generated content on Truth Social.","By scrutinizing Truths with and without Wikipedia links, identifying toxicity trends & recognizing coordinated networks, we observe a lower level of engagement and a tendency for Truths shared on Truth Social to cover more neutral topics when it includes Wikipedia links (Wiki Truths).","Given the significantly different engagement and nature of content shared of Wiki Truths against Non-Wiki Truths, we emphasize that we should not generalize the techno-political affiliation of a social media platform, but rather should investigate the content closely."],"url":"http://arxiv.org/abs/2406.03354v1"}
{"created":"2024-06-05 15:05:24","title":"Position: A Call to Action for a Human-Centered AutoML Paradigm","abstract":"Automated machine learning (AutoML) was formed around the fundamental objectives of automatically and efficiently configuring machine learning (ML) workflows, aiding the research of new ML algorithms, and contributing to the democratization of ML by making it accessible to a broader audience. Over the past decade, commendable achievements in AutoML have primarily focused on optimizing predictive performance. This focused progress, while substantial, raises questions about how well AutoML has met its broader, original goals. In this position paper, we argue that a key to unlocking AutoML's full potential lies in addressing the currently underexplored aspect of user interaction with AutoML systems, including their diverse roles, expectations, and expertise. We envision a more human-centered approach in future AutoML research, promoting the collaborative design of ML systems that tightly integrates the complementary strengths of human expertise and AutoML methodologies.","sentences":["Automated machine learning (AutoML) was formed around the fundamental objectives of automatically and efficiently configuring machine learning (ML) workflows, aiding the research of new ML algorithms, and contributing to the democratization of ML by making it accessible to a broader audience.","Over the past decade, commendable achievements in AutoML have primarily focused on optimizing predictive performance.","This focused progress, while substantial, raises questions about how well AutoML has met its broader, original goals.","In this position paper, we argue that a key to unlocking AutoML's full potential lies in addressing the currently underexplored aspect of user interaction with AutoML systems, including their diverse roles, expectations, and expertise.","We envision a more human-centered approach in future AutoML research, promoting the collaborative design of ML systems that tightly integrates the complementary strengths of human expertise and AutoML methodologies."],"url":"http://arxiv.org/abs/2406.03348v1"}
{"created":"2024-06-05 15:04:28","title":"Normalizing Flows for Conformal Regression","abstract":"Conformal Prediction (CP) algorithms estimate the uncertainty of a prediction model by calibrating its outputs on labeled data. The same calibration scheme usually applies to any model and data without modifications. The obtained prediction intervals are valid by construction but could be inefficient, i.e. unnecessarily big, if the prediction errors are not uniformly distributed over the input space.   We present a general scheme to localize the intervals by training the calibration process. The standard prediction error is replaced by an optimized distance metric that depends explicitly on the object attributes. Learning the optimal metric is equivalent to training a Normalizing Flow that acts on the joint distribution of the errors and the inputs. Unlike the Error Re-weighting CP algorithm of Papadopoulos et al. (2008), the framework allows estimating the gap between nominal and empirical conditional validity. The approach is compatible with existing locally-adaptive CP strategies based on re-weighting the calibration samples and applies to any point-prediction model without retraining.","sentences":["Conformal Prediction (CP) algorithms estimate the uncertainty of a prediction model by calibrating its outputs on labeled data.","The same calibration scheme usually applies to any model and data without modifications.","The obtained prediction intervals are valid by construction but could be inefficient, i.e. unnecessarily big, if the prediction errors are not uniformly distributed over the input space.   ","We present a general scheme to localize the intervals by training the calibration process.","The standard prediction error is replaced by an optimized distance metric that depends explicitly on the object attributes.","Learning the optimal metric is equivalent to training a Normalizing Flow that acts on the joint distribution of the errors and the inputs.","Unlike the Error Re-weighting CP algorithm of Papadopoulos et al. (2008), the framework allows estimating the gap between nominal and empirical conditional validity.","The approach is compatible with existing locally-adaptive CP strategies based on re-weighting the calibration samples and applies to any point-prediction model without retraining."],"url":"http://arxiv.org/abs/2406.03346v1"}
{"created":"2024-06-05 15:04:27","title":"Feature Contamination: Neural Networks Learn Uncorrelated Features and Fail to Generalize","abstract":"Learning representations that generalize under distribution shifts is critical for building robust machine learning models. However, despite significant efforts in recent years, algorithmic advances in this direction have been limited. In this work, we seek to understand the fundamental difficulty of out-of-distribution generalization with deep neural networks. We first empirically show that perhaps surprisingly, even allowing a neural network to explicitly fit the representations obtained from a teacher network that can generalize out-of-distribution is insufficient for the generalization of the student network. Then, by a theoretical study of two-layer ReLU networks optimized by stochastic gradient descent (SGD) under a structured feature model, we identify a fundamental yet unexplored feature learning proclivity of neural networks, feature contamination: neural networks can learn uncorrelated features together with predictive features, resulting in generalization failure under distribution shifts. Notably, this mechanism essentially differs from the prevailing narrative in the literature that attributes the generalization failure to spurious correlations. Overall, our results offer new insights into the non-linear feature learning dynamics of neural networks and highlight the necessity of considering inductive biases in out-of-distribution generalization.","sentences":["Learning representations that generalize under distribution shifts is critical for building robust machine learning models.","However, despite significant efforts in recent years, algorithmic advances in this direction have been limited.","In this work, we seek to understand the fundamental difficulty of out-of-distribution generalization with deep neural networks.","We first empirically show that perhaps surprisingly, even allowing a neural network to explicitly fit the representations obtained from a teacher network that can generalize out-of-distribution is insufficient for the generalization of the student network.","Then, by a theoretical study of two-layer ReLU networks optimized by stochastic gradient descent (SGD) under a structured feature model, we identify a fundamental yet unexplored feature learning proclivity of neural networks, feature contamination: neural networks can learn uncorrelated features together with predictive features, resulting in generalization failure under distribution shifts.","Notably, this mechanism essentially differs from the prevailing narrative in the literature that attributes the generalization failure to spurious correlations.","Overall, our results offer new insights into the non-linear feature learning dynamics of neural networks and highlight the necessity of considering inductive biases in out-of-distribution generalization."],"url":"http://arxiv.org/abs/2406.03345v1"}
{"created":"2024-06-05 15:00:59","title":"Audio Mamba: Bidirectional State Space Model for Audio Representation Learning","abstract":"Transformers have rapidly become the preferred choice for audio classification, surpassing methods based on CNNs. However, Audio Spectrogram Transformers (ASTs) exhibit quadratic scaling due to self-attention. The removal of this quadratic self-attention cost presents an appealing direction. Recently, state space models (SSMs), such as Mamba, have demonstrated potential in language and vision tasks in this regard. In this study, we explore whether reliance on self-attention is necessary for audio classification tasks. By introducing Audio Mamba (AuM), the first self-attention-free, purely SSM-based model for audio classification, we aim to address this question. We evaluate AuM on various audio datasets - comprising six different benchmarks - where it achieves comparable or better performance compared to well-established AST model.","sentences":["Transformers have rapidly become the preferred choice for audio classification, surpassing methods based on CNNs.","However, Audio Spectrogram Transformers (ASTs) exhibit quadratic scaling due to self-attention.","The removal of this quadratic self-attention cost presents an appealing direction.","Recently, state space models (SSMs), such as Mamba, have demonstrated potential in language and vision tasks in this regard.","In this study, we explore whether reliance on self-attention is necessary for audio classification tasks.","By introducing Audio Mamba (AuM), the first self-attention-free, purely SSM-based model for audio classification, we aim to address this question.","We evaluate AuM on various audio datasets - comprising six different benchmarks - where it achieves comparable or better performance compared to well-established AST model."],"url":"http://arxiv.org/abs/2406.03344v1"}
{"created":"2024-06-05 14:59:40","title":"Understanding and measuring software engineer behavior: What can we learn from the behavioral sciences?","abstract":"This paper explores the intricate challenge of understanding and measuring software engineer behavior. More specifically, we revolve around a central question: How can we enhance our understanding of software engineer behavior? Grounded in the nuanced complexities addressed within Behavioral Software Engineering (BSE), we advocate for holistic methods that integrate quantitative measures, such as psychometric instruments, and qualitative data from diverse sources. Furthermore, we delve into the relevance of this challenge within national and international contexts, highlighting the increasing interest in understanding software engineer behavior. Real-world initiatives and academic endeavors are also examined to underscore the potential for advancing this research agenda and, consequently, refining software engineering practices based on behavioral aspects. Lastly, this paper addresses different ways to evaluate the progress of this challenge by leveraging methodological skills derived from behavioral sciences, ultimately contributing to a deeper understanding of software engineer behavior and software engineering practices.","sentences":["This paper explores the intricate challenge of understanding and measuring software engineer behavior.","More specifically, we revolve around a central question: How can we enhance our understanding of software engineer behavior?","Grounded in the nuanced complexities addressed within Behavioral Software Engineering (BSE), we advocate for holistic methods that integrate quantitative measures, such as psychometric instruments, and qualitative data from diverse sources.","Furthermore, we delve into the relevance of this challenge within national and international contexts, highlighting the increasing interest in understanding software engineer behavior.","Real-world initiatives and academic endeavors are also examined to underscore the potential for advancing this research agenda and, consequently, refining software engineering practices based on behavioral aspects.","Lastly, this paper addresses different ways to evaluate the progress of this challenge by leveraging methodological skills derived from behavioral sciences, ultimately contributing to a deeper understanding of software engineer behavior and software engineering practices."],"url":"http://arxiv.org/abs/2406.03342v1"}
{"created":"2024-06-05 14:58:32","title":"Tackling GenAI Copyright Issues: Originality Estimation and Genericization","abstract":"The rapid progress of generative AI technology has sparked significant copyright concerns, leading to numerous lawsuits filed against AI developers. While some studies explore methods to mitigate copyright risks by steering the outputs of generative models away from those resembling copyrighted data, little attention has been paid to the question of how much of a resemblance is undesirable; more original or unique data are afforded stronger protection, and the threshold level of resemblance for constituting infringement correspondingly lower. Here, leveraging this principle, we propose a genericization method that modifies the outputs of a generative model to make them more generic and less likely to infringe copyright. To achieve this, we introduce a metric for quantifying the level of originality of data in a manner that is consistent with the legal framework. This metric can be practically estimated by drawing samples from a generative model, which is then used for the genericization process. Experiments demonstrate that our genericization method successfully modifies the output of a text-to-image generative model so that it produces more generic, copyright-compliant images.","sentences":["The rapid progress of generative AI technology has sparked significant copyright concerns, leading to numerous lawsuits filed against AI developers.","While some studies explore methods to mitigate copyright risks by steering the outputs of generative models away from those resembling copyrighted data, little attention has been paid to the question of how much of a resemblance is undesirable; more original or unique data are afforded stronger protection, and the threshold level of resemblance for constituting infringement correspondingly lower.","Here, leveraging this principle, we propose a genericization method that modifies the outputs of a generative model to make them more generic and less likely to infringe copyright.","To achieve this, we introduce a metric for quantifying the level of originality of data in a manner that is consistent with the legal framework.","This metric can be practically estimated by drawing samples from a generative model, which is then used for the genericization process.","Experiments demonstrate that our genericization method successfully modifies the output of a text-to-image generative model so that it produces more generic, copyright-compliant images."],"url":"http://arxiv.org/abs/2406.03341v1"}
{"created":"2024-06-05 14:57:29","title":"Analyzing and Estimating Support for U.S. Presidential Candidates in Twitter Polls","abstract":"Polls posted on social media have emerged in recent years as an important tool for estimating public opinion, e.g., to gauge public support for business decisions and political candidates in national elections. Here, we examine nearly two thousand Twitter polls gauging support for U.S. presidential candidates during the 2016 and 2020 election campaigns. First, we describe the rapidly emerging prevalence of social polls. Second, we characterize social polls in terms of their heterogeneity and response options. Third, leveraging machine learning models for user attribute inference, we describe the demographics, political leanings, and other characteristics of the users who author and interact with social polls. Finally, we study the relationship between social poll results, their attributes, and the characteristics of users interacting with them. Our findings reveal that Twitter polls are biased in various ways, starting from the position of the presidential candidates among the poll options to biases in demographic attributes and poll results. The 2016 and 2020 polls were predominantly crafted by older males and manifested a pronounced bias favoring candidate Donald Trump, in contrast to traditional surveys, which favored Democratic candidates. We further identify and explore the potential reasons for such biases in social polling and discuss their potential repercussions. Finally, we show that biases in social media polls can be corrected via regression and poststratification. The errors of the resulting election estimates can be as low as 1%-2%, suggesting that social media polls can become a promising source of information about public opinion.","sentences":["Polls posted on social media have emerged in recent years as an important tool for estimating public opinion, e.g., to gauge public support for business decisions and political candidates in national elections.","Here, we examine nearly two thousand Twitter polls gauging support for U.S. presidential candidates during the 2016 and 2020 election campaigns.","First, we describe the rapidly emerging prevalence of social polls.","Second, we characterize social polls in terms of their heterogeneity and response options.","Third, leveraging machine learning models for user attribute inference, we describe the demographics, political leanings, and other characteristics of the users who author and interact with social polls.","Finally, we study the relationship between social poll results, their attributes, and the characteristics of users interacting with them.","Our findings reveal that Twitter polls are biased in various ways, starting from the position of the presidential candidates among the poll options to biases in demographic attributes and poll results.","The 2016 and 2020 polls were predominantly crafted by older males and manifested a pronounced bias favoring candidate Donald Trump, in contrast to traditional surveys, which favored Democratic candidates.","We further identify and explore the potential reasons for such biases in social polling and discuss their potential repercussions.","Finally, we show that biases in social media polls can be corrected via regression and poststratification.","The errors of the resulting election estimates can be as low as 1%-2%, suggesting that social media polls can become a promising source of information about public opinion."],"url":"http://arxiv.org/abs/2406.03340v1"}
{"created":"2024-06-05 14:55:10","title":"The Challenges of Evaluating LLM Applications: An Analysis of Automated, Human, and LLM-Based Approaches","abstract":"Chatbots have been an interesting application of natural language generation since its inception. With novel transformer based Generative AI methods, building chatbots have become trivial. Chatbots which are targeted at specific domains such as medicine, psychology, and general information retrieval are implemented rapidly. This, however, should not distract from the need to evaluate the chatbot responses. Especially because the natural language generation community does not entirely agree upon how to effectively evaluate such applications. With this work we discuss the issue further with the increasingly popular LLM based evaluations and how they correlate with human evaluations. Additionally, we introduce a comprehensive factored evaluation mechanism that can be utilized in conjunction with both human and LLM-based evaluations.   We present the results of an experimental evaluation conducted using this scheme in one of our chatbot implementations, and subsequently compare automated, traditional human evaluation, factored human evaluation, and factored LLM evaluation. Results show that factor based evaluation produces better insights on which aspects need to be improved in LLM applications and further strengthens the argument to use human evaluation in critical spaces where main functionality is not direct retrieval.","sentences":["Chatbots have been an interesting application of natural language generation since its inception.","With novel transformer based Generative AI methods, building chatbots have become trivial.","Chatbots which are targeted at specific domains such as medicine, psychology, and general information retrieval are implemented rapidly.","This, however, should not distract from the need to evaluate the chatbot responses.","Especially because the natural language generation community does not entirely agree upon how to effectively evaluate such applications.","With this work we discuss the issue further with the increasingly popular LLM based evaluations and how they correlate with human evaluations.","Additionally, we introduce a comprehensive factored evaluation mechanism that can be utilized in conjunction with both human and LLM-based evaluations.   ","We present the results of an experimental evaluation conducted using this scheme in one of our chatbot implementations, and subsequently compare automated, traditional human evaluation, factored human evaluation, and factored LLM evaluation.","Results show that factor based evaluation produces better insights on which aspects need to be improved in LLM applications and further strengthens the argument to use human evaluation in critical spaces where main functionality is not direct retrieval."],"url":"http://arxiv.org/abs/2406.03339v1"}
{"created":"2024-06-05 14:52:43","title":"Identifying latent state transition in non-linear dynamical systems","abstract":"This work aims to improve generalization and interpretability of dynamical systems by recovering the underlying lower-dimensional latent states and their time evolutions. Previous work on disentangled representation learning within the realm of dynamical systems focused on the latent states, possibly with linear transition approximations. As such, they cannot identify nonlinear transition dynamics, and hence fail to reliably predict complex future behavior. Inspired by the advances in nonlinear ICA, we propose a state-space modeling framework in which we can identify not just the latent states but also the unknown transition function that maps the past states to the present. We introduce a practical algorithm based on variational auto-encoders and empirically demonstrate in realistic synthetic settings that we can (i) recover latent state dynamics with high accuracy, (ii) correspondingly achieve high future prediction accuracy, and (iii) adapt fast to new environments.","sentences":["This work aims to improve generalization and interpretability of dynamical systems by recovering the underlying lower-dimensional latent states and their time evolutions.","Previous work on disentangled representation learning within the realm of dynamical systems focused on the latent states, possibly with linear transition approximations.","As such, they cannot identify nonlinear transition dynamics, and hence fail to reliably predict complex future behavior.","Inspired by the advances in nonlinear ICA, we propose a state-space modeling framework in which we can identify not just the latent states but also the unknown transition function that maps the past states to the present.","We introduce a practical algorithm based on variational auto-encoders and empirically demonstrate in realistic synthetic settings that we can (i) recover latent state dynamics with high accuracy, (ii) correspondingly achieve high future prediction accuracy, and (iii) adapt fast to new environments."],"url":"http://arxiv.org/abs/2406.03337v1"}
{"created":"2024-06-05 14:49:14","title":"A Flexible Recursive Network for Video Stereo Matching Based on Residual Estimation","abstract":"Due to the high similarity of disparity between consecutive frames in video sequences, the area where disparity changes is defined as the residual map, which can be calculated. Based on this, we propose RecSM, a network based on residual estimation with a flexible recursive structure for video stereo matching. The RecSM network accelerates stereo matching using a Multi-scale Residual Estimation Module (MREM), which employs the temporal context as a reference and rapidly calculates the disparity for the current frame by computing only the residual values between the current and previous frames. To further reduce the error of estimated disparities, we use the Disparity Optimization Module (DOM) and Temporal Attention Module (TAM) to enforce constraints between each module, and together with MREM, form a flexible Stackable Computation Structure (SCS), which allows for the design of different numbers of SCS based on practical scenarios. Experimental results demonstrate that with a stack count of 3, RecSM achieves a 4x speed improvement compared to ACVNet, running at 0.054 seconds based on one NVIDIA RTX 2080TI GPU, with an accuracy decrease of only 0.7%. Code is available at https://github.com/Y0uchenZ/RecSM.","sentences":["Due to the high similarity of disparity between consecutive frames in video sequences, the area where disparity changes is defined as the residual map, which can be calculated.","Based on this, we propose RecSM, a network based on residual estimation with a flexible recursive structure for video stereo matching.","The RecSM network accelerates stereo matching using a Multi-scale Residual Estimation Module (MREM), which employs the temporal context as a reference and rapidly calculates the disparity for the current frame by computing only the residual values between the current and previous frames.","To further reduce the error of estimated disparities, we use the Disparity Optimization Module (DOM) and Temporal Attention Module (TAM) to enforce constraints between each module, and together with MREM, form a flexible Stackable Computation Structure (SCS), which allows for the design of different numbers of SCS based on practical scenarios.","Experimental results demonstrate that with a stack count of 3, RecSM achieves a 4x speed improvement compared to ACVNet, running at 0.054 seconds based on one NVIDIA RTX 2080TI GPU, with an accuracy decrease of only 0.7%.","Code is available at https://github.com/Y0uchenZ/RecSM."],"url":"http://arxiv.org/abs/2406.03333v1"}
{"created":"2024-06-05 14:37:42","title":"UDQL: Bridging The Gap between MSE Loss and The Optimal Value Function in Offline Reinforcement Learning","abstract":"The Mean Square Error (MSE) is commonly utilized to estimate the solution of the optimal value function in the vast majority of offline reinforcement learning (RL) models and has achieved outstanding performance. However, we find that its principle can lead to overestimation phenomenon for the value function. In this paper, we first theoretically analyze overestimation phenomenon led by MSE and provide the theoretical upper bound of the overestimated error. Furthermore, to address it, we propose a novel Bellman underestimated operator to counteract overestimation phenomenon and then prove its contraction characteristics. At last, we propose the offline RL algorithm based on underestimated operator and diffusion policy model. Extensive experimental results on D4RL tasks show that our method can outperform state-of-the-art offline RL algorithms, which demonstrates that our theoretical analysis and underestimation way are effective for offline RL tasks.","sentences":["The Mean Square Error (MSE) is commonly utilized to estimate the solution of the optimal value function in the vast majority of offline reinforcement learning (RL) models and has achieved outstanding performance.","However, we find that its principle can lead to overestimation phenomenon for the value function.","In this paper, we first theoretically analyze overestimation phenomenon led by MSE and provide the theoretical upper bound of the overestimated error.","Furthermore, to address it, we propose a novel Bellman underestimated operator to counteract overestimation phenomenon and then prove its contraction characteristics.","At last, we propose the offline RL algorithm based on underestimated operator and diffusion policy model.","Extensive experimental results on D4RL tasks show that our method can outperform state-of-the-art offline RL algorithms, which demonstrates that our theoretical analysis and underestimation way are effective for offline RL tasks."],"url":"http://arxiv.org/abs/2406.03324v1"}
{"created":"2024-06-05 14:36:33","title":"Comparative Benchmarking of Failure Detection Methods in Medical Image Segmentation: Unveiling the Role of Confidence Aggregation","abstract":"Semantic segmentation is an essential component of medical image analysis research, with recent deep learning algorithms offering out-of-the-box applicability across diverse datasets. Despite these advancements, segmentation failures remain a significant concern for real-world clinical applications, necessitating reliable detection mechanisms. This paper introduces a comprehensive benchmarking framework aimed at evaluating failure detection methodologies within medical image segmentation. Through our analysis, we identify the strengths and limitations of current failure detection metrics, advocating for the risk-coverage analysis as a holistic evaluation approach. Utilizing a collective dataset comprising five public 3D medical image collections, we assess the efficacy of various failure detection strategies under realistic test-time distribution shifts. Our findings highlight the importance of pixel confidence aggregation and we observe superior performance of the pairwise Dice score (Roy et al., 2019) between ensemble predictions, positioning it as a simple and robust baseline for failure detection in medical image segmentation. To promote ongoing research, we make the benchmarking framework available to the community.","sentences":["Semantic segmentation is an essential component of medical image analysis research, with recent deep learning algorithms offering out-of-the-box applicability across diverse datasets.","Despite these advancements, segmentation failures remain a significant concern for real-world clinical applications, necessitating reliable detection mechanisms.","This paper introduces a comprehensive benchmarking framework aimed at evaluating failure detection methodologies within medical image segmentation.","Through our analysis, we identify the strengths and limitations of current failure detection metrics, advocating for the risk-coverage analysis as a holistic evaluation approach.","Utilizing a collective dataset comprising five public 3D medical image collections, we assess the efficacy of various failure detection strategies under realistic test-time distribution shifts.","Our findings highlight the importance of pixel confidence aggregation and we observe superior performance of the pairwise Dice score (Roy et al., 2019) between ensemble predictions, positioning it as a simple and robust baseline for failure detection in medical image segmentation.","To promote ongoing research, we make the benchmarking framework available to the community."],"url":"http://arxiv.org/abs/2406.03323v1"}
{"created":"2024-06-05 14:34:37","title":"A Framework for Mapping Organisational Workforce Knowledge Profile in Cyber Security","abstract":"A cyber security organisation needs to ensure that its workforce possesses the necessary knowledge to fulfil its cyber security business functions. Similarly, where an organisation chooses to delegate their cyber security tasks to a third party provider, they must ensure that the chosen entity possesses robust knowledge capabilities to effectively carry out the assigned tasks. Building a comprehensive cyber security knowledge profile is a distinct challenge; the field is ever evolving with a range of professional certifications, academic qualifications and on-the-job training. So far, there has been a lack of a well-defined methodology for systematically evaluating an organisation's cyber security knowledge, specifically derived from its workforce, against a standardised reference point. Prior research on knowledge profiling across various disciplines has predominantly utilised established frameworks such as SWEBOK. However, within the domain of cyber security, the absence of a standardised reference point is notable. In this paper, we advance a framework leveraging CyBOK, to construct an organisation's knowledge profile. The framework enables a user to identify areas of coverage and where gaps may lie, so that an organisation can consider targeted recruitment or training or, where such expertise may be outsourced, drawing in knowledge capability from third parties. In the latter case, the framework can also be used as a basis for assessing the knowledge capability of such a third party. We present the knowledge profiling framework, discussing three case studies in organisational teams underpinning its initial development, followed by its refinement through workshops with cyber security practitioners.","sentences":["A cyber security organisation needs to ensure that its workforce possesses the necessary knowledge to fulfil its cyber security business functions.","Similarly, where an organisation chooses to delegate their cyber security tasks to a third party provider, they must ensure that the chosen entity possesses robust knowledge capabilities to effectively carry out the assigned tasks.","Building a comprehensive cyber security knowledge profile is a distinct challenge; the field is ever evolving with a range of professional certifications, academic qualifications and on-the-job training.","So far, there has been a lack of a well-defined methodology for systematically evaluating an organisation's cyber security knowledge, specifically derived from its workforce, against a standardised reference point.","Prior research on knowledge profiling across various disciplines has predominantly utilised established frameworks such as SWEBOK.","However, within the domain of cyber security, the absence of a standardised reference point is notable.","In this paper, we advance a framework leveraging CyBOK, to construct an organisation's knowledge profile.","The framework enables a user to identify areas of coverage and where gaps may lie, so that an organisation can consider targeted recruitment or training or, where such expertise may be outsourced, drawing in knowledge capability from third parties.","In the latter case, the framework can also be used as a basis for assessing the knowledge capability of such a third party.","We present the knowledge profiling framework, discussing three case studies in organisational teams underpinning its initial development, followed by its refinement through workshops with cyber security practitioners."],"url":"http://arxiv.org/abs/2406.03322v1"}
{"created":"2024-06-05 14:29:44","title":"Save It for the \"Hot\" Day: An LLM-Empowered Visual Analytics System for Heat Risk Management","abstract":"The escalating frequency and intensity of heat-related climate events, particularly heatwaves, emphasize the pressing need for advanced heat risk management strategies. Current approaches, primarily relying on numerical models, face challenges in spatial-temporal resolution and in capturing the dynamic interplay of environmental, social, and behavioral factors affecting heat risks. This has led to difficulties in translating risk assessments into effective mitigation actions. Recognizing these problems, we introduce a novel approach leveraging the burgeoning capabilities of Large Language Models (LLMs) to extract rich and contextual insights from news reports. We hence propose an LLM-empowered visual analytics system, Havior, that integrates the precise, data-driven insights of numerical models with nuanced news report information. This hybrid approach enables a more comprehensive assessment of heat risks and better identification, assessment, and mitigation of heat-related threats. The system incorporates novel visualization designs, such as \"thermoglyph\" and news glyph, enhancing intuitive understanding and analysis of heat risks. The integration of LLM-based techniques also enables advanced information retrieval and semantic knowledge extraction that can be guided by experts' analytics needs. Our case studies on two cities that faced significant heatwave events and interviews with five experts have demonstrated the usefulness of our system in providing in-depth and actionable insights for heat risk management.","sentences":["The escalating frequency and intensity of heat-related climate events, particularly heatwaves, emphasize the pressing need for advanced heat risk management strategies.","Current approaches, primarily relying on numerical models, face challenges in spatial-temporal resolution and in capturing the dynamic interplay of environmental, social, and behavioral factors affecting heat risks.","This has led to difficulties in translating risk assessments into effective mitigation actions.","Recognizing these problems, we introduce a novel approach leveraging the burgeoning capabilities of Large Language Models (LLMs) to extract rich and contextual insights from news reports.","We hence propose an LLM-empowered visual analytics system, Havior, that integrates the precise, data-driven insights of numerical models with nuanced news report information.","This hybrid approach enables a more comprehensive assessment of heat risks and better identification, assessment, and mitigation of heat-related threats.","The system incorporates novel visualization designs, such as \"thermoglyph\" and news glyph, enhancing intuitive understanding and analysis of heat risks.","The integration of LLM-based techniques also enables advanced information retrieval and semantic knowledge extraction that can be guided by experts' analytics needs.","Our case studies on two cities that faced significant heatwave events and interviews with five experts have demonstrated the usefulness of our system in providing in-depth and actionable insights for heat risk management."],"url":"http://arxiv.org/abs/2406.03317v1"}
{"created":"2024-06-05 14:26:45","title":"Reproducibility study of FairAC","abstract":"This work aims to reproduce the findings of the paper \"Fair Attribute Completion on Graph with Missing Attributes\" written by Guo, Chu, and Li arXiv:2302.12977 by investigating the claims made in the paper. This paper suggests that the results of the original paper are reproducible and thus, the claims hold. However, the claim that FairAC is a generic framework for many downstream tasks is very broad and could therefore only be partially tested. Moreover, we show that FairAC is generalizable to various datasets and sensitive attributes and show evidence that the improvement in group fairness of the FairAC framework does not come at the expense of individual fairness. Lastly, the codebase of FairAC has been refactored and is now easily applicable for various datasets and models.","sentences":["This work aims to reproduce the findings of the paper \"Fair Attribute Completion on Graph with Missing Attributes\" written by Guo, Chu, and Li arXiv:2302.12977 by investigating the claims made in the paper.","This paper suggests that the results of the original paper are reproducible and thus, the claims hold.","However, the claim that FairAC is a generic framework for many downstream tasks is very broad and could therefore only be partially tested.","Moreover, we show that FairAC is generalizable to various datasets and sensitive attributes and show evidence that the improvement in group fairness of the FairAC framework does not come at the expense of individual fairness.","Lastly, the codebase of FairAC has been refactored and is now easily applicable for various datasets and models."],"url":"http://arxiv.org/abs/2406.03314v1"}
{"created":"2024-06-05 14:13:38","title":"Learning Visual Prompts for Guiding the Attention of Vision Transformers","abstract":"Visual prompting infuses visual information into the input image to adapt models toward specific predictions and tasks. Recently, manually crafted markers such as red circles are shown to guide the model to attend to a target region on the image. However, these markers only work on models trained with data containing those markers. Moreover, finding these prompts requires guesswork or prior knowledge of the domain on which the model is trained. This work circumvents manual design constraints by proposing to learn the visual prompts for guiding the attention of vision transformers. The learned visual prompt, added to any input image would redirect the attention of the pre-trained vision transformer to its spatial location on the image. Specifically, the prompt is learned in a self-supervised manner without requiring annotations and without fine-tuning the vision transformer. Our experiments demonstrate the effectiveness of the proposed optimization-based visual prompting strategy across various pre-trained vision encoders.","sentences":["Visual prompting infuses visual information into the input image to adapt models toward specific predictions and tasks.","Recently, manually crafted markers such as red circles are shown to guide the model to attend to a target region on the image.","However, these markers only work on models trained with data containing those markers.","Moreover, finding these prompts requires guesswork or prior knowledge of the domain on which the model is trained.","This work circumvents manual design constraints by proposing to learn the visual prompts for guiding the attention of vision transformers.","The learned visual prompt, added to any input image would redirect the attention of the pre-trained vision transformer to its spatial location on the image.","Specifically, the prompt is learned in a self-supervised manner without requiring annotations and without fine-tuning the vision transformer.","Our experiments demonstrate the effectiveness of the proposed optimization-based visual prompting strategy across various pre-trained vision encoders."],"url":"http://arxiv.org/abs/2406.03303v1"}
{"created":"2024-06-05 14:08:54","title":"The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games","abstract":"Behavior study experiments are an important part of society modeling and understanding human interactions. In practice, many behavioral experiments encounter challenges related to internal and external validity, reproducibility, and social bias due to the complexity of social interactions and cooperation in human user studies. Recent advances in Large Language Models (LLMs) have provided researchers with a new promising tool for the simulation of human behavior. However, existing LLM-based simulations operate under the unproven hypothesis that LLM agents behave similarly to humans as well as ignore a crucial factor in human decision-making: emotions.   In this paper, we introduce a novel methodology and the framework to study both, the decision-making of LLMs and their alignment with human behavior under emotional states. Experiments with GPT-3.5 and GPT-4 on four games from two different classes of behavioral game theory showed that emotions profoundly impact the performance of LLMs, leading to the development of more optimal strategies. While there is a strong alignment between the behavioral responses of GPT-3.5 and human participants, particularly evident in bargaining games, GPT-4 exhibits consistent behavior, ignoring induced emotions for rationality decisions. Surprisingly, emotional prompting, particularly with `anger' emotion, can disrupt the \"superhuman\" alignment of GPT-4, resembling human emotional responses.","sentences":["Behavior study experiments are an important part of society modeling and understanding human interactions.","In practice, many behavioral experiments encounter challenges related to internal and external validity, reproducibility, and social bias due to the complexity of social interactions and cooperation in human user studies.","Recent advances in Large Language Models (LLMs) have provided researchers with a new promising tool for the simulation of human behavior.","However, existing LLM-based simulations operate under the unproven hypothesis that LLM agents behave similarly to humans as well as ignore a crucial factor in human decision-making: emotions.   ","In this paper, we introduce a novel methodology and the framework to study both, the decision-making of LLMs and their alignment with human behavior under emotional states.","Experiments with GPT-3.5 and GPT-4 on four games from two different classes of behavioral game theory showed that emotions profoundly impact the performance of LLMs, leading to the development of more optimal strategies.","While there is a strong alignment between the behavioral responses of GPT-3.5 and human participants, particularly evident in bargaining games, GPT-4 exhibits consistent behavior, ignoring induced emotions for rationality decisions.","Surprisingly, emotional prompting, particularly with `anger' emotion, can disrupt the \"superhuman\" alignment of GPT-4, resembling human emotional responses."],"url":"http://arxiv.org/abs/2406.03299v1"}
{"created":"2024-06-05 14:08:13","title":"L-PR: Exploiting LiDAR Fiducial Marker for Unordered Low Overlap Multiview Point Cloud Registration","abstract":"Point cloud registration is a prerequisite for many applications in computer vision and robotics. Most existing methods focus on pairwise registration of two point clouds with high overlap. Although there have been some methods for low overlap cases, they struggle in degraded scenarios. This paper introduces a novel framework named L-PR, designed to register unordered low overlap multiview point clouds leveraging LiDAR fiducial markers. We refer to them as LiDAR fiducial markers, but they are the same as the popular AprilTag and ArUco markers, thin sheets of paper that do not affect the 3D geometry of the environment. We first propose an improved adaptive threshold marker detection method to provide robust detection results when the viewpoints among point clouds change dramatically. Then, we formulate the unordered multiview point cloud registration problem as a maximum a-posteriori (MAP) problem and develop a framework consisting of two levels of graphs to address it. The first-level graph, constructed as a weighted graph, is designed to efficiently and optimally infer initial values of scan poses from the unordered set. The second-level graph is constructed as a factor graph. By globally optimizing the variables on the graph, including scan poses, marker poses, and marker corner positions, we tackle the MAP problem. We conduct qualitative and quantitative experiments to demonstrate that the proposed method exhibits superiority over competitors in four aspects: registration accuracy, instance reconstruction quality, localization accuracy, and robustness to the degraded scene. To benefit the community, we open-source our method and dataset at https://github.com/yorklyb/LiDAR-SFM.","sentences":["Point cloud registration is a prerequisite for many applications in computer vision and robotics.","Most existing methods focus on pairwise registration of two point clouds with high overlap.","Although there have been some methods for low overlap cases, they struggle in degraded scenarios.","This paper introduces a novel framework named L-PR, designed to register unordered low overlap multiview point clouds leveraging LiDAR fiducial markers.","We refer to them as LiDAR fiducial markers, but they are the same as the popular AprilTag and ArUco markers, thin sheets of paper that do not affect the 3D geometry of the environment.","We first propose an improved adaptive threshold marker detection method to provide robust detection results when the viewpoints among point clouds change dramatically.","Then, we formulate the unordered multiview point cloud registration problem as a maximum a-posteriori (MAP) problem and develop a framework consisting of two levels of graphs to address it.","The first-level graph, constructed as a weighted graph, is designed to efficiently and optimally infer initial values of scan poses from the unordered set.","The second-level graph is constructed as a factor graph.","By globally optimizing the variables on the graph, including scan poses, marker poses, and marker corner positions, we tackle the MAP problem.","We conduct qualitative and quantitative experiments to demonstrate that the proposed method exhibits superiority over competitors in four aspects: registration accuracy, instance reconstruction quality, localization accuracy, and robustness to the degraded scene.","To benefit the community, we open-source our method and dataset at https://github.com/yorklyb/LiDAR-SFM."],"url":"http://arxiv.org/abs/2406.03298v1"}
{"created":"2024-06-05 14:02:31","title":"Text-to-Image Rectified Flow as Plug-and-Play Priors","abstract":"Large-scale diffusion models have achieved remarkable performance in generative tasks. Beyond their initial training applications, these models have proven their ability to function as versatile plug-and-play priors. For instance, 2D diffusion models can serve as loss functions to optimize 3D implicit models. Rectified flow, a novel class of generative models, enforces a linear progression from the source to the target distribution and has demonstrated superior performance across various domains. Compared to diffusion-based methods, rectified flow approaches surpass in terms of generation quality and efficiency, requiring fewer inference steps. In this work, we present theoretical and experimental evidence demonstrating that rectified flow based methods offer similar functionalities to diffusion models - they can also serve as effective priors. Besides the generative capabilities of diffusion priors, motivated by the unique time-symmetry properties of rectified flow models, a variant of our method can additionally perform image inversion. Experimentally, our rectified flow-based priors outperform their diffusion counterparts - the SDS and VSD losses - in text-to-3D generation. Our method also displays competitive performance in image inversion and editing.","sentences":["Large-scale diffusion models have achieved remarkable performance in generative tasks.","Beyond their initial training applications, these models have proven their ability to function as versatile plug-and-play priors.","For instance, 2D diffusion models can serve as loss functions to optimize 3D implicit models.","Rectified flow, a novel class of generative models, enforces a linear progression from the source to the target distribution and has demonstrated superior performance across various domains.","Compared to diffusion-based methods, rectified flow approaches surpass in terms of generation quality and efficiency, requiring fewer inference steps.","In this work, we present theoretical and experimental evidence demonstrating that rectified flow based methods offer similar functionalities to diffusion models - they can also serve as effective priors.","Besides the generative capabilities of diffusion priors, motivated by the unique time-symmetry properties of rectified flow models, a variant of our method can additionally perform image inversion.","Experimentally, our rectified flow-based priors outperform their diffusion counterparts - the SDS and VSD losses - in text-to-3D generation.","Our method also displays competitive performance in image inversion and editing."],"url":"http://arxiv.org/abs/2406.03293v1"}
{"created":"2024-06-05 14:00:46","title":"Evaluating AI fairness in credit scoring with the BRIO tool","abstract":"We present a method for quantitative, in-depth analyses of fairness issues in AI systems with an application to credit scoring. To this aim we use BRIO, a tool for the evaluation of AI systems with respect to social unfairness and, more in general, ethically undesirable behaviours. It features a model-agnostic bias detection module, presented in \\cite{DBLP:conf/beware/CoragliaDGGPPQ23}, to which a full-fledged unfairness risk evaluation module is added. As a case study, we focus on the context of credit scoring, analysing the UCI German Credit Dataset \\cite{misc_statlog_(german_credit_data)_144}. We apply the BRIO fairness metrics to several, socially sensitive attributes featured in the German Credit Dataset, quantifying fairness across various demographic segments, with the aim of identifying potential sources of bias and discrimination in a credit scoring model. We conclude by combining our results with a revenue analysis.","sentences":["We present a method for quantitative, in-depth analyses of fairness issues in AI systems with an application to credit scoring.","To this aim we use BRIO, a tool for the evaluation of AI systems with respect to social unfairness and, more in general, ethically undesirable behaviours.","It features a model-agnostic bias detection module, presented in \\cite{DBLP:conf/beware/CoragliaDGGPPQ23}, to which a full-fledged unfairness risk evaluation module is added.","As a case study, we focus on the context of credit scoring, analysing the UCI German Credit Dataset \\cite{misc_statlog_(german_credit_data)_144}.","We apply the BRIO fairness metrics to several, socially sensitive attributes featured in the German Credit Dataset, quantifying fairness across various demographic segments, with the aim of identifying potential sources of bias and discrimination in a credit scoring model.","We conclude by combining our results with a revenue analysis."],"url":"http://arxiv.org/abs/2406.03292v1"}
{"created":"2024-06-05 13:59:05","title":"Embarrassingly Parallel GFlowNets","abstract":"GFlowNets are a promising alternative to MCMC sampling for discrete compositional random variables. Training GFlowNets requires repeated evaluations of the unnormalized target distribution or reward function. However, for large-scale posterior sampling, this may be prohibitive since it incurs traversing the data several times. Moreover, if the data are distributed across clients, employing standard GFlowNets leads to intensive client-server communication. To alleviate both these issues, we propose embarrassingly parallel GFlowNet (EP-GFlowNet). EP-GFlowNet is a provably correct divide-and-conquer method to sample from product distributions of the form $R(\\cdot) \\propto R_1(\\cdot) ... R_N(\\cdot)$ -- e.g., in parallel or federated Bayes, where each $R_n$ is a local posterior defined on a data partition. First, in parallel, we train a local GFlowNet targeting each $R_n$ and send the resulting models to the server. Then, the server learns a global GFlowNet by enforcing our newly proposed \\emph{aggregating balance} condition, requiring a single communication step. Importantly, EP-GFlowNets can also be applied to multi-objective optimization and model reuse. Our experiments illustrate the EP-GFlowNets's effectiveness on many tasks, including parallel Bayesian phylogenetics, multi-objective multiset, sequence generation, and federated Bayesian structure learning.","sentences":["GFlowNets are a promising alternative to MCMC sampling for discrete compositional random variables.","Training GFlowNets requires repeated evaluations of the unnormalized target distribution or reward function.","However, for large-scale posterior sampling, this may be prohibitive since it incurs traversing the data several times.","Moreover, if the data are distributed across clients, employing standard GFlowNets leads to intensive client-server communication.","To alleviate both these issues, we propose embarrassingly parallel GFlowNet (EP-GFlowNet).","EP-GFlowNet is a provably correct divide-and-conquer method to sample from product distributions of the form $R(\\cdot) \\propto R_1(\\cdot) ...","R_N(\\cdot)$ -- e.g., in parallel or federated Bayes, where each $R_n$ is a local posterior defined on a data partition.","First, in parallel, we train a local GFlowNet targeting each $R_n$ and send the resulting models to the server.","Then, the server learns a global GFlowNet by enforcing our newly proposed \\emph{aggregating balance} condition, requiring a single communication step.","Importantly, EP-GFlowNets can also be applied to multi-objective optimization and model reuse.","Our experiments illustrate the EP-GFlowNets's effectiveness on many tasks, including parallel Bayesian phylogenetics, multi-objective multiset, sequence generation, and federated Bayesian structure learning."],"url":"http://arxiv.org/abs/2406.03288v1"}
{"created":"2024-06-05 13:59:03","title":"SpikeLM: Towards General Spike-Driven Language Modeling via Elastic Bi-Spiking Mechanisms","abstract":"Towards energy-efficient artificial intelligence similar to the human brain, the bio-inspired spiking neural networks (SNNs) have advantages of biological plausibility, event-driven sparsity, and binary activation. Recently, large-scale language models exhibit promising generalization capability, making it a valuable issue to explore more general spike-driven models. However, the binary spikes in existing SNNs fail to encode adequate semantic information, placing technological challenges for generalization. This work proposes the first fully spiking mechanism for general language tasks, including both discriminative and generative ones. Different from previous spikes with {0,1} levels, we propose a more general spike formulation with bi-directional, elastic amplitude, and elastic frequency encoding, while still maintaining the addition nature of SNNs. In a single time step, the spike is enhanced by direction and amplitude information; in spike frequency, a strategy to control spike firing rate is well designed. We plug this elastic bi-spiking mechanism in language modeling, named SpikeLM. It is the first time to handle general language tasks with fully spike-driven models, which achieve much higher accuracy than previously possible. SpikeLM also greatly bridges the performance gap between SNNs and ANNs in language modeling. Our code is available at https://github.com/Xingrun-Xing/SpikeLM.","sentences":["Towards energy-efficient artificial intelligence similar to the human brain, the bio-inspired spiking neural networks (SNNs) have advantages of biological plausibility, event-driven sparsity, and binary activation.","Recently, large-scale language models exhibit promising generalization capability, making it a valuable issue to explore more general spike-driven models.","However, the binary spikes in existing SNNs fail to encode adequate semantic information, placing technological challenges for generalization.","This work proposes the first fully spiking mechanism for general language tasks, including both discriminative and generative ones.","Different from previous spikes with {0,1} levels, we propose a more general spike formulation with bi-directional, elastic amplitude, and elastic frequency encoding, while still maintaining the addition nature of SNNs.","In a single time step, the spike is enhanced by direction and amplitude information; in spike frequency, a strategy to control spike firing rate is well designed.","We plug this elastic bi-spiking mechanism in language modeling, named SpikeLM.","It is the first time to handle general language tasks with fully spike-driven models, which achieve much higher accuracy than previously possible.","SpikeLM also greatly bridges the performance gap between SNNs and ANNs in language modeling.","Our code is available at https://github.com/Xingrun-Xing/SpikeLM."],"url":"http://arxiv.org/abs/2406.03287v1"}
{"created":"2024-06-05 13:57:06","title":"Efficient Data-Parallel Continual Learning with Asynchronous Distributed Rehearsal Buffers","abstract":"Deep learning has emerged as a powerful method for extracting valuable information from large volumes of data. However, when new training data arrives continuously (i.e., is not fully available from the beginning), incremental training suffers from catastrophic forgetting (i.e., new patterns are reinforced at the expense of previously acquired knowledge). Training from scratch each time new training data becomes available would result in extremely long training times and massive data accumulation. Rehearsal-based continual learning has shown promise for addressing the catastrophic forgetting challenge, but research to date has not addressed performance and scalability. To fill this gap, we propose an approach based on a distributed rehearsal buffer that efficiently complements data-parallel training on multiple GPUs, allowing us to achieve short runtime and scalability while retaining high accuracy. It leverages a set of buffers (local to each GPU) and uses several asynchronous techniques for updating these local buffers in an embarrassingly parallel fashion, all while handling the communication overheads necessary to augment input mini-batches (groups of training samples fed to the model) using unbiased, global sampling. In this paper we explore the benefits of this approach for classification models. We run extensive experiments on up to 128 GPUs of the ThetaGPU supercomputer to compare our approach with baselines representative of training-from-scratch (the upper bound in terms of accuracy) and incremental training (the lower bound). Results show that rehearsal-based continual learning achieves a top-5 classification accuracy close to the upper bound, while simultaneously exhibiting a runtime close to the lower bound.","sentences":["Deep learning has emerged as a powerful method for extracting valuable information from large volumes of data.","However, when new training data arrives continuously (i.e., is not fully available from the beginning), incremental training suffers from catastrophic forgetting (i.e., new patterns are reinforced at the expense of previously acquired knowledge).","Training from scratch each time new training data becomes available would result in extremely long training times and massive data accumulation.","Rehearsal-based continual learning has shown promise for addressing the catastrophic forgetting challenge, but research to date has not addressed performance and scalability.","To fill this gap, we propose an approach based on a distributed rehearsal buffer that efficiently complements data-parallel training on multiple GPUs, allowing us to achieve short runtime and scalability while retaining high accuracy.","It leverages a set of buffers (local to each GPU) and uses several asynchronous techniques for updating these local buffers in an embarrassingly parallel fashion, all while handling the communication overheads necessary to augment input mini-batches (groups of training samples fed to the model) using unbiased, global sampling.","In this paper we explore the benefits of this approach for classification models.","We run extensive experiments on up to 128 GPUs of the ThetaGPU supercomputer to compare our approach with baselines representative of training-from-scratch (the upper bound in terms of accuracy) and incremental training (the lower bound).","Results show that rehearsal-based continual learning achieves a top-5 classification accuracy close to the upper bound, while simultaneously exhibiting a runtime close to the lower bound."],"url":"http://arxiv.org/abs/2406.03285v1"}
{"created":"2024-06-05 13:56:42","title":"Enhancing Repository-Level Code Generation with Integrated Contextual Information","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, repository-level code generation presents unique challenges, particularly due to the need to utilize information spread across multiple files within a repository. Existing retrieval-based approaches sometimes fall short as they are limited in obtaining a broader and deeper repository context. In this paper, we present CatCoder, a novel code generation framework designed for statically typed programming languages. CatCoder enhances repository-level code generation by integrating relevant code and type context. Specifically, it leverages static analyzers to extract type dependencies and merges this information with retrieved code to create comprehensive prompts for LLMs. To evaluate the effectiveness of CatCoder, we adapt and construct benchmarks that include 199 Java tasks and 90 Rust tasks. The results show that CatCoder outperforms the RepoCoder baseline by up to 17.35%, in terms of pass@k score. Furthermore, the generalizability of CatCoder is assessed using various LLMs, including both code-specialized models and general-purpose models. Our findings indicate consistent performance improvements across all models, which underlines the practicality of CatCoder.","sentences":["Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks.","However, repository-level code generation presents unique challenges, particularly due to the need to utilize information spread across multiple files within a repository.","Existing retrieval-based approaches sometimes fall short as they are limited in obtaining a broader and deeper repository context.","In this paper, we present CatCoder, a novel code generation framework designed for statically typed programming languages.","CatCoder enhances repository-level code generation by integrating relevant code and type context.","Specifically, it leverages static analyzers to extract type dependencies and merges this information with retrieved code to create comprehensive prompts for LLMs.","To evaluate the effectiveness of CatCoder, we adapt and construct benchmarks that include 199 Java tasks and 90 Rust tasks.","The results show that CatCoder outperforms the RepoCoder baseline by up to 17.35%, in terms of pass@k score.","Furthermore, the generalizability of CatCoder is assessed using various LLMs, including both code-specialized models and general-purpose models.","Our findings indicate consistent performance improvements across all models, which underlines the practicality of CatCoder."],"url":"http://arxiv.org/abs/2406.03283v1"}
