{"created":"2024-05-20 17:59:59","title":"Images that Sound: Composing Images and Sounds on a Single Canvas","abstract":"Spectrograms are 2D representations of sound that look very different from the images found in our visual world. And natural images, when played as spectrograms, make unnatural sounds. In this paper, we show that it is possible to synthesize spectrograms that simultaneously look like natural images and sound like natural audio. We call these spectrograms images that sound. Our approach is simple and zero-shot, and it leverages pre-trained text-to-image and text-to-spectrogram diffusion models that operate in a shared latent space. During the reverse process, we denoise noisy latents with both the audio and image diffusion models in parallel, resulting in a sample that is likely under both models. Through quantitative evaluations and perceptual studies, we find that our method successfully generates spectrograms that align with a desired audio prompt while also taking the visual appearance of a desired image prompt. Please see our project page for video results: https://ificl.github.io/images-that-sound/","sentences":["Spectrograms are 2D representations of sound that look very different from the images found in our visual world.","And natural images, when played as spectrograms, make unnatural sounds.","In this paper, we show that it is possible to synthesize spectrograms that simultaneously look like natural images and sound like natural audio.","We call these spectrograms images that sound.","Our approach is simple and zero-shot, and it leverages pre-trained text-to-image and text-to-spectrogram diffusion models that operate in a shared latent space.","During the reverse process, we denoise noisy latents with both the audio and image diffusion models in parallel, resulting in a sample that is likely under both models.","Through quantitative evaluations and perceptual studies, we find that our method successfully generates spectrograms that align with a desired audio prompt while also taking the visual appearance of a desired image prompt.","Please see our project page for video results: https://ificl.github.io/images-that-sound/"],"url":"http://arxiv.org/abs/2405.12221v1"}
{"created":"2024-05-20 17:59:30","title":"Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo","abstract":"We present MVSGaussian, a new generalizable 3D Gaussian representation approach derived from Multi-View Stereo (MVS) that can efficiently reconstruct unseen scenes. Specifically, 1) we leverage MVS to encode geometry-aware Gaussian representations and decode them into Gaussian parameters. 2) To further enhance performance, we propose a hybrid Gaussian rendering that integrates an efficient volume rendering design for novel view synthesis. 3) To support fast fine-tuning for specific scenes, we introduce a multi-view geometric consistent aggregation strategy to effectively aggregate the point clouds generated by the generalizable model, serving as the initialization for per-scene optimization. Compared with previous generalizable NeRF-based methods, which typically require minutes of fine-tuning and seconds of rendering per image, MVSGaussian achieves real-time rendering with better synthesis quality for each scene. Compared with the vanilla 3D-GS, MVSGaussian achieves better view synthesis with less training computational cost. Extensive experiments on DTU, Real Forward-facing, NeRF Synthetic, and Tanks and Temples datasets validate that MVSGaussian attains state-of-the-art performance with convincing generalizability, real-time rendering speed, and fast per-scene optimization.","sentences":["We present MVSGaussian, a new generalizable 3D Gaussian representation approach derived from Multi-View Stereo (MVS) that can efficiently reconstruct unseen scenes.","Specifically, 1) we leverage MVS to encode geometry-aware Gaussian representations and decode them into Gaussian parameters.","2) To further enhance performance, we propose a hybrid Gaussian rendering that integrates an efficient volume rendering design for novel view synthesis.","3) To support fast fine-tuning for specific scenes, we introduce a multi-view geometric consistent aggregation strategy to effectively aggregate the point clouds generated by the generalizable model, serving as the initialization for per-scene optimization.","Compared with previous generalizable NeRF-based methods, which typically require minutes of fine-tuning and seconds of rendering per image, MVSGaussian achieves real-time rendering with better synthesis quality for each scene.","Compared with the vanilla 3D-GS, MVSGaussian achieves better view synthesis with less training computational cost.","Extensive experiments on DTU, Real Forward-facing, NeRF Synthetic, and Tanks and Temples datasets validate that MVSGaussian attains state-of-the-art performance with convincing generalizability, real-time rendering speed, and fast per-scene optimization."],"url":"http://arxiv.org/abs/2405.12218v1"}
{"created":"2024-05-20 17:59:21","title":"Adapting Large Multimodal Models to Distribution Shifts: The Role of In-Context Learning","abstract":"Recent studies indicate that large multimodal models (LMMs) are highly robust against natural distribution shifts, often surpassing previous baselines. Despite this, domain-specific adaptation is still necessary, particularly in specialized areas like healthcare. Due to the impracticality of fine-tuning LMMs given their vast parameter space, this work investigates in-context learning (ICL) as an effective alternative for enhancing LMMs' adaptability. We find that the success of ICL heavily relies on the choice of demonstration, mirroring challenges seen in large language models but introducing unique complexities for LMMs facing distribution shifts. Our study addresses this by evaluating an unsupervised ICL method, TopKNearestPR, which selects in-context examples through a nearest example search based on feature similarity. We uncover that its effectiveness is limited by the deficiencies of pre-trained vision encoders under distribution shift scenarios. To address these challenges, we propose InvariantSelectPR, a novel method leveraging Class-conditioned Contrastive Invariance (CCI) for more robust demonstration selection. Specifically, CCI enhances pre-trained vision encoders by improving their discriminative capabilities across different classes and ensuring invariance to domain-specific variations. This enhancement allows the encoders to effectively identify and retrieve the most informative examples, which are then used to guide LMMs in adapting to new query samples under varying distributions. Our experiments show that InvariantSelectPR substantially improves the adaptability of LMMs, achieving significant performance gains on benchmark datasets, with a 34.2%$\\uparrow$ accuracy increase in 7-shot on Camelyon17 and 16.9%$\\uparrow$ increase in 7-shot on HAM10000 compared to the baseline zero-shot performance.","sentences":["Recent studies indicate that large multimodal models (LMMs) are highly robust against natural distribution shifts, often surpassing previous baselines.","Despite this, domain-specific adaptation is still necessary, particularly in specialized areas like healthcare.","Due to the impracticality of fine-tuning LMMs given their vast parameter space, this work investigates in-context learning (ICL) as an effective alternative for enhancing LMMs' adaptability.","We find that the success of ICL heavily relies on the choice of demonstration, mirroring challenges seen in large language models but introducing unique complexities for LMMs facing distribution shifts.","Our study addresses this by evaluating an unsupervised ICL method, TopKNearestPR, which selects in-context examples through a nearest example search based on feature similarity.","We uncover that its effectiveness is limited by the deficiencies of pre-trained vision encoders under distribution shift scenarios.","To address these challenges, we propose InvariantSelectPR, a novel method leveraging Class-conditioned Contrastive Invariance (CCI) for more robust demonstration selection.","Specifically, CCI enhances pre-trained vision encoders by improving their discriminative capabilities across different classes and ensuring invariance to domain-specific variations.","This enhancement allows the encoders to effectively identify and retrieve the most informative examples, which are then used to guide LMMs in adapting to new query samples under varying distributions.","Our experiments show that InvariantSelectPR substantially improves the adaptability of LMMs, achieving significant performance gains on benchmark datasets, with a 34.2%$\\uparrow$ accuracy increase in 7-shot on Camelyon17 and 16.9%$\\uparrow$ increase in 7-shot on HAM10000 compared to the baseline zero-shot performance."],"url":"http://arxiv.org/abs/2405.12217v1"}
{"created":"2024-05-20 17:57:01","title":"Octo: An Open-Source Generalist Robot Policy","abstract":"Large policies pretrained on diverse robot datasets have the potential to transform robotic learning: instead of training new policies from scratch, such generalist robot policies may be finetuned with only a little in-domain data, yet generalize broadly. However, to be widely applicable across a range of robotic learning scenarios, environments, and tasks, such policies need to handle diverse sensors and action spaces, accommodate a variety of commonly used robotic platforms, and finetune readily and efficiently to new domains. In this work, we aim to lay the groundwork for developing open-source, widely applicable, generalist policies for robotic manipulation. As a first step, we introduce Octo, a large transformer-based policy trained on 800k trajectories from the Open X-Embodiment dataset, the largest robot manipulation dataset to date. It can be instructed via language commands or goal images and can be effectively finetuned to robot setups with new sensory inputs and action spaces within a few hours on standard consumer GPUs. In experiments across 9 robotic platforms, we demonstrate that Octo serves as a versatile policy initialization that can be effectively finetuned to new observation and action spaces. We also perform detailed ablations of design decisions for the Octo model, from architecture to training data, to guide future research on building generalist robot models.","sentences":["Large policies pretrained on diverse robot datasets have the potential to transform robotic learning: instead of training new policies from scratch, such generalist robot policies may be finetuned with only a little in-domain data, yet generalize broadly.","However, to be widely applicable across a range of robotic learning scenarios, environments, and tasks, such policies need to handle diverse sensors and action spaces, accommodate a variety of commonly used robotic platforms, and finetune readily and efficiently to new domains.","In this work, we aim to lay the groundwork for developing open-source, widely applicable, generalist policies for robotic manipulation.","As a first step, we introduce Octo, a large transformer-based policy trained on 800k trajectories from the Open X-Embodiment dataset, the largest robot manipulation dataset to date.","It can be instructed via language commands or goal images and can be effectively finetuned to robot setups with new sensory inputs and action spaces within a few hours on standard consumer GPUs.","In experiments across 9 robotic platforms, we demonstrate that Octo serves as a versatile policy initialization that can be effectively finetuned to new observation and action spaces.","We also perform detailed ablations of design decisions for the Octo model, from architecture to training data, to guide future research on building generalist robot models."],"url":"http://arxiv.org/abs/2405.12213v1"}
{"created":"2024-05-20 17:55:56","title":"Slicedit: Zero-Shot Video Editing With Text-to-Image Diffusion Models Using Spatio-Temporal Slices","abstract":"Text-to-image (T2I) diffusion models achieve state-of-the-art results in image synthesis and editing. However, leveraging such pretrained models for video editing is considered a major challenge. Many existing works attempt to enforce temporal consistency in the edited video through explicit correspondence mechanisms, either in pixel space or between deep features. These methods, however, struggle with strong nonrigid motion. In this paper, we introduce a fundamentally different approach, which is based on the observation that spatiotemporal slices of natural videos exhibit similar characteristics to natural images. Thus, the same T2I diffusion model that is normally used only as a prior on video frames, can also serve as a strong prior for enhancing temporal consistency by applying it on spatiotemporal slices. Based on this observation, we present Slicedit, a method for text-based video editing that utilizes a pretrained T2I diffusion model to process both spatial and spatiotemporal slices. Our method generates videos that retain the structure and motion of the original video while adhering to the target text. Through extensive experiments, we demonstrate Slicedit's ability to edit a wide range of real-world videos, confirming its clear advantages compared to existing competing methods. Webpage: https://matankleiner.github.io/slicedit/","sentences":["Text-to-image (T2I) diffusion models achieve state-of-the-art results in image synthesis and editing.","However, leveraging such pretrained models for video editing is considered a major challenge.","Many existing works attempt to enforce temporal consistency in the edited video through explicit correspondence mechanisms, either in pixel space or between deep features.","These methods, however, struggle with strong nonrigid motion.","In this paper, we introduce a fundamentally different approach, which is based on the observation that spatiotemporal slices of natural videos exhibit similar characteristics to natural images.","Thus, the same T2I diffusion model that is normally used only as a prior on video frames, can also serve as a strong prior for enhancing temporal consistency by applying it on spatiotemporal slices.","Based on this observation, we present Slicedit, a method for text-based video editing that utilizes a pretrained T2I diffusion model to process both spatial and spatiotemporal slices.","Our method generates videos that retain the structure and motion of the original video while adhering to the target text.","Through extensive experiments, we demonstrate Slicedit's ability to edit a wide range of real-world videos, confirming its clear advantages compared to existing competing methods.","Webpage: https://matankleiner.github.io/slicedit/"],"url":"http://arxiv.org/abs/2405.12211v1"}
{"created":"2024-05-20 17:52:29","title":"MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark","abstract":"Recent advancements in large language models (LLMs) have showcased significant improvements in mathematics. However, traditional math benchmarks like GSM8k offer a unidimensional perspective, falling short in providing a holistic assessment of the LLMs' math capabilities. To address this gap, we introduce MathBench, a new benchmark that rigorously assesses the mathematical capabilities of large language models. MathBench spans a wide range of mathematical disciplines, offering a detailed evaluation of both theoretical understanding and practical problem-solving skills. The benchmark progresses through five distinct stages, from basic arithmetic to college mathematics, and is structured to evaluate models at various depths of knowledge. Each stage includes theoretical questions and application problems, allowing us to measure a model's mathematical proficiency and its ability to apply concepts in practical scenarios. MathBench aims to enhance the evaluation of LLMs' mathematical abilities, providing a nuanced view of their knowledge understanding levels and problem solving skills in a bilingual context. The project is released at https://github.com/open-compass/MathBench .","sentences":["Recent advancements in large language models (LLMs) have showcased significant improvements in mathematics.","However, traditional math benchmarks like GSM8k offer a unidimensional perspective, falling short in providing a holistic assessment of the LLMs' math capabilities.","To address this gap, we introduce MathBench, a new benchmark that rigorously assesses the mathematical capabilities of large language models.","MathBench spans a wide range of mathematical disciplines, offering a detailed evaluation of both theoretical understanding and practical problem-solving skills.","The benchmark progresses through five distinct stages, from basic arithmetic to college mathematics, and is structured to evaluate models at various depths of knowledge.","Each stage includes theoretical questions and application problems, allowing us to measure a model's mathematical proficiency and its ability to apply concepts in practical scenarios.","MathBench aims to enhance the evaluation of LLMs' mathematical abilities, providing a nuanced view of their knowledge understanding levels and problem solving skills in a bilingual context.","The project is released at https://github.com/open-compass/MathBench ."],"url":"http://arxiv.org/abs/2405.12209v1"}
{"created":"2024-05-20 17:47:18","title":"Optimistic Query Routing in Clustering-based Approximate Maximum Inner Product Search","abstract":"Clustering-based nearest neighbor search is a simple yet effective method in which data points are partitioned into geometric shards to form an index, and only a few shards are searched during query processing to find an approximate set of top-$k$ vectors. Even though the search efficacy is heavily influenced by the algorithm that identifies the set of shards to probe, it has received little attention in the literature. This work attempts to bridge that gap by studying the problem of routing in clustering-based maximum inner product search (MIPS). We begin by unpacking existing routing protocols and notice the surprising contribution of optimism. We then take a page from the sequential decision making literature and formalize that insight following the principle of ``optimism in the face of uncertainty.'' In particular, we present a new framework that incorporates the moments of the distribution of inner products within each shard to optimistically estimate the maximum inner product. We then present a simple instance of our algorithm that uses only the first two moments to reach the same accuracy as state-of-the-art routers such as \\scann by probing up to $50%$ fewer points on a suite of benchmark MIPS datasets. Our algorithm is also space-efficient: we design a sketch of the second moment whose size is independent of the number of points and in practice requires storing only $O(1)$ additional vectors per shard.","sentences":["Clustering-based nearest neighbor search is a simple yet effective method in which data points are partitioned into geometric shards to form an index, and only a few shards are searched during query processing to find an approximate set of top-$k$ vectors.","Even though the search efficacy is heavily influenced by the algorithm that identifies the set of shards to probe, it has received little attention in the literature.","This work attempts to bridge that gap by studying the problem of routing in clustering-based maximum inner product search (MIPS).","We begin by unpacking existing routing protocols and notice the surprising contribution of optimism.","We then take a page from the sequential decision making literature and formalize that insight following the principle of ``optimism in the face of uncertainty.''","In particular, we present a new framework that incorporates the moments of the distribution of inner products within each shard to optimistically estimate the maximum inner product.","We then present a simple instance of our algorithm that uses only the first two moments to reach the same accuracy as state-of-the-art routers such as \\scann by probing up to $50%$ fewer points on a suite of benchmark MIPS datasets.","Our algorithm is also space-efficient: we design a sketch of the second moment whose size is independent of the number of points and in practice requires storing only $O(1)$ additional vectors per shard."],"url":"http://arxiv.org/abs/2405.12207v1"}
{"created":"2024-05-20 17:45:36","title":"Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models","abstract":"Scientist learn early on how to cite scientific sources to support their claims. Sometimes, however, scientists have challenges determining where a citation should be situated -- or, even worse, fail to cite a source altogether. Automatically detecting sentences that need a citation (i.e., citation worthiness) could solve both of these issues, leading to more robust and well-constructed scientific arguments. Previous researchers have applied machine learning to this task but have used small datasets and models that do not take advantage of recent algorithmic developments such as attention mechanisms in deep learning. We hypothesize that we can develop significantly accurate deep learning architectures that learn from large supervised datasets constructed from open access publications. In this work, we propose a Bidirectional Long Short-Term Memory (BiLSTM) network with attention mechanism and contextual information to detect sentences that need citations. We also produce a new, large dataset (PMOA-CITE) based on PubMed Open Access Subset, which is orders of magnitude larger than previous datasets. Our experiments show that our architecture achieves state of the art performance on the standard ACL-ARC dataset ($F_{1}=0.507$) and exhibits high performance ($F_{1}=0.856$) on the new PMOA-CITE. Moreover, we show that it can transfer learning across these datasets. We further use interpretable models to illuminate how specific language is used to promote and inhibit citations. We discover that sections and surrounding sentences are crucial for our improved predictions. We further examined purported mispredictions of the model, and uncovered systematic human mistakes in citation behavior and source data. This opens the door for our model to check documents during pre-submission and pre-archival procedures. We make this new dataset, the code, and a web-based tool available to the community.","sentences":["Scientist learn early on how to cite scientific sources to support their claims.","Sometimes, however, scientists have challenges determining where a citation should be situated -- or, even worse, fail to cite a source altogether.","Automatically detecting sentences that need a citation (i.e., citation worthiness) could solve both of these issues, leading to more robust and well-constructed scientific arguments.","Previous researchers have applied machine learning to this task but have used small datasets and models that do not take advantage of recent algorithmic developments such as attention mechanisms in deep learning.","We hypothesize that we can develop significantly accurate deep learning architectures that learn from large supervised datasets constructed from open access publications.","In this work, we propose a Bidirectional Long Short-Term Memory (BiLSTM) network with attention mechanism and contextual information to detect sentences that need citations.","We also produce a new, large dataset (PMOA-CITE) based on PubMed Open Access Subset, which is orders of magnitude larger than previous datasets.","Our experiments show that our architecture achieves state of the art performance on the standard ACL-ARC dataset ($F_{1}=0.507$) and exhibits high performance ($F_{1}=0.856$) on the new PMOA-CITE.","Moreover, we show that it can transfer learning across these datasets.","We further use interpretable models to illuminate how specific language is used to promote and inhibit citations.","We discover that sections and surrounding sentences are crucial for our improved predictions.","We further examined purported mispredictions of the model, and uncovered systematic human mistakes in citation behavior and source data.","This opens the door for our model to check documents during pre-submission and pre-archival procedures.","We make this new dataset, the code, and a web-based tool available to the community."],"url":"http://arxiv.org/abs/2405.12206v1"}
{"created":"2024-05-20 17:45:26","title":"Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving","abstract":"Metacognitive knowledge refers to humans' intuitive knowledge of their own thinking and reasoning processes. Today's best LLMs clearly possess some reasoning processes. The paper gives evidence that they also have metacognitive knowledge, including ability to name skills and procedures to apply given a task. We explore this primarily in context of math reasoning, developing a prompt-guided interaction procedure to get a powerful LLM to assign sensible skill labels to math questions, followed by having it perform semantic clustering to obtain coarser families of skill labels. These coarse skill labels look interpretable to humans.   To validate that these skill labels are meaningful and relevant to the LLM's reasoning processes we perform the following experiments. (a) We ask GPT-4 to assign skill labels to training questions in math datasets GSM8K and MATH. (b) When using an LLM to solve the test questions, we present it with the full list of skill labels and ask it to identify the skill needed. Then it is presented with randomly selected exemplar solved questions associated with that skill label. This improves accuracy on GSM8k and MATH for several strong LLMs, including code-assisted models. The methodology presented is domain-agnostic, even though this article applies it to math problems.","sentences":["Metacognitive knowledge refers to humans' intuitive knowledge of their own thinking and reasoning processes.","Today's best LLMs clearly possess some reasoning processes.","The paper gives evidence that they also have metacognitive knowledge, including ability to name skills and procedures to apply given a task.","We explore this primarily in context of math reasoning, developing a prompt-guided interaction procedure to get a powerful LLM to assign sensible skill labels to math questions, followed by having it perform semantic clustering to obtain coarser families of skill labels.","These coarse skill labels look interpretable to humans.   ","To validate that these skill labels are meaningful and relevant to the LLM's reasoning processes we perform the following experiments.","(a) We ask GPT-4 to assign skill labels to training questions in math datasets GSM8K and MATH.","(b) When using an LLM to solve the test questions, we present it with the full list of skill labels and ask it to identify the skill needed.","Then it is presented with randomly selected exemplar solved questions associated with that skill label.","This improves accuracy on GSM8k and MATH for several strong LLMs, including code-assisted models.","The methodology presented is domain-agnostic, even though this article applies it to math problems."],"url":"http://arxiv.org/abs/2405.12205v1"}
{"created":"2024-05-20 17:41:19","title":"Accelerating Relative Entropy Coding with Space Partitioning","abstract":"Relative entropy coding (REC) algorithms encode a random sample following a target distribution $Q$, using a coding distribution $P$ shared between the sender and receiver. Sadly, general REC algorithms suffer from prohibitive encoding times, at least on the order of $2^{D_{\\text{KL}}[Q||P]}$, and faster algorithms are limited to very specific settings. This work addresses this issue by introducing a REC scheme utilizing space partitioning to reduce runtime in practical scenarios. We provide theoretical analyses of our method and demonstrate its effectiveness with both toy examples and practical applications. Notably, our method successfully handles REC tasks with $D_{\\text{KL}}[Q||P]$ about three times what previous methods can manage and reduces the compression rate by approximately 5-15\\% in VAE-based lossless compression on MNIST and INR-based lossy compression on CIFAR-10 compared to previous methods, significantly improving the practicality of REC for neural compression.","sentences":["Relative entropy coding (REC) algorithms encode a random sample following a target distribution $Q$, using a coding distribution $P$ shared between the sender and receiver.","Sadly, general REC algorithms suffer from prohibitive encoding times, at least on the order of $2^{D_{\\text{KL}}[Q||P]}$, and faster algorithms are limited to very specific settings.","This work addresses this issue by introducing a REC scheme utilizing space partitioning to reduce runtime in practical scenarios.","We provide theoretical analyses of our method and demonstrate its effectiveness with both toy examples and practical applications.","Notably, our method successfully handles REC tasks with $D_{\\text{KL}}[Q||P]$ about three times what previous methods can manage and reduces the compression rate by approximately 5-15\\% in VAE-based lossless compression on MNIST and INR-based lossy compression on CIFAR-10 compared to previous methods, significantly improving the practicality of REC for neural compression."],"url":"http://arxiv.org/abs/2405.12203v1"}
{"created":"2024-05-20 17:39:29","title":"Hierarchical Neural Operator Transformer with Learnable Frequency-aware Loss Prior for Arbitrary-scale Super-resolution","abstract":"In this work, we present an arbitrary-scale super-resolution (SR) method to enhance the resolution of scientific data, which often involves complex challenges such as continuity, multi-scale physics, and the intricacies of high-frequency signals. Grounded in operator learning, the proposed method is resolution-invariant. The core of our model is a hierarchical neural operator that leverages a Galerkin-type self-attention mechanism, enabling efficient learning of mappings between function spaces. Sinc filters are used to facilitate the information transfer across different levels in the hierarchy, thereby ensuring representation equivalence in the proposed neural operator. Additionally, we introduce a learnable prior structure that is derived from the spectral resizing of the input data. This loss prior is model-agnostic and is designed to dynamically adjust the weighting of pixel contributions, thereby balancing gradients effectively across the model. We conduct extensive experiments on diverse datasets from different domains and demonstrate consistent improvements compared to strong baselines, which consist of various state-of-the-art SR methods.","sentences":["In this work, we present an arbitrary-scale super-resolution (SR) method to enhance the resolution of scientific data, which often involves complex challenges such as continuity, multi-scale physics, and the intricacies of high-frequency signals.","Grounded in operator learning, the proposed method is resolution-invariant.","The core of our model is a hierarchical neural operator that leverages a Galerkin-type self-attention mechanism, enabling efficient learning of mappings between function spaces.","Sinc filters are used to facilitate the information transfer across different levels in the hierarchy, thereby ensuring representation equivalence in the proposed neural operator.","Additionally, we introduce a learnable prior structure that is derived from the spectral resizing of the input data.","This loss prior is model-agnostic and is designed to dynamically adjust the weighting of pixel contributions, thereby balancing gradients effectively across the model.","We conduct extensive experiments on diverse datasets from different domains and demonstrate consistent improvements compared to strong baselines, which consist of various state-of-the-art SR methods."],"url":"http://arxiv.org/abs/2405.12202v1"}
{"created":"2024-05-20 17:37:10","title":"Multi-View Attentive Contextualization for Multi-View 3D Object Detection","abstract":"We present Multi-View Attentive Contextualization (MvACon), a simple yet effective method for improving 2D-to-3D feature lifting in query-based multi-view 3D (MV3D) object detection. Despite remarkable progress witnessed in the field of query-based MV3D object detection, prior art often suffers from either the lack of exploiting high-resolution 2D features in dense attention-based lifting, due to high computational costs, or from insufficiently dense grounding of 3D queries to multi-scale 2D features in sparse attention-based lifting. Our proposed MvACon hits the two birds with one stone using a representationally dense yet computationally sparse attentive feature contextualization scheme that is agnostic to specific 2D-to-3D feature lifting approaches. In experiments, the proposed MvACon is thoroughly tested on the nuScenes benchmark, using both the BEVFormer and its recent 3D deformable attention (DFA3D) variant, as well as the PETR, showing consistent detection performance improvement, especially in enhancing performance in location, orientation, and velocity prediction. It is also tested on the Waymo-mini benchmark using BEVFormer with similar improvement. We qualitatively and quantitatively show that global cluster-based contexts effectively encode dense scene-level contexts for MV3D object detection. The promising results of our proposed MvACon reinforces the adage in computer vision -- ``(contextualized) feature matters\".","sentences":["We present Multi-View Attentive Contextualization (MvACon), a simple yet effective method for improving 2D-to-3D feature lifting in query-based multi-view 3D (MV3D) object detection.","Despite remarkable progress witnessed in the field of query-based MV3D object detection, prior art often suffers from either the lack of exploiting high-resolution 2D features in dense attention-based lifting, due to high computational costs, or from insufficiently dense grounding of 3D queries to multi-scale 2D features in sparse attention-based lifting.","Our proposed MvACon hits the two birds with one stone using a representationally dense yet computationally sparse attentive feature contextualization scheme that is agnostic to specific 2D-to-3D feature lifting approaches.","In experiments, the proposed MvACon is thoroughly tested on the nuScenes benchmark, using both the BEVFormer and its recent 3D deformable attention (DFA3D) variant, as well as the PETR, showing consistent detection performance improvement, especially in enhancing performance in location, orientation, and velocity prediction.","It is also tested on the Waymo-mini benchmark using BEVFormer with similar improvement.","We qualitatively and quantitatively show that global cluster-based contexts effectively encode dense scene-level contexts for MV3D object detection.","The promising results of our proposed MvACon reinforces the adage in computer vision -- ``(contextualized) feature matters\"."],"url":"http://arxiv.org/abs/2405.12200v1"}
{"created":"2024-05-20 17:33:00","title":"Automated Hardware Logic Obfuscation Framework Using GPT","abstract":"Obfuscation stands as a promising solution for safeguarding hardware intellectual property (IP) against a spectrum of threats including reverse engineering, IP piracy, and tampering. In this paper, we introduce Obfus-chat, a novel framework leveraging Generative Pre-trained Transformer (GPT) models to automate the obfuscation process. The proposed framework accepts hardware design netlists and key sizes as inputs, and autonomously generates obfuscated code tailored to enhance security. To evaluate the effectiveness of our approach, we employ the Trust-Hub Obfuscation Benchmark for comparative analysis. We employed SAT attacks to assess the security of the design, along with functional verification procedures to ensure that the obfuscated design remains consistent with the original. Our results demonstrate the efficacy and efficiency of the proposed framework in fortifying hardware IP against potential threats, thus providing a valuable contribution to the field of hardware security.","sentences":["Obfuscation stands as a promising solution for safeguarding hardware intellectual property (IP) against a spectrum of threats including reverse engineering, IP piracy, and tampering.","In this paper, we introduce Obfus-chat, a novel framework leveraging Generative Pre-trained Transformer (GPT) models to automate the obfuscation process.","The proposed framework accepts hardware design netlists and key sizes as inputs, and autonomously generates obfuscated code tailored to enhance security.","To evaluate the effectiveness of our approach, we employ the Trust-Hub Obfuscation Benchmark for comparative analysis.","We employed SAT attacks to assess the security of the design, along with functional verification procedures to ensure that the obfuscated design remains consistent with the original.","Our results demonstrate the efficacy and efficiency of the proposed framework in fortifying hardware IP against potential threats, thus providing a valuable contribution to the field of hardware security."],"url":"http://arxiv.org/abs/2405.12197v1"}
{"created":"2024-05-20 17:31:16","title":"Developers' Perceptions on the Impact of ChatGPT in Software Development: A Survey","abstract":"As Large Language Models (LLMs), including ChatGPT and analogous systems, continue to advance, their robust natural language processing capabilities and diverse applications have garnered considerable attention. Nonetheless, despite the increasing acknowledgment of the convergence of Artificial Intelligence (AI) and Software Engineering (SE), there is a lack of studies involving the impact of this convergence on the practices and perceptions of software developers. Understanding how software developers perceive and engage with AI tools, such as ChatGPT, is essential for elucidating the impact and potential challenges of incorporating AI-driven tools in the software development process. In this paper, we conducted a survey with 207 software developers to understand the impact of ChatGPT on software quality, productivity, and job satisfaction. Furthermore, the study delves into developers' expectations regarding future adaptations of ChatGPT, concerns about potential job displacement, and perspectives on regulatory interventions.","sentences":["As Large Language Models (LLMs), including ChatGPT and analogous systems, continue to advance, their robust natural language processing capabilities and diverse applications have garnered considerable attention.","Nonetheless, despite the increasing acknowledgment of the convergence of Artificial Intelligence (AI) and Software Engineering (SE), there is a lack of studies involving the impact of this convergence on the practices and perceptions of software developers.","Understanding how software developers perceive and engage with AI tools, such as ChatGPT, is essential for elucidating the impact and potential challenges of incorporating AI-driven tools in the software development process.","In this paper, we conducted a survey with 207 software developers to understand the impact of ChatGPT on software quality, productivity, and job satisfaction.","Furthermore, the study delves into developers' expectations regarding future adaptations of ChatGPT, concerns about potential job displacement, and perspectives on regulatory interventions."],"url":"http://arxiv.org/abs/2405.12195v1"}
{"created":"2024-05-20 17:26:43","title":"The Narrow Depth and Breadth of Corporate Responsible AI Research","abstract":"The transformative potential of AI presents remarkable opportunities, but also significant risks, underscoring the importance of responsible AI development and deployment. Despite a growing emphasis on this area, there is limited understanding of industry's engagement in responsible AI research, i.e., the critical examination of AI's ethical, social, and legal dimensions. To address this gap, we analyzed over 6 million peer-reviewed articles and 32 million patent citations using multiple methods across five distinct datasets to quantify industry's engagement. Our findings reveal that the majority of AI firms show limited or no engagement in this critical subfield of AI. We show a stark disparity between industry's dominant presence in conventional AI research and its limited engagement in responsible AI. Leading AI firms exhibit significantly lower output in responsible AI research compared to their conventional AI research and the contributions of leading academic institutions. Our linguistic analysis documents a narrower scope of responsible AI research within industry, with a lack of diversity in key topics addressed. Our large-scale patent citation analysis uncovers a pronounced disconnect between responsible AI research and the commercialization of AI technologies, suggesting that industry patents rarely build upon insights generated by the responsible AI literature. This gap highlights the potential for AI development to diverge from a socially optimal path, risking unintended consequences due to insufficient consideration of ethical and societal implications. Our results highlight the urgent need for industry to publicly engage in responsible AI research to absorb academic knowledge, cultivate public trust, and proactively mitigate AI-induced societal harms.","sentences":["The transformative potential of AI presents remarkable opportunities, but also significant risks, underscoring the importance of responsible AI development and deployment.","Despite a growing emphasis on this area, there is limited understanding of industry's engagement in responsible AI research, i.e., the critical examination of AI's ethical, social, and legal dimensions.","To address this gap, we analyzed over 6 million peer-reviewed articles and 32 million patent citations using multiple methods across five distinct datasets to quantify industry's engagement.","Our findings reveal that the majority of AI firms show limited or no engagement in this critical subfield of AI.","We show a stark disparity between industry's dominant presence in conventional AI research and its limited engagement in responsible AI.","Leading AI firms exhibit significantly lower output in responsible AI research compared to their conventional AI research and the contributions of leading academic institutions.","Our linguistic analysis documents a narrower scope of responsible AI research within industry, with a lack of diversity in key topics addressed.","Our large-scale patent citation analysis uncovers a pronounced disconnect between responsible AI research and the commercialization of AI technologies, suggesting that industry patents rarely build upon insights generated by the responsible AI literature.","This gap highlights the potential for AI development to diverge from a socially optimal path, risking unintended consequences due to insufficient consideration of ethical and societal implications.","Our results highlight the urgent need for industry to publicly engage in responsible AI research to absorb academic knowledge, cultivate public trust, and proactively mitigate AI-induced societal harms."],"url":"http://arxiv.org/abs/2405.12193v1"}
{"created":"2024-05-20 17:18:26","title":"Brewer-Nash Scrutinised: Mechanised Checking of Policies featuring Write Revocation","abstract":"This paper revisits the Brewer-Nash security policy model inspired by ethical Chinese Wall policies. We draw attention to the fact that write access can be revoked in the Brewer-Nash model. The semantics of write access were underspecified originally, leading to multiple interpretations for which we provide a modern operational semantics. We go on to modernise the analysis of information flow in the Brewer-Nash model, by adopting a more precise definition adapted from Kessler. For our modernised reformulation, we provide full mechanised coverage for all theorems proposed by Brewer & Nash. Most theorems are established automatically using the tool {log} with the exception of a theorem regarding information flow, which combines a lemma in {log} with a theorem mechanised in Coq. Having covered all theorems originally posed by Brewer-Nash, achieving modern precision and mechanisation, we propose this work as a step towards a methodology for automated checking of more complex security policy models.","sentences":["This paper revisits the Brewer-Nash security policy model inspired by ethical Chinese Wall policies.","We draw attention to the fact that write access can be revoked in the Brewer-Nash model.","The semantics of write access were underspecified originally, leading to multiple interpretations for which we provide a modern operational semantics.","We go on to modernise the analysis of information flow in the Brewer-Nash model, by adopting a more precise definition adapted from Kessler.","For our modernised reformulation, we provide full mechanised coverage for all theorems proposed by Brewer & Nash.","Most theorems are established automatically using the tool {log} with the exception of a theorem regarding information flow, which combines a lemma in {log} with a theorem mechanised in Coq.","Having covered all theorems originally posed by Brewer-Nash, achieving modern precision and mechanisation, we propose this work as a step towards a methodology for automated checking of more complex security policy models."],"url":"http://arxiv.org/abs/2405.12187v1"}
{"created":"2024-05-20 17:17:44","title":"Training Data Attribution via Approximate Unrolled Differentation","abstract":"Many training data attribution (TDA) methods aim to estimate how a model's behavior would change if one or more data points were removed from the training set. Methods based on implicit differentiation, such as influence functions, can be made computationally efficient, but fail to account for underspecification, the implicit bias of the optimization algorithm, or multi-stage training pipelines. By contrast, methods based on unrolling address these issues but face scalability challenges. In this work, we connect the implicit-differentiation-based and unrolling-based approaches and combine their benefits by introducing Source, an approximate unrolling-based TDA method that is computed using an influence-function-like formula. While being computationally efficient compared to unrolling-based approaches, Source is suitable in cases where implicit-differentiation-based approaches struggle, such as in non-converged models and multi-stage training pipelines. Empirically, Source outperforms existing TDA techniques in counterfactual prediction, especially in settings where implicit-differentiation-based approaches fall short.","sentences":["Many training data attribution (TDA) methods aim to estimate how a model's behavior would change if one or more data points were removed from the training set.","Methods based on implicit differentiation, such as influence functions, can be made computationally efficient, but fail to account for underspecification, the implicit bias of the optimization algorithm, or multi-stage training pipelines.","By contrast, methods based on unrolling address these issues but face scalability challenges.","In this work, we connect the implicit-differentiation-based and unrolling-based approaches and combine their benefits by introducing Source, an approximate unrolling-based TDA method that is computed using an influence-function-like formula.","While being computationally efficient compared to unrolling-based approaches, Source is suitable in cases where implicit-differentiation-based approaches struggle, such as in non-converged models and multi-stage training pipelines.","Empirically, Source outperforms existing TDA techniques in counterfactual prediction, especially in settings where implicit-differentiation-based approaches fall short."],"url":"http://arxiv.org/abs/2405.12186v1"}
{"created":"2024-05-20 17:09:58","title":"Multi-order Graph Clustering with Adaptive Node-level Weight Learning","abstract":"Current graph clustering methods emphasize individual node and edge con nections, while ignoring higher-order organization at the level of motif. Re cently, higher-order graph clustering approaches have been designed by motif based hypergraphs. However, these approaches often suffer from hypergraph fragmentation issue seriously, which degrades the clustering performance greatly. Moreover, real-world graphs usually contain diverse motifs, with nodes participating in multiple motifs. A key challenge is how to achieve precise clustering results by integrating information from multiple motifs at the node level. In this paper, we propose a multi-order graph clustering model (MOGC) to integrate multiple higher-order structures and edge connections at node level. MOGC employs an adaptive weight learning mechanism to au tomatically adjust the contributions of different motifs for each node. This not only tackles hypergraph fragmentation issue but enhances clustering accuracy. MOGC is efficiently solved by an alternating minimization algo rithm. Experiments on seven real-world datasets illustrate the effectiveness of MOGC.","sentences":["Current graph clustering methods emphasize individual node and edge con nections, while ignoring higher-order organization at the level of motif.","Re cently, higher-order graph clustering approaches have been designed by motif based hypergraphs.","However, these approaches often suffer from hypergraph fragmentation issue seriously, which degrades the clustering performance greatly.","Moreover, real-world graphs usually contain diverse motifs, with nodes participating in multiple motifs.","A key challenge is how to achieve precise clustering results by integrating information from multiple motifs at the node level.","In this paper, we propose a multi-order graph clustering model (MOGC) to integrate multiple higher-order structures and edge connections at node level.","MOGC employs an adaptive weight learning mechanism to au tomatically adjust the contributions of different motifs for each node.","This not only tackles hypergraph fragmentation issue but enhances clustering accuracy.","MOGC is efficiently solved by an alternating minimization algo rithm.","Experiments on seven real-world datasets illustrate the effectiveness of MOGC."],"url":"http://arxiv.org/abs/2405.12183v1"}
{"created":"2024-05-20 17:06:24","title":"Building Temporal Kernels with Orthogonal Polynomials","abstract":"We introduce a class of models named PLEIADES (PoLynomial Expansion In Adaptive Distributed Event-based Systems), which contains temporal convolution kernels generated from orthogonal polynomial basis functions. We focus on interfacing these networks with event-based data to perform online spatiotemporal classification and detection with low latency. By virtue of using structured temporal kernels and event-based data, we have the freedom to vary the sample rate of the data along with the discretization step-size of the network without additional finetuning. We experimented with three event-based benchmarks and obtained state-of-the-art results on all three by large margins with significantly smaller memory and compute costs. We achieved: 1) 99.59% accuracy with 192K parameters on the DVS128 hand gesture recognition dataset and 100% with a small additional output filter; 2) 99.58% test accuracy with 277K parameters on the AIS 2024 eye tracking challenge; and 3) 0.556 mAP with 576k parameters on the PROPHESEE 1 Megapixel Automotive Detection Dataset.","sentences":["We introduce a class of models named PLEIADES (PoLynomial Expansion In Adaptive Distributed Event-based Systems), which contains temporal convolution kernels generated from orthogonal polynomial basis functions.","We focus on interfacing these networks with event-based data to perform online spatiotemporal classification and detection with low latency.","By virtue of using structured temporal kernels and event-based data, we have the freedom to vary the sample rate of the data along with the discretization step-size of the network without additional finetuning.","We experimented with three event-based benchmarks and obtained state-of-the-art results on all three by large margins with significantly smaller memory and compute costs.","We achieved: 1) 99.59% accuracy with 192K parameters on the DVS128 hand gesture recognition dataset and 100% with a small additional output filter; 2) 99.58% test accuracy with 277K parameters on the AIS 2024 eye tracking challenge; and 3) 0.556 mAP with 576k parameters on the PROPHESEE 1 Megapixel Automotive Detection Dataset."],"url":"http://arxiv.org/abs/2405.12179v1"}
{"created":"2024-05-20 17:02:18","title":"Establishing Trust in the Beyond-5G Core Network using Trusted Execution Environments","abstract":"The fifth generation (5G) of cellular networks starts a paradigm shift from the traditional monolithic system design to a Service Based Architecture, that fits modern performance requirements and scales efficiently to new services. This paradigm will be the foundation of future cellular core networks beyond 5G. The new architecture splits network functionalities into smaller logical entities that can be disaggregated logically, physically, and geographically. This affords interoperability between the mobile network operators and commercial software and hardware vendors or cloud providers. By making use of commodity services and products, this system construct inherits the vulnerabilities in those underlying technologies, thereby increasing its attack surface and requiring a rigorous security analysis. In this work, we review the security implications introduced in B5G networks, and the security mechanisms that are supported by the 5G standard. We emphasize on the support of Zero Trust Architecture in 5G and its relevance in decentralized deployments. We revisit the definition of trust in modern enterprise network operations and identify important Zero Trust properties that are weakened by the nature of cloud deployments. To that end, we propose a vertical extension of Zero Trust, namely, Zero Trust Execution, to model untrusted execution environments, and we provide an analysis on how to establish trust in Beyond-5G network architectures using Trusted Execution Environments. Our analysis shows how our model architecture handles the increased attack surface and reinforces the Zero Trust Architecture principles in the 5G Core, without any changes to the 5G standard. Finally, we provide experimental results over a 5G testbed using Open5GS and UERANSIM that demonstrate minimal performance overhead, and a monetary cost evaluation.","sentences":["The fifth generation (5G) of cellular networks starts a paradigm shift from the traditional monolithic system design to a Service Based Architecture, that fits modern performance requirements and scales efficiently to new services.","This paradigm will be the foundation of future cellular core networks beyond 5G.","The new architecture splits network functionalities into smaller logical entities that can be disaggregated logically, physically, and geographically.","This affords interoperability between the mobile network operators and commercial software and hardware vendors or cloud providers.","By making use of commodity services and products, this system construct inherits the vulnerabilities in those underlying technologies, thereby increasing its attack surface and requiring a rigorous security analysis.","In this work, we review the security implications introduced in B5G networks, and the security mechanisms that are supported by the 5G standard.","We emphasize on the support of Zero Trust Architecture in 5G and its relevance in decentralized deployments.","We revisit the definition of trust in modern enterprise network operations and identify important Zero Trust properties that are weakened by the nature of cloud deployments.","To that end, we propose a vertical extension of Zero Trust, namely, Zero Trust Execution, to model untrusted execution environments, and we provide an analysis on how to establish trust in Beyond-5G network architectures using Trusted Execution Environments.","Our analysis shows how our model architecture handles the increased attack surface and reinforces the Zero Trust Architecture principles in the 5G Core, without any changes to the 5G standard.","Finally, we provide experimental results over a 5G testbed using Open5GS and UERANSIM that demonstrate minimal performance overhead, and a monetary cost evaluation."],"url":"http://arxiv.org/abs/2405.12177v1"}
{"created":"2024-05-20 16:58:24","title":"Enhancing Explainable AI: A Hybrid Approach Combining GradCAM and LRP for CNN Interpretability","abstract":"We present a new technique that explains the output of a CNN-based model using a combination of GradCAM and LRP methods. Both of these methods produce visual explanations by highlighting input regions that are important for predictions. In the new method, the explanation produced by GradCAM is first processed to remove noises. The processed output is then multiplied elementwise with the output of LRP. Finally, a Gaussian blur is applied on the product. We compared the proposed method with GradCAM and LRP on the metrics of Faithfulness, Robustness, Complexity, Localisation and Randomisation. It was observed that this method performs better on Complexity than both GradCAM and LRP and is better than atleast one of them in the other metrics.","sentences":["We present a new technique that explains the output of a CNN-based model using a combination of GradCAM and LRP methods.","Both of these methods produce visual explanations by highlighting input regions that are important for predictions.","In the new method, the explanation produced by GradCAM is first processed to remove noises.","The processed output is then multiplied elementwise with the output of LRP.","Finally, a Gaussian blur is applied on the product.","We compared the proposed method with GradCAM and LRP on the metrics of Faithfulness, Robustness, Complexity, Localisation and Randomisation.","It was observed that this method performs better on Complexity than both GradCAM and LRP and is better than atleast one of them in the other metrics."],"url":"http://arxiv.org/abs/2405.12175v1"}
{"created":"2024-05-20 16:58:02","title":"CT-Eval: Benchmarking Chinese Text-to-Table Performance in Large Language Models","abstract":"Text-to-Table aims to generate structured tables to convey the key information from unstructured documents. Existing text-to-table datasets are typically oriented English, limiting the research in non-English languages. Meanwhile, the emergence of large language models (LLMs) has shown great success as general task solvers in multi-lingual settings (e.g., ChatGPT), theoretically enabling text-to-table in other languages. In this paper, we propose a Chinese text-to-table dataset, CT-Eval, to benchmark LLMs on this task. Our preliminary analysis of English text-to-table datasets highlights two key factors for dataset construction: data diversity and data hallucination. Inspired by this, the CT-Eval dataset selects a popular Chinese multidisciplinary online encyclopedia as the source and covers 28 domains to ensure data diversity. To minimize data hallucination, we first train an LLM to judge and filter out the task samples with hallucination, then employ human annotators to clean the hallucinations in the validation and testing sets. After this process, CT-Eval contains 88.6K task samples. Using CT-Eval, we evaluate the performance of open-source and closed-source LLMs. Our results reveal that zero-shot LLMs (including GPT-4) still have a significant performance gap compared with human judgment. Furthermore, after fine-tuning, open-source LLMs can significantly improve their text-to-table ability, outperforming GPT-4 by a large margin. In short, CT-Eval not only helps researchers evaluate and quickly understand the Chinese text-to-table ability of existing LLMs but also serves as a valuable resource to significantly improve the text-to-table performance of LLMs.","sentences":["Text-to-Table aims to generate structured tables to convey the key information from unstructured documents.","Existing text-to-table datasets are typically oriented English, limiting the research in non-English languages.","Meanwhile, the emergence of large language models (LLMs) has shown great success as general task solvers in multi-lingual settings (e.g., ChatGPT), theoretically enabling text-to-table in other languages.","In this paper, we propose a Chinese text-to-table dataset, CT-Eval, to benchmark LLMs on this task.","Our preliminary analysis of English text-to-table datasets highlights two key factors for dataset construction: data diversity and data hallucination.","Inspired by this, the CT-Eval dataset selects a popular Chinese multidisciplinary online encyclopedia as the source and covers 28 domains to ensure data diversity.","To minimize data hallucination, we first train an LLM to judge and filter out the task samples with hallucination, then employ human annotators to clean the hallucinations in the validation and testing sets.","After this process, CT-Eval contains 88.6K task samples.","Using CT-Eval, we evaluate the performance of open-source and closed-source LLMs.","Our results reveal that zero-shot LLMs (including GPT-4) still have a significant performance gap compared with human judgment.","Furthermore, after fine-tuning, open-source LLMs can significantly improve their text-to-table ability, outperforming GPT-4 by a large margin.","In short, CT-Eval not only helps researchers evaluate and quickly understand the Chinese text-to-table ability of existing LLMs but also serves as a valuable resource to significantly improve the text-to-table performance of LLMs."],"url":"http://arxiv.org/abs/2405.12174v1"}
{"created":"2024-05-20 16:55:05","title":"State of the Practice for Medical Imaging Software","abstract":"We selected 29 medical imaging projects from 48 candidates, assessed 10 software qualities by answering 108 questions for each software project, and interviewed 8 of the 29 development teams. Based on the quantitative data, we ranked the MI software with the Analytic Hierarchy Process (AHP). The four top-ranked software products are 3D Slicer, ImageJ, Fiji, and OHIF Viewer. Generally, MI software is in a healthy state as shown by the following: we observed 88% of the documentation artifacts recommended by research software development guidelines, 100% of MI projects use version control tools, and developers appear to use the common quasi-agile research software development process. However, the current state of the practice deviates from the existing guidelines because of the rarity of some recommended artifacts, low usage of continuous integration (17% of the projects), low use of unit testing (about 50% of projects), and room for improvement with documentation (six of nine developers felt their documentation was not clear enough). From interviewing the developers, we identified five pain points and two qualities of potential concern: lack of development time, lack of funding, technology hurdles, ensuring correctness, usability, maintainability, and reproducibility. The interviewees proposed strategies to improve the state of the practice, to address the identified pain points, and to improve software quality. Combining their ideas with ours, we have the following list of recommendations: increase documentation, increase testing by enriching datasets, increase continuous integration usage, move to web applications, employ linters, use peer reviews, design for change, add assurance cases, and incorporate a \"Generate All Things\" approach.","sentences":["We selected 29 medical imaging projects from 48 candidates, assessed 10 software qualities by answering 108 questions for each software project, and interviewed 8 of the 29 development teams.","Based on the quantitative data, we ranked the MI software with the Analytic Hierarchy Process (AHP).","The four top-ranked software products are 3D Slicer, ImageJ, Fiji, and OHIF Viewer.","Generally, MI software is in a healthy state as shown by the following: we observed 88% of the documentation artifacts recommended by research software development guidelines, 100% of MI projects use version control tools, and developers appear to use the common quasi-agile research software development process.","However, the current state of the practice deviates from the existing guidelines because of the rarity of some recommended artifacts, low usage of continuous integration (17% of the projects), low use of unit testing (about 50% of projects), and room for improvement with documentation (six of nine developers felt their documentation was not clear enough).","From interviewing the developers, we identified five pain points and two qualities of potential concern: lack of development time, lack of funding, technology hurdles, ensuring correctness, usability, maintainability, and reproducibility.","The interviewees proposed strategies to improve the state of the practice, to address the identified pain points, and to improve software quality.","Combining their ideas with ours, we have the following list of recommendations: increase documentation, increase testing by enriching datasets, increase continuous integration usage, move to web applications, employ linters, use peer reviews, design for change, add assurance cases, and incorporate a \"Generate All Things\" approach."],"url":"http://arxiv.org/abs/2405.12171v1"}
{"created":"2024-05-20 16:52:33","title":"WiDRa -- Enabling Millimeter-Level Differential Ranging Accuracy in Wi-Fi Using Carrier Phase","abstract":"Although Wi-Fi is an ideal technology for many ranging applications, the performance of current methods is limited by the system bandwidth, leading to low accuracy of $\\sim 1$ m. For many applications, measuring differential range, viz., the change in the range between adjacent measurements, is sufficient. Correspondingly, this work proposes WiDRa - a Wi-Fi based Differential Ranging solution that provides differential range estimates by using the sum-carrier-phase information. The proposed method is not limited by system bandwidth and can track range changes even smaller than the carrier wavelength. The proposed method is first theoretically justified, while taking into consideration the various hardware impairments affecting Wi-Fi chips. In the process, methods to isolate the sum-carrier phase from the hardware impairments are proposed. Extensive simulation results show that WiDRa can achieve a differential range estimation root-mean-square-error (RMSE) of $\\approx 1$ mm in channels with a Rician-factor $\\geq 7$ (a $100 \\times$ improvement to existing methods). The proposed methods are also validated on off-the-shelf Wi-Fi hardware to demonstrate feasibility, where they achieve an RMSE of $< 1$ mm in the differential range. Finally, limitations of current investigation and future directions of exploration are suggested, to further tap into the potential of WiDRa.","sentences":["Although Wi-Fi is an ideal technology for many ranging applications, the performance of current methods is limited by the system bandwidth, leading to low accuracy of $\\sim 1$ m. For many applications, measuring differential range, viz., the change in the range between adjacent measurements, is sufficient.","Correspondingly, this work proposes WiDRa - a Wi-Fi based Differential Ranging solution that provides differential range estimates by using the sum-carrier-phase information.","The proposed method is not limited by system bandwidth and can track range changes even smaller than the carrier wavelength.","The proposed method is first theoretically justified, while taking into consideration the various hardware impairments affecting Wi-Fi chips.","In the process, methods to isolate the sum-carrier phase from the hardware impairments are proposed.","Extensive simulation results show that WiDRa can achieve a differential range estimation root-mean-square-error (RMSE) of $\\approx 1$ mm in channels with a Rician-factor $\\geq 7$ (a $100 \\times$ improvement to existing methods).","The proposed methods are also validated on off-the-shelf Wi-Fi hardware to demonstrate feasibility, where they achieve an RMSE of $< 1$ mm in the differential range.","Finally, limitations of current investigation and future directions of exploration are suggested, to further tap into the potential of WiDRa."],"url":"http://arxiv.org/abs/2405.12168v1"}
{"created":"2024-05-20 16:51:25","title":"Open-Source Assessments of AI Capabilities: The Proliferation of AI Analysis Tools, Replicating Competitor Models, and the Zhousidun Dataset","abstract":"The integration of artificial intelligence (AI) into military capabilities has become a norm for major military power across the globe. Understanding how these AI models operate is essential for maintaining strategic advantages and ensuring security. This paper demonstrates an open-source methodology for analyzing military AI models through a detailed examination of the Zhousidun dataset, a Chinese-originated dataset that exhaustively labels critical components on American and Allied destroyers. By demonstrating the replication of a state-of-the-art computer vision model on this dataset, we illustrate how open-source tools can be leveraged to assess and understand key military AI capabilities. This methodology offers a robust framework for evaluating the performance and potential of AI-enabled military capabilities, thus enhancing the accuracy and reliability of strategic assessments.","sentences":["The integration of artificial intelligence (AI) into military capabilities has become a norm for major military power across the globe.","Understanding how these AI models operate is essential for maintaining strategic advantages and ensuring security.","This paper demonstrates an open-source methodology for analyzing military AI models through a detailed examination of the Zhousidun dataset, a Chinese-originated dataset that exhaustively labels critical components on American and Allied destroyers.","By demonstrating the replication of a state-of-the-art computer vision model on this dataset, we illustrate how open-source tools can be leveraged to assess and understand key military AI capabilities.","This methodology offers a robust framework for evaluating the performance and potential of AI-enabled military capabilities, thus enhancing the accuracy and reliability of strategic assessments."],"url":"http://arxiv.org/abs/2405.12167v1"}
{"created":"2024-05-20 16:47:22","title":"Fennec: Fine-grained Language Model Evaluation and Correction Extended through Branching and Bridging","abstract":"The rapid advancement of large language models has given rise to a plethora of applications across a myriad of real-world tasks, mainly centered on aligning with human intent. However, the complexities inherent in human intent necessitate a dependence on labor-intensive and time-consuming human evaluation. To alleviate this constraint, we delve into the paradigm of employing open-source large language models as evaluators, aligning with the prevailing trend of utilizing GPT-4. Particularly, we present a step-by-step evaluation framework: \\textbf{Fennec}, capable of \\textbf{F}ine-grained \\textbf{E}valuatio\\textbf{N} and correctio\\textbf{N} \\textbf{E}xtended through bran\\textbf{C}hing and bridging. Specifically, the branching operation dissects the evaluation task into various dimensions and granularities, thereby alleviating the challenges associated with evaluation. Concurrently, the bridging operation amalgamates diverse training datasets, augmenting the variety of evaluation tasks. In experimental trials, our 7B model consistently outperforms open-source larger-scale evaluation models across various widely adopted benchmarks in terms of both \\textit{Agreement} and \\textit{Consistency}, closely approaching the capabilities of GPT-4. We employ the fine-grained correction capabilities induced by the evaluation model to refine multiple model responses, and the results show that the refinement elevates the quality of responses, leading to an improvement of 1-2 points on the MT-Bench. Our code is available at Github\\footnote{\\url{https://github.com/dropreg/Fennec}}.","sentences":["The rapid advancement of large language models has given rise to a plethora of applications across a myriad of real-world tasks, mainly centered on aligning with human intent.","However, the complexities inherent in human intent necessitate a dependence on labor-intensive and time-consuming human evaluation.","To alleviate this constraint, we delve into the paradigm of employing open-source large language models as evaluators, aligning with the prevailing trend of utilizing GPT-4.","Particularly, we present a step-by-step evaluation framework: \\textbf{Fennec}, capable of \\textbf{F}ine-grained \\textbf{E}valuatio\\textbf{N} and correctio\\textbf{N} \\textbf{E}xtended through bran\\textbf{C}hing and bridging.","Specifically, the branching operation dissects the evaluation task into various dimensions and granularities, thereby alleviating the challenges associated with evaluation.","Concurrently, the bridging operation amalgamates diverse training datasets, augmenting the variety of evaluation tasks.","In experimental trials, our 7B model consistently outperforms open-source larger-scale evaluation models across various widely adopted benchmarks in terms of both \\textit{Agreement} and \\textit{Consistency}, closely approaching the capabilities of GPT-4.","We employ the fine-grained correction capabilities induced by the evaluation model to refine multiple model responses, and the results show that the refinement elevates the quality of responses, leading to an improvement of 1-2 points on the MT-Bench.","Our code is available at Github\\footnote{\\url{https://github.com/dropreg/Fennec}}."],"url":"http://arxiv.org/abs/2405.12163v1"}
{"created":"2024-05-20 16:32:37","title":"Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents","abstract":"The efficient representation, transmission, and reconstruction of three-dimensional (3D) contents are becoming increasingly important for sixth-generation (6G) networks that aim to merge virtual and physical worlds for offering immersive communication experiences. Neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) have recently emerged as two promising 3D representation techniques based on radiance field rendering, which are able to provide photorealistic rendering results for complex scenes. Therefore, embracing NeRF and 3D-GS in 6G networks is envisioned to be a prominent solution to support emerging 3D applications with enhanced quality of experience. This paper provides a comprehensive overview on the integration of NeRF and 3D-GS in 6G. First, we review the basics of the radiance field rendering techniques, and highlight their applications and implementation challenges over wireless networks. Next, we consider the over-the-air training of NeRF and 3D-GS models over wireless networks by presenting various learning techniques. We particularly focus on the federated learning design over a hierarchical device-edge-cloud architecture. Then, we discuss three practical rendering architectures of NeRF and 3D-GS models at wireless network edge. We provide model compression approaches to facilitate the transmission of radiance field models, and present rendering acceleration approaches and joint computation and communication designs to enhance the rendering efficiency. In particular, we propose a new semantic communication enabled 3D content transmission design, in which the radiance field models are exploited as the semantic knowledge base to reduce the communication overhead for distributed inference. Furthermore, we present the utilization of radiance field rendering in wireless applications like radio mapping and radio imaging.","sentences":["The efficient representation, transmission, and reconstruction of three-dimensional (3D) contents are becoming increasingly important for sixth-generation (6G) networks that aim to merge virtual and physical worlds for offering immersive communication experiences.","Neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) have recently emerged as two promising 3D representation techniques based on radiance field rendering, which are able to provide photorealistic rendering results for complex scenes.","Therefore, embracing NeRF and 3D-GS in 6G networks is envisioned to be a prominent solution to support emerging 3D applications with enhanced quality of experience.","This paper provides a comprehensive overview on the integration of NeRF and 3D-GS in 6G. First, we review the basics of the radiance field rendering techniques, and highlight their applications and implementation challenges over wireless networks.","Next, we consider the over-the-air training of NeRF and 3D-GS models over wireless networks by presenting various learning techniques.","We particularly focus on the federated learning design over a hierarchical device-edge-cloud architecture.","Then, we discuss three practical rendering architectures of NeRF and 3D-GS models at wireless network edge.","We provide model compression approaches to facilitate the transmission of radiance field models, and present rendering acceleration approaches and joint computation and communication designs to enhance the rendering efficiency.","In particular, we propose a new semantic communication enabled 3D content transmission design, in which the radiance field models are exploited as the semantic knowledge base to reduce the communication overhead for distributed inference.","Furthermore, we present the utilization of radiance field rendering in wireless applications like radio mapping and radio imaging."],"url":"http://arxiv.org/abs/2405.12155v1"}
{"created":"2024-05-20 16:27:25","title":"A Nearly Quadratic Improvement for Memory Reallocation","abstract":"In the Memory Reallocation Problem a set of items of various sizes must be dynamically assigned to non-overlapping contiguous chunks of memory. It is guaranteed that the sum of the sizes of all items present at any time is at most a $(1-\\varepsilon)$-fraction of the total size of memory (i.e., the load-factor is at most $1-\\varepsilon$). The allocator receives insert and delete requests online, and can re-arrange existing items to handle the requests, but at a reallocation cost defined to be the sum of the sizes of items moved divided by the size of the item being inserted/deleted.   The folklore algorithm for Memory Reallocation achieves a cost of $O(\\varepsilon^{-1})$ per update. In recent work at FOCS'23, Kuszmaul showed that, in the special case where each item is promised to be smaller than an $\\varepsilon^4$-fraction of memory, it is possible to achieve expected update cost $O(\\log\\varepsilon^{-1})$. Kuszmaul conjectures, however, that for larger items the folklore algorithm is optimal.   In this work we disprove Kuszmaul's conjecture, giving an allocator that achieves expected update cost $O(\\varepsilon^{-1/2} \\operatorname*{polylog} \\varepsilon^{-1})$ on any input sequence. We also give the first non-trivial lower bound for the Memory Reallocation Problem: we demonstrate an input sequence on which any resizable allocator (even offline) must incur amortized update cost at least $\\Omega(\\log\\varepsilon^{-1})$.   Finally, we analyze the Memory Reallocation Problem on a stochastic sequence of inserts and deletes, with random sizes in $[\\delta, 2 \\delta]$ for some $\\delta$. We show that, in this simplified setting, it is possible to achieve $O(\\log\\varepsilon^{-1})$ expected update cost, even in the ``large item'' parameter regime ($\\delta > \\varepsilon^4$).","sentences":["In the Memory Reallocation Problem a set of items of various sizes must be dynamically assigned to non-overlapping contiguous chunks of memory.","It is guaranteed that the sum of the sizes of all items present at any time is at most a $(1-\\varepsilon)$-fraction of the total size of memory (i.e., the load-factor is at most $1-\\varepsilon$).","The allocator receives insert and delete requests online, and can re-arrange existing items to handle the requests, but at a reallocation cost defined to be the sum of the sizes of items moved divided by the size of the item being inserted/deleted.   ","The folklore algorithm for Memory Reallocation achieves a cost of $O(\\varepsilon^{-1})$ per update.","In recent work at FOCS'23, Kuszmaul showed that, in the special case where each item is promised to be smaller than an $\\varepsilon^4$-fraction of memory, it is possible to achieve expected update cost $O(\\log\\varepsilon^{-1})$. Kuszmaul conjectures, however, that for larger items the folklore algorithm is optimal.   ","In this work we disprove Kuszmaul's conjecture, giving an allocator that achieves expected update cost $O(\\varepsilon^{-1/2} \\operatorname*{polylog} \\varepsilon^{-1})$ on any input sequence.","We also give the first non-trivial lower bound for the Memory Reallocation Problem: we demonstrate an input sequence on which any resizable allocator (even offline) must incur amortized update cost at least $\\Omega(\\log\\varepsilon^{-1})$.   Finally, we analyze the Memory Reallocation Problem on a stochastic sequence of inserts and deletes, with random sizes in $[\\delta, 2 \\delta]$ for some $\\delta$. We show that, in this simplified setting, it is possible to achieve $O(\\log\\varepsilon^{-1})$ expected update cost, even in the ``large item'' parameter regime ($\\delta > \\varepsilon^4$)."],"url":"http://arxiv.org/abs/2405.12152v1"}
{"created":"2024-05-20 16:23:40","title":"Bangladeshi Native Vehicle Detection in Wild","abstract":"The success of autonomous navigation relies on robust and precise vehicle recognition, hindered by the scarcity of region-specific vehicle detection datasets, impeding the development of context-aware systems. To advance terrestrial object detection research, this paper proposes a native vehicle detection dataset for the most commonly appeared vehicle classes in Bangladesh. 17 distinct vehicle classes have been taken into account, with fully annotated 81542 instances of 17326 images. Each image width is set to at least 1280px. The dataset's average vehicle bounding box-to-image ratio is 4.7036. This Bangladesh Native Vehicle Dataset (BNVD) has accounted for several geographical, illumination, variety of vehicle sizes, and orientations to be more robust on surprised scenarios. In the context of examining the BNVD dataset, this work provides a thorough assessment with four successive You Only Look Once (YOLO) models, namely YOLO v5, v6, v7, and v8. These dataset's effectiveness is methodically evaluated and contrasted with other vehicle datasets already in use. The BNVD dataset exhibits mean average precision(mAP) at 50% intersection over union (IoU) is 0.848 corresponding precision and recall values of 0.841 and 0.774. The research findings indicate a mAP of 0.643 at an IoU range of 0.5 to 0.95. The experiments show that the BNVD dataset serves as a reliable representation of vehicle distribution and presents considerable complexities.","sentences":["The success of autonomous navigation relies on robust and precise vehicle recognition, hindered by the scarcity of region-specific vehicle detection datasets, impeding the development of context-aware systems.","To advance terrestrial object detection research, this paper proposes a native vehicle detection dataset for the most commonly appeared vehicle classes in Bangladesh.","17 distinct vehicle classes have been taken into account, with fully annotated 81542 instances of 17326 images.","Each image width is set to at least 1280px.","The dataset's average vehicle bounding box-to-image ratio is 4.7036.","This Bangladesh Native Vehicle Dataset (BNVD) has accounted for several geographical, illumination, variety of vehicle sizes, and orientations to be more robust on surprised scenarios.","In the context of examining the BNVD dataset, this work provides a thorough assessment with four successive You Only Look Once (YOLO) models, namely YOLO v5, v6, v7, and v8.","These dataset's effectiveness is methodically evaluated and contrasted with other vehicle datasets already in use.","The BNVD dataset exhibits mean average precision(mAP) at 50% intersection over union (IoU) is 0.848 corresponding precision and recall values of 0.841 and 0.774.","The research findings indicate a mAP of 0.643 at an IoU range of 0.5 to 0.95.","The experiments show that the BNVD dataset serves as a reliable representation of vehicle distribution and presents considerable complexities."],"url":"http://arxiv.org/abs/2405.12150v1"}
{"created":"2024-05-20 16:19:02","title":"Eliciting Problem Specifications via Large Language Models","abstract":"Cognitive systems generally require a human to translate a problem definition into some specification that the cognitive system can use to attempt to solve the problem or perform the task. In this paper, we illustrate that large language models (LLMs) can be utilized to map a problem class, defined in natural language, into a semi-formal specification that can then be utilized by an existing reasoning and learning system to solve instances from the problem class. We present the design of LLM-enabled cognitive task analyst agent(s). Implemented with LLM agents, this system produces a definition of problem spaces for tasks specified in natural language. LLM prompts are derived from the definition of problem spaces in the AI literature and general problem-solving strategies (Polya's How to Solve It). A cognitive system can then use the problem-space specification, applying domain-general problem solving strategies (\"weak methods\" such as search), to solve multiple instances of problems from the problem class. This result, while preliminary, suggests the potential for speeding cognitive systems research via disintermediation of problem formulation while also retaining core capabilities of cognitive systems, such as robust inference and online learning.","sentences":["Cognitive systems generally require a human to translate a problem definition into some specification that the cognitive system can use to attempt to solve the problem or perform the task.","In this paper, we illustrate that large language models (LLMs) can be utilized to map a problem class, defined in natural language, into a semi-formal specification that can then be utilized by an existing reasoning and learning system to solve instances from the problem class.","We present the design of LLM-enabled cognitive task analyst agent(s).","Implemented with LLM agents, this system produces a definition of problem spaces for tasks specified in natural language.","LLM prompts are derived from the definition of problem spaces in the AI literature and general problem-solving strategies (Polya's How to Solve It).","A cognitive system can then use the problem-space specification, applying domain-general problem solving strategies (\"weak methods\" such as search), to solve multiple instances of problems from the problem class.","This result, while preliminary, suggests the potential for speeding cognitive systems research via disintermediation of problem formulation while also retaining core capabilities of cognitive systems, such as robust inference and online learning."],"url":"http://arxiv.org/abs/2405.12147v1"}
{"created":"2024-05-20 16:01:01","title":"DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM","abstract":"Visual Language Tracking (VLT) enhances single object tracking (SOT) by integrating natural language descriptions from a video, for the precise tracking of a specified object. By leveraging high-level semantic information, VLT guides object tracking, alleviating the constraints associated with relying on a visual modality. Nevertheless, most VLT benchmarks are annotated in a single granularity and lack a coherent semantic framework to provide scientific guidance. Moreover, coordinating human annotators for high-quality annotations is laborious and time-consuming. To address these challenges, we introduce DTLLM-VLT, which automatically generates extensive and multi-granularity text to enhance environmental diversity. (1) DTLLM-VLT generates scientific and multi-granularity text descriptions using a cohesive prompt framework. Its succinct and highly adaptable design allows seamless integration into various visual tracking benchmarks. (2) We select three prominent benchmarks to deploy our approach: short-term tracking, long-term tracking, and global instance tracking. We offer four granularity combinations for these benchmarks, considering the extent and density of semantic information, thereby showcasing the practicality and versatility of DTLLM-VLT. (3) We conduct comparative experiments on VLT benchmarks with different text granularities, evaluating and analyzing the impact of diverse text on tracking performance. Conclusionally, this work leverages LLM to provide multi-granularity semantic information for VLT task from efficient and diverse perspectives, enabling fine-grained evaluation of multi-modal trackers. In the future, we believe this work can be extended to more datasets to support vision datasets understanding.","sentences":["Visual Language Tracking (VLT) enhances single object tracking (SOT) by integrating natural language descriptions from a video, for the precise tracking of a specified object.","By leveraging high-level semantic information, VLT guides object tracking, alleviating the constraints associated with relying on a visual modality.","Nevertheless, most VLT benchmarks are annotated in a single granularity and lack a coherent semantic framework to provide scientific guidance.","Moreover, coordinating human annotators for high-quality annotations is laborious and time-consuming.","To address these challenges, we introduce DTLLM-VLT, which automatically generates extensive and multi-granularity text to enhance environmental diversity.","(1) DTLLM-VLT generates scientific and multi-granularity text descriptions using a cohesive prompt framework.","Its succinct and highly adaptable design allows seamless integration into various visual tracking benchmarks.","(2) We select three prominent benchmarks to deploy our approach: short-term tracking, long-term tracking, and global instance tracking.","We offer four granularity combinations for these benchmarks, considering the extent and density of semantic information, thereby showcasing the practicality and versatility of DTLLM-VLT.","(3) We conduct comparative experiments on VLT benchmarks with different text granularities, evaluating and analyzing the impact of diverse text on tracking performance.","Conclusionally, this work leverages LLM to provide multi-granularity semantic information for VLT task from efficient and diverse perspectives, enabling fine-grained evaluation of multi-modal trackers.","In the future, we believe this work can be extended to more datasets to support vision datasets understanding."],"url":"http://arxiv.org/abs/2405.12139v1"}
{"created":"2024-05-20 15:51:23","title":"A Vision on Open Science for the Evolution of Software Engineering Research and Practice","abstract":"Open Science aims to foster openness and collaboration in research, leading to more significant scientific and social impact. However, practicing Open Science comes with several challenges and is currently not properly rewarded. In this paper, we share our vision for addressing those challenges through a conceptual framework that connects essential building blocks for a change in the Software Engineering community, both culturally and technically. The idea behind this framework is that Open Science is treated as a first-class requirement for better Software Engineering research, practice, recognition, and relevant social impact. There is a long road for us, as a community, to truly embrace and gain from the benefits of Open Science. Nevertheless, we shed light on the directions for promoting the necessary culture shift and empowering the Software Engineering community.","sentences":["Open Science aims to foster openness and collaboration in research, leading to more significant scientific and social impact.","However, practicing Open Science comes with several challenges and is currently not properly rewarded.","In this paper, we share our vision for addressing those challenges through a conceptual framework that connects essential building blocks for a change in the Software Engineering community, both culturally and technically.","The idea behind this framework is that Open Science is treated as a first-class requirement for better Software Engineering research, practice, recognition, and relevant social impact.","There is a long road for us, as a community, to truly embrace and gain from the benefits of Open Science.","Nevertheless, we shed light on the directions for promoting the necessary culture shift and empowering the Software Engineering community."],"url":"http://arxiv.org/abs/2405.12132v1"}
{"created":"2024-05-20 15:48:32","title":"MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning","abstract":"Low-rank adaptation is a popular parameter-efficient fine-tuning method for large language models. In this paper, we analyze the impact of low-rank updating, as implemented in LoRA. Our findings suggest that the low-rank updating mechanism may limit the ability of LLMs to effectively learn and memorize new knowledge. Inspired by this observation, we propose a new method called MoRA, which employs a square matrix to achieve high-rank updating while maintaining the same number of trainable parameters. To achieve it, we introduce the corresponding non-parameter operators to reduce the input dimension and increase the output dimension for the square matrix. Furthermore, these operators ensure that the weight can be merged back into LLMs, which makes our method can be deployed like LoRA. We perform a comprehensive evaluation of our method across five tasks: instruction tuning, mathematical reasoning, continual pretraining, memory and pretraining. Our method outperforms LoRA on memory-intensive tasks and achieves comparable performance on other tasks.","sentences":["Low-rank adaptation is a popular parameter-efficient fine-tuning method for large language models.","In this paper, we analyze the impact of low-rank updating, as implemented in LoRA.","Our findings suggest that the low-rank updating mechanism may limit the ability of LLMs to effectively learn and memorize new knowledge.","Inspired by this observation, we propose a new method called MoRA, which employs a square matrix to achieve high-rank updating while maintaining the same number of trainable parameters.","To achieve it, we introduce the corresponding non-parameter operators to reduce the input dimension and increase the output dimension for the square matrix.","Furthermore, these operators ensure that the weight can be merged back into LLMs, which makes our method can be deployed like LoRA.","We perform a comprehensive evaluation of our method across five tasks: instruction tuning, mathematical reasoning, continual pretraining, memory and pretraining.","Our method outperforms LoRA on memory-intensive tasks and achieves comparable performance on other tasks."],"url":"http://arxiv.org/abs/2405.12130v1"}
{"created":"2024-05-20 15:44:07","title":"Alzheimer's Magnetic Resonance Imaging Classification Using Deep and Meta-Learning Models","abstract":"Deep learning, a cutting-edge machine learning approach, outperforms traditional machine learning in identifying intricate structures in complex high-dimensional data, particularly in the domain of healthcare. This study focuses on classifying Magnetic Resonance Imaging (MRI) data for Alzheimer's disease (AD) by leveraging deep learning techniques characterized by state-of-the-art CNNs. Brain imaging techniques such as MRI have enabled the measurement of pathophysiological brain changes related to Alzheimer's disease. Alzheimer's disease is the leading cause of dementia in the elderly, and it is an irreversible brain illness that causes gradual cognitive function disorder. In this paper, we train some benchmark deep models individually for the approach of the solution and later use an ensembling approach to combine the effect of multiple CNNs towards the observation of higher recall and accuracy. Here, the model's effectiveness is evaluated using various methods, including stacking, majority voting, and the combination of models with high recall values. The majority voting performs better than the alternative modelling approach as the majority voting approach typically reduces the variance in the predictions. We report a test accuracy of 90% with a precision score of 0.90 and a recall score of 0.89 in our proposed approach. In future, this study can be extended to incorporate other types of medical data, including signals, images, and other data. The same or alternative datasets can be used with additional classifiers, neural networks, and AI techniques to enhance Alzheimer's detection.","sentences":["Deep learning, a cutting-edge machine learning approach, outperforms traditional machine learning in identifying intricate structures in complex high-dimensional data, particularly in the domain of healthcare.","This study focuses on classifying Magnetic Resonance Imaging (MRI) data for Alzheimer's disease (AD) by leveraging deep learning techniques characterized by state-of-the-art CNNs.","Brain imaging techniques such as MRI have enabled the measurement of pathophysiological brain changes related to Alzheimer's disease.","Alzheimer's disease is the leading cause of dementia in the elderly, and it is an irreversible brain illness that causes gradual cognitive function disorder.","In this paper, we train some benchmark deep models individually for the approach of the solution and later use an ensembling approach to combine the effect of multiple CNNs towards the observation of higher recall and accuracy.","Here, the model's effectiveness is evaluated using various methods, including stacking, majority voting, and the combination of models with high recall values.","The majority voting performs better than the alternative modelling approach as the majority voting approach typically reduces the variance in the predictions.","We report a test accuracy of 90% with a precision score of 0.90 and a recall score of 0.89 in our proposed approach.","In future, this study can be extended to incorporate other types of medical data, including signals, images, and other data.","The same or alternative datasets can be used with additional classifiers, neural networks, and AI techniques to enhance Alzheimer's detection."],"url":"http://arxiv.org/abs/2405.12126v1"}
{"created":"2024-05-20 15:39:40","title":"An Active Learning Framework with a Class Balancing Strategy for Time Series Classification","abstract":"Training machine learning models for classification tasks often requires labeling numerous samples, which is costly and time-consuming, especially in time series analysis. This research investigates Active Learning (AL) strategies to reduce the amount of labeled data needed for effective time series classification. Traditional AL techniques cannot control the selection of instances per class for labeling, leading to potential bias in classification performance and instance selection, particularly in imbalanced time series datasets. To address this, we propose a novel class-balancing instance selection algorithm integrated with standard AL strategies. Our approach aims to select more instances from classes with fewer labeled examples, thereby addressing imbalance in time series datasets. We demonstrate the effectiveness of our AL framework in selecting informative data samples for two distinct domains of tactile texture recognition and industrial fault detection. In robotics, our method achieves high-performance texture categorization while significantly reducing labeled training data requirements to 70%. We also evaluate the impact of different sliding window time intervals on robotic texture classification using AL strategies. In synthetic fiber manufacturing, we adapt AL techniques to address the challenge of fault classification, aiming to minimize data annotation cost and time for industries. We also address real-life class imbalances in the multiclass industrial anomalous dataset using our class-balancing instance algorithm integrated with AL strategies. Overall, this thesis highlights the potential of our AL framework across these two distinct domains.","sentences":["Training machine learning models for classification tasks often requires labeling numerous samples, which is costly and time-consuming, especially in time series analysis.","This research investigates Active Learning (AL) strategies to reduce the amount of labeled data needed for effective time series classification.","Traditional AL techniques cannot control the selection of instances per class for labeling, leading to potential bias in classification performance and instance selection, particularly in imbalanced time series datasets.","To address this, we propose a novel class-balancing instance selection algorithm integrated with standard AL strategies.","Our approach aims to select more instances from classes with fewer labeled examples, thereby addressing imbalance in time series datasets.","We demonstrate the effectiveness of our AL framework in selecting informative data samples for two distinct domains of tactile texture recognition and industrial fault detection.","In robotics, our method achieves high-performance texture categorization while significantly reducing labeled training data requirements to 70%.","We also evaluate the impact of different sliding window time intervals on robotic texture classification using AL strategies.","In synthetic fiber manufacturing, we adapt AL techniques to address the challenge of fault classification, aiming to minimize data annotation cost and time for industries.","We also address real-life class imbalances in the multiclass industrial anomalous dataset using our class-balancing instance algorithm integrated with AL strategies.","Overall, this thesis highlights the potential of our AL framework across these two distinct domains."],"url":"http://arxiv.org/abs/2405.12122v1"}
{"created":"2024-05-20 15:38:53","title":"EdgeLoc: A Communication-Adaptive Parallel System for Real-Time Localization in Infrastructure-Assisted Autonomous Driving","abstract":"This paper presents EdgeLoc, an infrastructure-assisted, real-time localization system for autonomous driving that addresses the incompatibility between traditional localization methods and deep learning approaches. The system is built on top of the Robot Operating System (ROS) and combines the real-time performance of traditional methods with the high accuracy of deep learning approaches. The system leverages edge computing capabilities of roadside units (RSUs) for precise localization to enhance on-vehicle localization that is based on the real-time visual odometry. EdgeLoc is a parallel processing system, utilizing a proposed uncertainty-aware pose fusion solution. It achieves communication adaptivity through online learning and addresses fluctuations via window-based detection. Moreover, it achieves optimal latency and maximum improvement by utilizing auto-splitting vehicle-infrastructure collaborative inference, as well as online distribution learning for decision-making. Even with the most basic end-to-end deep neural network for localization estimation, EdgeLoc realizes a 67.75\\% reduction in the localization error for real-time local visual odometry, a 29.95\\% reduction for non-real-time collaborative inference, and a 30.26\\% reduction compared to Kalman filtering. Finally, accuracy-to-latency conversion was experimentally validated, and an overall experiment was conducted on a practical cellular network. The system is open sourced at https://github.com/LoganCome/EdgeAssistedLocalization.","sentences":["This paper presents EdgeLoc, an infrastructure-assisted, real-time localization system for autonomous driving that addresses the incompatibility between traditional localization methods and deep learning approaches.","The system is built on top of the Robot Operating System (ROS) and combines the real-time performance of traditional methods with the high accuracy of deep learning approaches.","The system leverages edge computing capabilities of roadside units (RSUs) for precise localization to enhance on-vehicle localization that is based on the real-time visual odometry.","EdgeLoc is a parallel processing system, utilizing a proposed uncertainty-aware pose fusion solution.","It achieves communication adaptivity through online learning and addresses fluctuations via window-based detection.","Moreover, it achieves optimal latency and maximum improvement by utilizing auto-splitting vehicle-infrastructure collaborative inference, as well as online distribution learning for decision-making.","Even with the most basic end-to-end deep neural network for localization estimation, EdgeLoc realizes a 67.75\\% reduction in the localization error for real-time local visual odometry, a 29.95\\% reduction for non-real-time collaborative inference, and a 30.26\\% reduction compared to Kalman filtering.","Finally, accuracy-to-latency conversion was experimentally validated, and an overall experiment was conducted on a practical cellular network.","The system is open sourced at https://github.com/LoganCome/EdgeAssistedLocalization."],"url":"http://arxiv.org/abs/2405.12120v1"}
{"created":"2024-05-20 15:37:55","title":"Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation","abstract":"Large language models (LLMs) are revolutionizing conversational recommender systems by adeptly indexing item content, understanding complex conversational contexts, and generating relevant item titles. However, controlling the distribution of recommended items remains a challenge. This leads to suboptimal performance due to the failure to capture rapidly changing data distributions, such as item popularity, on targeted conversational recommendation platforms. In conversational recommendation, LLMs recommend items by generating the titles (as multiple tokens) autoregressively, making it difficult to obtain and control the recommendations over all items. Thus, we propose a Reindex-Then-Adapt (RTA) framework, which converts multi-token item titles into single tokens within LLMs, and then adjusts the probability distributions over these single-token item titles accordingly. The RTA framework marries the benefits of both LLMs and traditional recommender systems (RecSys): understanding complex queries as LLMs do; while efficiently controlling the recommended item distributions in conversational recommendations as traditional RecSys do. Our framework demonstrates improved accuracy metrics across three different conversational recommendation datasets and two adaptation settings","sentences":["Large language models (LLMs) are revolutionizing conversational recommender systems by adeptly indexing item content, understanding complex conversational contexts, and generating relevant item titles.","However, controlling the distribution of recommended items remains a challenge.","This leads to suboptimal performance due to the failure to capture rapidly changing data distributions, such as item popularity, on targeted conversational recommendation platforms.","In conversational recommendation, LLMs recommend items by generating the titles (as multiple tokens) autoregressively, making it difficult to obtain and control the recommendations over all items.","Thus, we propose a Reindex-Then-Adapt (RTA) framework, which converts multi-token item titles into single tokens within LLMs, and then adjusts the probability distributions over these single-token item titles accordingly.","The RTA framework marries the benefits of both LLMs and traditional recommender systems (RecSys): understanding complex queries as LLMs do; while efficiently controlling the recommended item distributions in conversational recommendations as traditional RecSys do.","Our framework demonstrates improved accuracy metrics across three different conversational recommendation datasets and two adaptation settings"],"url":"http://arxiv.org/abs/2405.12119v1"}
{"created":"2024-05-20 15:32:47","title":"Strongly-Consistent Distributed Discrete-event Systems","abstract":"Discrete-event (DE) systems are concurrent programs where components communicate via tagged events, where tags are drawn from a totally ordered set. Reactors are an emerging model of computation based on DE and realized in the open-source coordination language Lingua Franca. Distributed DE (DDE) systems are DE systems where the components (reactors) communicate over networks. The prior art has required that for DDE systems with cycles, each cycle must contain at least one logical delay, where the tag of events is incremented. Such delays, however, are not required by the elegant fixed-point semantics of DE. The only requirement is that the program be constructive, meaning it is free of causality cycles. This paper gives a way to coordinate the execution of DDE systems that can execute any constructive program, even one with zero-delay cycles. It provides a formal model that exposes exactly the information that must be shared across networks for such execution to be possible. Furthermore, it describes a concrete implementation that is an extension of the coordination mechanisms in Lingua Franca.","sentences":["Discrete-event (DE) systems are concurrent programs where components communicate via tagged events, where tags are drawn from a totally ordered set.","Reactors are an emerging model of computation based on DE and realized in the open-source coordination language Lingua Franca.","Distributed DE (DDE) systems are DE systems where the components (reactors) communicate over networks.","The prior art has required that for DDE systems with cycles, each cycle must contain at least one logical delay, where the tag of events is incremented.","Such delays, however, are not required by the elegant fixed-point semantics of DE.","The only requirement is that the program be constructive, meaning it is free of causality cycles.","This paper gives a way to coordinate the execution of DDE systems that can execute any constructive program, even one with zero-delay cycles.","It provides a formal model that exposes exactly the information that must be shared across networks for such execution to be possible.","Furthermore, it describes a concrete implementation that is an extension of the coordination mechanisms in Lingua Franca."],"url":"http://arxiv.org/abs/2405.12117v1"}
{"created":"2024-05-20 15:31:32","title":"Clap: a Rust eDSL for PlonKish Proof Systems with a Semantics-preserving Optimizing Compiler","abstract":"Writing Plonkish constraint systems by hand is tedious and error-prone; as a result, several libraries and DSL's have emerged over the years to facilitate this task as well as techniques to directly analyze constraint systems. However, standalone languages require developers to use a foreign toolchain and leave gaps between the application and its circuits. On the other hand, Rust-embedded DSL like Halo2 or Boojum lack in modularity; furthermore, it is usually impossible to tease apart the circuit from the proof system, making it hard to reuse circuits and even to compare performance of different proof systems on the same circuits.   In this paper we introduce Clap, the first Rust eDSL to propose a prover-agnostic circuit format that enables extensibility, automatic optimizations, and formal guarantees for the resulting constraint system. Clap generates Plonkish constraint systems and witness generators that are sound and complete with respect to each other, leaving no room for subtle bugs due to under- or over-constraining. A model of this equivalence is proved in the Agda proof assistant for a subset of Clap's Rust implementation that is expressive enough to capture the compositional properties of our format. In order to increase the reuse of circuits, a number of optimizations are carried out automatically, sparing the developer from over-specifying low-level constraint system details in their circuit descriptions. We test the expressivity and efficiency of Clap on an implementation of the Poseidon2 hash function that produces a constraint system that is competitive in terms of size with hand-optimized Boojum circuits.","sentences":["Writing Plonkish constraint systems by hand is tedious and error-prone; as a result, several libraries and DSL's have emerged over the years to facilitate this task as well as techniques to directly analyze constraint systems.","However, standalone languages require developers to use a foreign toolchain and leave gaps between the application and its circuits.","On the other hand, Rust-embedded DSL like Halo2 or Boojum lack in modularity; furthermore, it is usually impossible to tease apart the circuit from the proof system, making it hard to reuse circuits and even to compare performance of different proof systems on the same circuits.   ","In this paper we introduce Clap, the first Rust eDSL to propose a prover-agnostic circuit format that enables extensibility, automatic optimizations, and formal guarantees for the resulting constraint system.","Clap generates Plonkish constraint systems and witness generators that are sound and complete with respect to each other, leaving no room for subtle bugs due to under- or over-constraining.","A model of this equivalence is proved in the Agda proof assistant for a subset of Clap's Rust implementation that is expressive enough to capture the compositional properties of our format.","In order to increase the reuse of circuits, a number of optimizations are carried out automatically, sparing the developer from over-specifying low-level constraint system details in their circuit descriptions.","We test the expressivity and efficiency of Clap on an implementation of the Poseidon2 hash function that produces a constraint system that is competitive in terms of size with hand-optimized Boojum circuits."],"url":"http://arxiv.org/abs/2405.12115v1"}
{"created":"2024-05-20 15:29:26","title":"A New Cross-Space Total Variation Regularization Model for Color Image Restoration with Quaternion Blur Operator","abstract":"The cross-channel deblurring problem in color image processing is difficult to solve due to the complex coupling and structural blurring of color pixels. Until now, there are few efficient algorithms that can reduce color infection in deblurring process. To solve this challenging problem, we present a novel cross-space total variation (CSTV) regularization model for color image deblurring by introducing a quaternion blur operator and a cross-color space regularization functional. The existence and uniqueness of the solution is proved and a new L-curve method is proposed to find a sweet balance of regularization functionals on different color spaces.   The Euler-Lagrange equation is derived to show that CSTV has taken into account the coupling of all color channels and the local smoothing within each color channel. A quaternion operator splitting method is firstly proposed to enhance the ability of color infection reduction of the CSTV regularization model. This strategy also applies to the well-known color deblurring models. Numerical experiments on color image databases illustrate the efficiency and manoeuvrability of the new model and algorithms. The color images restored by them successfully maintain the color and spatial information and are of higher quality in terms of PSNR, SSIM, MSE and CIEde2000 than the restorations of the-state-of-the-art methods.","sentences":["The cross-channel deblurring problem in color image processing is difficult to solve due to the complex coupling and structural blurring of color pixels.","Until now, there are few efficient algorithms that can reduce color infection in deblurring process.","To solve this challenging problem, we present a novel cross-space total variation (CSTV) regularization model for color image deblurring by introducing a quaternion blur operator and a cross-color space regularization functional.","The existence and uniqueness of the solution is proved and a new L-curve method is proposed to find a sweet balance of regularization functionals on different color spaces.   ","The Euler-Lagrange equation is derived to show that CSTV has taken into account the coupling of all color channels and the local smoothing within each color channel.","A quaternion operator splitting method is firstly proposed to enhance the ability of color infection reduction of the CSTV regularization model.","This strategy also applies to the well-known color deblurring models.","Numerical experiments on color image databases illustrate the efficiency and manoeuvrability of the new model and algorithms.","The color images restored by them successfully maintain the color and spatial information and are of higher quality in terms of PSNR, SSIM, MSE and CIEde2000 than the restorations of the-state-of-the-art methods."],"url":"http://arxiv.org/abs/2405.12114v1"}
{"created":"2024-05-20 15:25:47","title":"CoR-GS: Sparse-View 3D Gaussian Splatting via Co-Regularization","abstract":"3D Gaussian Splatting (3DGS) creates a radiance field consisting of 3D Gaussians to represent a scene. With sparse training views, 3DGS easily suffers from overfitting, negatively impacting the reconstruction quality. This paper introduces a new co-regularization perspective for improving sparse-view 3DGS. When training two 3D Gaussian radiance fields with the same sparse views of a scene, we observe that the two radiance fields exhibit \\textit{point disagreement} and \\textit{rendering disagreement} that can unsupervisedly predict reconstruction quality, stemming from the sampling implementation in densification. We further quantify the point disagreement and rendering disagreement by evaluating the registration between Gaussians' point representations and calculating differences in their rendered pixels. The empirical study demonstrates the negative correlation between the two disagreements and accurate reconstruction, which allows us to identify inaccurate reconstruction without accessing ground-truth information. Based on the study, we propose CoR-GS, which identifies and suppresses inaccurate reconstruction based on the two disagreements: (\\romannumeral1) Co-pruning considers Gaussians that exhibit high point disagreement in inaccurate positions and prunes them. (\\romannumeral2) Pseudo-view co-regularization considers pixels that exhibit high rendering disagreement are inaccurately rendered and suppress the disagreement. Results on LLFF, Mip-NeRF360, DTU, and Blender demonstrate that CoR-GS effectively regularizes the scene geometry, reconstructs the compact representations, and achieves state-of-the-art novel view synthesis quality under sparse training views.","sentences":["3D Gaussian Splatting (3DGS) creates a radiance field consisting of 3D Gaussians to represent a scene.","With sparse training views, 3DGS easily suffers from overfitting, negatively impacting the reconstruction quality.","This paper introduces a new co-regularization perspective for improving sparse-view 3DGS.","When training two 3D Gaussian radiance fields with the same sparse views of a scene, we observe that the two radiance fields exhibit \\textit{point disagreement} and \\textit{rendering disagreement} that can unsupervisedly predict reconstruction quality, stemming from the sampling implementation in densification.","We further quantify the point disagreement and rendering disagreement by evaluating the registration between Gaussians' point representations and calculating differences in their rendered pixels.","The empirical study demonstrates the negative correlation between the two disagreements and accurate reconstruction, which allows us to identify inaccurate reconstruction without accessing ground-truth information.","Based on the study, we propose CoR-GS, which identifies and suppresses inaccurate reconstruction based on the two disagreements: (\\romannumeral1) Co-pruning considers Gaussians that exhibit high point disagreement in inaccurate positions and prunes them.","(\\romannumeral2) Pseudo-view co-regularization considers pixels that exhibit high rendering disagreement are inaccurately rendered and suppress the disagreement.","Results on LLFF, Mip-NeRF360, DTU, and Blender demonstrate that CoR-GS effectively regularizes the scene geometry, reconstructs the compact representations, and achieves state-of-the-art novel view synthesis quality under sparse training views."],"url":"http://arxiv.org/abs/2405.12110v1"}
{"created":"2024-05-20 15:25:18","title":"Linguistic Structure from a Bottleneck on Sequential Information Processing","abstract":"Human language is a unique form of communication in the natural world, distinguished by its structured nature. Most fundamentally, it is systematic, meaning that signals can be broken down into component parts that are individually meaningful -- roughly, words -- which are combined in a regular way to form sentences. Furthermore, the way in which these parts are combined maintains a kind of locality: words are usually concatenated together, and they form contiguous phrases, keeping related parts of sentences close to each other. We address the challenge of understanding how these basic properties of language arise from broader principles of efficient communication under information processing constraints. Here we show that natural-language-like systematicity arises from minimization of excess entropy, a measure of statistical complexity that represents the minimum amount of information necessary for predicting the future of a sequence based on its past. In simulations, we show that codes that minimize excess entropy factorize their source distributions into approximately independent components, and then express those components systematically and locally. Next, in a series of massively cross-linguistic corpus studies, we show that human languages are structured to have low excess entropy at the level of phonology, morphology, syntax, and semantics. Our result suggests that human language performs a sequential generalization of Independent Components Analysis on the statistical distribution over meanings that need to be expressed. It establishes a link between the statistical and algebraic structure of human language, and reinforces the idea that the structure of human language may have evolved to minimize cognitive load while maximizing communicative expressiveness.","sentences":["Human language is a unique form of communication in the natural world, distinguished by its structured nature.","Most fundamentally, it is systematic, meaning that signals can be broken down into component parts that are individually meaningful -- roughly, words -- which are combined in a regular way to form sentences.","Furthermore, the way in which these parts are combined maintains a kind of locality: words are usually concatenated together, and they form contiguous phrases, keeping related parts of sentences close to each other.","We address the challenge of understanding how these basic properties of language arise from broader principles of efficient communication under information processing constraints.","Here we show that natural-language-like systematicity arises from minimization of excess entropy, a measure of statistical complexity that represents the minimum amount of information necessary for predicting the future of a sequence based on its past.","In simulations, we show that codes that minimize excess entropy factorize their source distributions into approximately independent components, and then express those components systematically and locally.","Next, in a series of massively cross-linguistic corpus studies, we show that human languages are structured to have low excess entropy at the level of phonology, morphology, syntax, and semantics.","Our result suggests that human language performs a sequential generalization of Independent Components Analysis on the statistical distribution over meanings that need to be expressed.","It establishes a link between the statistical and algebraic structure of human language, and reinforces the idea that the structure of human language may have evolved to minimize cognitive load while maximizing communicative expressiveness."],"url":"http://arxiv.org/abs/2405.12109v1"}
{"created":"2024-05-20 15:23:19","title":"Imp: Highly Capable Large Multimodal Models for Mobile Devices","abstract":"By harnessing the capabilities of large language models (LLMs), recent large multimodal models (LMMs) have shown remarkable versatility in open-world multimodal understanding. Nevertheless, they are usually parameter-heavy and computation-intensive, thus hindering their applicability in resource-constrained scenarios. To this end, several lightweight LMMs have been proposed successively to maximize the capabilities under constrained scale (e.g., 3B). Despite the encouraging results achieved by these methods, most of them only focus on one or two aspects of the design space, and the key design choices that influence model capability have not yet been thoroughly investigated. In this paper, we conduct a systematic study for lightweight LMMs from the aspects of model architecture, training strategy, and training data. Based on our findings, we obtain Imp -- a family of highly capable LMMs at the 2B-4B scales. Notably, our Imp-3B model steadily outperforms all the existing lightweight LMMs of similar size, and even surpasses the state-of-the-art LMMs at the 13B scale. With low-bit quantization and resolution reduction techniques, our Imp model can be deployed on a Qualcomm Snapdragon 8Gen3 mobile chip with a high inference speed of about 13 tokens/s.","sentences":["By harnessing the capabilities of large language models (LLMs), recent large multimodal models (LMMs) have shown remarkable versatility in open-world multimodal understanding.","Nevertheless, they are usually parameter-heavy and computation-intensive, thus hindering their applicability in resource-constrained scenarios.","To this end, several lightweight LMMs have been proposed successively to maximize the capabilities under constrained scale (e.g., 3B).","Despite the encouraging results achieved by these methods, most of them only focus on one or two aspects of the design space, and the key design choices that influence model capability have not yet been thoroughly investigated.","In this paper, we conduct a systematic study for lightweight LMMs from the aspects of model architecture, training strategy, and training data.","Based on our findings, we obtain Imp -- a family of highly capable LMMs at the 2B-4B scales.","Notably, our Imp-3B model steadily outperforms all the existing lightweight LMMs of similar size, and even surpasses the state-of-the-art LMMs at the 13B scale.","With low-bit quantization and resolution reduction techniques, our Imp model can be deployed on a Qualcomm Snapdragon 8Gen3 mobile chip with a high inference speed of about 13 tokens/s."],"url":"http://arxiv.org/abs/2405.12107v1"}
{"created":"2024-05-20 15:21:48","title":"Sheet Music Transformer ++: End-to-End Full-Page Optical Music Recognition for Pianoform Sheet Music","abstract":"Optical Music Recognition is a field that has progressed significantly, bringing accurate systems that transcribe effectively music scores into digital formats. Despite this, there are still several limitations that hinder OMR from achieving its full potential. Specifically, state of the art OMR still depends on multi-stage pipelines for performing full-page transcription, as well as it has only been demonstrated in monophonic cases, leaving behind very relevant engravings. In this work, we present the Sheet Music Transformer++, an end-to-end model that is able to transcribe full-page polyphonic music scores without the need of a previous Layout Analysis step. This is done thanks to an extensive curriculum learning-based pretraining with synthetic data generation. We conduct several experiments on a full-page extension of a public polyphonic transcription dataset. The experimental outcomes confirm that the model is competent at transcribing full-page pianoform scores, marking a noteworthy milestone in end-to-end OMR transcription.","sentences":["Optical Music Recognition is a field that has progressed significantly, bringing accurate systems that transcribe effectively music scores into digital formats.","Despite this, there are still several limitations that hinder OMR from achieving its full potential.","Specifically, state of the art OMR still depends on multi-stage pipelines for performing full-page transcription, as well as it has only been demonstrated in monophonic cases, leaving behind very relevant engravings.","In this work, we present the Sheet Music Transformer++, an end-to-end model that is able to transcribe full-page polyphonic music scores without the need of a previous Layout Analysis step.","This is done thanks to an extensive curriculum learning-based pretraining with synthetic data generation.","We conduct several experiments on a full-page extension of a public polyphonic transcription dataset.","The experimental outcomes confirm that the model is competent at transcribing full-page pianoform scores, marking a noteworthy milestone in end-to-end OMR transcription."],"url":"http://arxiv.org/abs/2405.12105v1"}
{"created":"2024-05-20 15:21:12","title":"Deciding branching hyperproperties for real time systems","abstract":"Security properties of real-time systems often involve reasoning about hyper-properties, as opposed to properties of single executions or trees of executions. These hyper-properties need to additionally be expressive enough to reason about real-time constraints. Examples of such properties include information flow, side channel attacks and service-level agreements. In this paper we study computational problems related to a branching-time, hyper-property extension of metric temporal logic (MTL) that we call HCMTL*. We consider both the interval-based and point-based semantics of this logic. The verification problem that we consider is to determine if a given HCMTL* formula $\\varphi$ is true in a system represented by a timed automaton. We show that this problem is undecidable. We then show that the verification problem is decidable if we consider executions upto a fixed time horizon $T$. Our decidability result relies on reducing the verification problem to the truth of an MSO formula over reals with a bounded time interval.","sentences":["Security properties of real-time systems often involve reasoning about hyper-properties, as opposed to properties of single executions or trees of executions.","These hyper-properties need to additionally be expressive enough to reason about real-time constraints.","Examples of such properties include information flow, side channel attacks and service-level agreements.","In this paper we study computational problems related to a branching-time, hyper-property extension of metric temporal logic (MTL) that we call HCMTL*.","We consider both the interval-based and point-based semantics of this logic.","The verification problem that we consider is to determine if a given HCMTL* formula $\\varphi$ is true in a system represented by a timed automaton.","We show that this problem is undecidable.","We then show that the verification problem is decidable if we consider executions upto a fixed time horizon $T$. Our decidability result relies on reducing the verification problem to the truth of an MSO formula over reals with a bounded time interval."],"url":"http://arxiv.org/abs/2405.12104v1"}
{"created":"2024-05-20 15:15:14","title":"Sustainable business decision modelling with blockchain and digital twins: A survey","abstract":"Industry 4.0 and beyond will rely heavily on sustainable Business Decision Modelling (BDM) that can be accelerated by blockchain and Digital Twin (DT) solutions. BDM is built on models and frameworks refined by key identification factors, data analysis, and mathematical or computational aspects applicable to complex business scenarios. Gaining actionable intelligence from collected data for BDM requires a carefully considered infrastructure to ensure data transparency, security, accessibility and sustainability. Organisations should consider social, economic and environmental factors (based on the triple bottom line approach) to ensure sustainability when integrating such an infrastructure. These sustainability features directly impact BDM concerning resource optimisation, stakeholder engagement, regulatory compliance and environmental impacts. To further understand these segments, taxonomies are defined to evaluate blockchain and DT sustainability features based on an in-depth review of the current state-of-the-art research. Detailed comparative evaluations provide insight into the reachability of the sustainable solution in terms of ideologies, access control and performance overheads. Several research questions are put forward to motivate further research that significantly impacts BDM. Finally, a case study based on an exemplary supply chain management system is presented to show the interoperability of blockchain and DT with BDM.","sentences":["Industry 4.0 and beyond will rely heavily on sustainable Business Decision Modelling (BDM) that can be accelerated by blockchain and Digital Twin (DT) solutions.","BDM is built on models and frameworks refined by key identification factors, data analysis, and mathematical or computational aspects applicable to complex business scenarios.","Gaining actionable intelligence from collected data for BDM requires a carefully considered infrastructure to ensure data transparency, security, accessibility and sustainability.","Organisations should consider social, economic and environmental factors (based on the triple bottom line approach) to ensure sustainability when integrating such an infrastructure.","These sustainability features directly impact BDM concerning resource optimisation, stakeholder engagement, regulatory compliance and environmental impacts.","To further understand these segments, taxonomies are defined to evaluate blockchain and DT sustainability features based on an in-depth review of the current state-of-the-art research.","Detailed comparative evaluations provide insight into the reachability of the sustainable solution in terms of ideologies, access control and performance overheads.","Several research questions are put forward to motivate further research that significantly impacts BDM.","Finally, a case study based on an exemplary supply chain management system is presented to show the interoperability of blockchain and DT with BDM."],"url":"http://arxiv.org/abs/2405.12101v1"}
{"created":"2024-05-20 15:13:22","title":"DOP: Diagnostic-Oriented Prompting for Large Language Models in Mathematical Correction","abstract":"Math world problems correction(MWPC) is a novel task dedicated to rectifying reasoning errors in the process of solving mathematical problems. In this paper, leveraging the advancements in large language models (LLMs), we address two key objectives:(1) Distinguishing between mathematical reasoning and error correction; (2) Exploring strategies to enhance the error correction capabilities of LLMs in mathematics to solve MWPC task. We noticed that, in real-time education,assisting students in recognizing their mistakes is more crucial than simply providing correct answers. However, current research tends to prioritize obtaining accurate solutions to math problems rather than correcting potentially incorrect ones. Therefore, we modify the research paradigm, demonstrating that improving mathematical reasoning abilities does not equate to mastery in error correction. Meanwhile, we propose a novel method called diagnostic-oriented promping(DOP) aimed at facilitating LLMs to excel in error correction. In experiments, DOP has shown outstanding performance, highlighting its significant impact. We argue that in mathematical education, the demand for outstanding correctors surpasses that for proficient reasoners. Codes and data are available on https://github.com/ChenhaoEcnuCS/Reason-Correct.","sentences":["Math world problems correction(MWPC) is a novel task dedicated to rectifying reasoning errors in the process of solving mathematical problems.","In this paper, leveraging the advancements in large language models (LLMs), we address two key objectives:(1)","Distinguishing between mathematical reasoning and error correction; (2) Exploring strategies to enhance the error correction capabilities of LLMs in mathematics to solve MWPC task.","We noticed that, in real-time education,assisting students in recognizing their mistakes is more crucial than simply providing correct answers.","However, current research tends to prioritize obtaining accurate solutions to math problems rather than correcting potentially incorrect ones.","Therefore, we modify the research paradigm, demonstrating that improving mathematical reasoning abilities does not equate to mastery in error correction.","Meanwhile, we propose a novel method called diagnostic-oriented promping(DOP) aimed at facilitating LLMs to excel in error correction.","In experiments, DOP has shown outstanding performance, highlighting its significant impact.","We argue that in mathematical education, the demand for outstanding correctors surpasses that for proficient reasoners.","Codes and data are available on https://github.com/ChenhaoEcnuCS/Reason-Correct."],"url":"http://arxiv.org/abs/2405.12100v1"}
{"created":"2024-05-20 15:08:15","title":"Using Unsupervised Learning to Explore Robot-Pedestrian Interactions in Urban Environments","abstract":"This study identifies a gap in data-driven approaches to robot-centric pedestrian interactions and proposes a corresponding pipeline. The pipeline utilizes unsupervised learning techniques to identify patterns in interaction data of urban environments, specifically focusing on conflict scenarios. Analyzed features include the robot's and pedestrian's speed and contextual parameters such as proximity to intersections. They are extracted and reduced in dimensionality using Principal Component Analysis (PCA). Finally, K-means clustering is employed to uncover underlying patterns in the interaction data. A use case application of the pipeline is presented, utilizing real-world robot mission data from a mid-sized German city. The results indicate the need for enriching interaction representations with contextual information to enable fine-grained analysis and reasoning. Nevertheless, they also highlight the need for expanding the data set and incorporating additional contextual factors to enhance the robots situational awareness and interaction quality.","sentences":["This study identifies a gap in data-driven approaches to robot-centric pedestrian interactions and proposes a corresponding pipeline.","The pipeline utilizes unsupervised learning techniques to identify patterns in interaction data of urban environments, specifically focusing on conflict scenarios.","Analyzed features include the robot's and pedestrian's speed and contextual parameters such as proximity to intersections.","They are extracted and reduced in dimensionality using Principal Component Analysis (PCA).","Finally, K-means clustering is employed to uncover underlying patterns in the interaction data.","A use case application of the pipeline is presented, utilizing real-world robot mission data from a mid-sized German city.","The results indicate the need for enriching interaction representations with contextual information to enable fine-grained analysis and reasoning.","Nevertheless, they also highlight the need for expanding the data set and incorporating additional contextual factors to enhance the robots situational awareness and interaction quality."],"url":"http://arxiv.org/abs/2405.12098v1"}
{"created":"2024-05-20 15:06:36","title":"PATE: Proximity-Aware Time series anomaly Evaluation","abstract":"Evaluating anomaly detection algorithms in time series data is critical as inaccuracies can lead to flawed decision-making in various domains where real-time analytics and data-driven strategies are essential. Traditional performance metrics assume iid data and fail to capture the complex temporal dynamics and specific characteristics of time series anomalies, such as early and delayed detections. We introduce Proximity-Aware Time series anomaly Evaluation (PATE), a novel evaluation metric that incorporates the temporal relationship between prediction and anomaly intervals. PATE uses proximity-based weighting considering buffer zones around anomaly intervals, enabling a more detailed and informed assessment of a detection. Using these weights, PATE computes a weighted version of the area under the Precision and Recall curve. Our experiments with synthetic and real-world datasets show the superiority of PATE in providing more sensible and accurate evaluations than other evaluation metrics. We also tested several state-of-the-art anomaly detectors across various benchmark datasets using the PATE evaluation scheme. The results show that a common metric like Point-Adjusted F1 Score fails to characterize the detection performances well, and that PATE is able to provide a more fair model comparison. By introducing PATE, we redefine the understanding of model efficacy that steers future studies toward developing more effective and accurate detection models.","sentences":["Evaluating anomaly detection algorithms in time series data is critical as inaccuracies can lead to flawed decision-making in various domains where real-time analytics and data-driven strategies are essential.","Traditional performance metrics assume iid data and fail to capture the complex temporal dynamics and specific characteristics of time series anomalies, such as early and delayed detections.","We introduce Proximity-Aware Time series anomaly Evaluation (PATE), a novel evaluation metric that incorporates the temporal relationship between prediction and anomaly intervals.","PATE uses proximity-based weighting considering buffer zones around anomaly intervals, enabling a more detailed and informed assessment of a detection.","Using these weights, PATE computes a weighted version of the area under the Precision and Recall curve.","Our experiments with synthetic and real-world datasets show the superiority of PATE in providing more sensible and accurate evaluations than other evaluation metrics.","We also tested several state-of-the-art anomaly detectors across various benchmark datasets using the PATE evaluation scheme.","The results show that a common metric like Point-Adjusted F1 Score fails to characterize the detection performances well, and that PATE is able to provide a more fair model comparison.","By introducing PATE, we redefine the understanding of model efficacy that steers future studies toward developing more effective and accurate detection models."],"url":"http://arxiv.org/abs/2405.12096v1"}
{"created":"2024-05-20 15:05:47","title":"Is Mamba Compatible with Trajectory Optimization in Offline Reinforcement Learning?","abstract":"Transformer-based trajectory optimization methods have demonstrated exceptional performance in offline Reinforcement Learning (offline RL), yet it poses challenges due to substantial parameter size and limited scalability, which is particularly critical in sequential decision-making scenarios where resources are constrained such as in robots and drones with limited computational power. Mamba, a promising new linear-time sequence model, offers performance on par with transformers while delivering substantially fewer parameters on long sequences. As it remains unclear whether Mamba is compatible with trajectory optimization, this work aims to conduct comprehensive experiments to explore the potential of Decision Mamba in offline RL (dubbed DeMa) from the aspect of data structures and network architectures with the following insights: (1) Long sequences impose a significant computational burden without contributing to performance improvements due to the fact that DeMa's focus on sequences diminishes approximately exponentially. Consequently, we introduce a Transformer-like DeMa as opposed to an RNN-like DeMa. (2) For the components of DeMa, we identify that the hidden attention mechanism is key to its success, which can also work well with other residual structures and does not require position embedding. Extensive evaluations from eight Atari games demonstrate that our specially designed DeMa is compatible with trajectory optimization and surpasses previous state-of-the-art methods, outdoing Decision Transformer (DT) by 80\\% with 30\\% fewer parameters, and exceeds DT in MuJoCo with only a quarter of the parameters.","sentences":["Transformer-based trajectory optimization methods have demonstrated exceptional performance in offline Reinforcement Learning (offline RL), yet it poses challenges due to substantial parameter size and limited scalability, which is particularly critical in sequential decision-making scenarios where resources are constrained such as in robots and drones with limited computational power.","Mamba, a promising new linear-time sequence model, offers performance on par with transformers while delivering substantially fewer parameters on long sequences.","As it remains unclear whether Mamba is compatible with trajectory optimization, this work aims to conduct comprehensive experiments to explore the potential of Decision Mamba in offline RL (dubbed DeMa) from the aspect of data structures and network architectures with the following insights: (1) Long sequences impose a significant computational burden without contributing to performance improvements due to the fact that DeMa's focus on sequences diminishes approximately exponentially.","Consequently, we introduce a Transformer-like DeMa as opposed to an RNN-like DeMa.","(2) For the components of DeMa, we identify that the hidden attention mechanism is key to its success, which can also work well with other residual structures and does not require position embedding.","Extensive evaluations from eight Atari games demonstrate that our specially designed DeMa is compatible with trajectory optimization and surpasses previous state-of-the-art methods, outdoing Decision Transformer (DT) by 80\\% with 30\\% fewer parameters, and exceeds DT in MuJoCo with only a quarter of the parameters."],"url":"http://arxiv.org/abs/2405.12094v1"}
{"created":"2024-05-20 15:02:13","title":"Using Formal Verification to Evaluate Single Event Upsets in a RISC-V Core","abstract":"Reliability has been a major concern in embedded systems. Higher transistor density and lower voltage supply increase the vulnerability of embedded systems to soft errors. A Single Event Upset (SEU), which is also called a soft error, can reverse a bit in a sequential element, resulting in a system failure. Simulation-based fault injection has been widely used to evaluate reliability, as suggested by ISO26262. However, it is practically impossible to test all faults for a complex design. Random fault injection is a compromise that reduces accuracy and fault coverage. Formal verification is an alternative approach. In this paper, we use formal verification, in the form of model checking, to evaluate the hardware reliability of a RISC-V Ibex Core in the presence of soft errors. Backward tracing is performed to identify and categorize faults according to their effects (no effect, Silent Data Corruption, crashes, and hangs). By using formal verification, the entire state space and fault list can be exhaustively explored. It is found that misaligned instructions can amplify fault effects. It is also found that some bits are more vulnerable to SEUs than others. In general, most of the bits in the Ibex Core are vulnerable to Silent Data Corruption, and the second pipeline stage is more vulnerable to Silent Data Corruption than the first.","sentences":["Reliability has been a major concern in embedded systems.","Higher transistor density and lower voltage supply increase the vulnerability of embedded systems to soft errors.","A Single Event Upset (SEU), which is also called a soft error, can reverse a bit in a sequential element, resulting in a system failure.","Simulation-based fault injection has been widely used to evaluate reliability, as suggested by ISO26262.","However, it is practically impossible to test all faults for a complex design.","Random fault injection is a compromise that reduces accuracy and fault coverage.","Formal verification is an alternative approach.","In this paper, we use formal verification, in the form of model checking, to evaluate the hardware reliability of a RISC-V Ibex Core in the presence of soft errors.","Backward tracing is performed to identify and categorize faults according to their effects (no effect, Silent Data Corruption, crashes, and hangs).","By using formal verification, the entire state space and fault list can be exhaustively explored.","It is found that misaligned instructions can amplify fault effects.","It is also found that some bits are more vulnerable to SEUs than others.","In general, most of the bits in the Ibex Core are vulnerable to Silent Data Corruption, and the second pipeline stage is more vulnerable to Silent Data Corruption than the first."],"url":"http://arxiv.org/abs/2405.12089v1"}
{"created":"2024-05-20 14:57:16","title":"Channel Balance Interpolation in the Lightning Network via Machine Learning","abstract":"The Bitcoin Lightning Network is a Layer 2 payment protocol that addresses Bitcoin's scalability by facilitating quick and cost effective transactions through payment channels. This research explores the feasibility of using machine learning models to interpolate channel balances within the network, which can be used for optimizing the network's pathfinding algorithms. While there has been much exploration in balance probing and multipath payment protocols, predicting channel balances using solely node and channel features remains an uncharted area. This paper evaluates the performance of several machine learning models against two heuristic baselines and investigates the predictive capabilities of various features. Our model performs favorably in experimental evaluation, outperforming by 10% against an equal split baseline where both edges are assigned half of the channel capacity.","sentences":["The Bitcoin Lightning Network is a Layer 2 payment protocol that addresses Bitcoin's scalability by facilitating quick and cost effective transactions through payment channels.","This research explores the feasibility of using machine learning models to interpolate channel balances within the network, which can be used for optimizing the network's pathfinding algorithms.","While there has been much exploration in balance probing and multipath payment protocols, predicting channel balances using solely node and channel features remains an uncharted area.","This paper evaluates the performance of several machine learning models against two heuristic baselines and investigates the predictive capabilities of various features.","Our model performs favorably in experimental evaluation, outperforming by 10% against an equal split baseline where both edges are assigned half of the channel capacity."],"url":"http://arxiv.org/abs/2405.12087v1"}
{"created":"2024-05-20 14:53:25","title":"Distributional Semantics, Holism, and the Instability of Meaning","abstract":"Current language models are built on the so-called distributional semantic approach to linguistic meaning that has the distributional hypothesis at its core. The distributional hypothesis involves a holistic conception of word meaning: the meaning of a word depends upon its relations to other words in the model. A standard objection to meaning holism is the charge of instability: any change in the meaning properties of a linguistic system (a human speaker, for example) would lead to many changes or possibly a complete change in the entire system. When the systems in question are trying to communicate with each other, it has been argued that instability of this kind makes communication impossible (Fodor and Lepore 1992, 1996, 1999). In this article, we examine whether the instability objection poses a problem for distributional models of meaning. First, we distinguish between distinct forms of instability that these models could exhibit, and we argue that only one such form is relevant for understanding the relation between instability and communication: what we call differential instability. Differential instability is variation in the relative distances between points in a space, rather than variation in the absolute position of those points. We distinguish differential and absolute instability by constructing two of our own models, a toy model constructed from the text of two novels, and a more sophisticated model constructed using the Word2vec algorithm from a combination of Wikipedia and SEP articles. We demonstrate the two forms of instability by showing how these models change as the corpora they are constructed from increase in size.","sentences":["Current language models are built on the so-called distributional semantic approach to linguistic meaning that has the distributional hypothesis at its core.","The distributional hypothesis involves a holistic conception of word meaning: the meaning of a word depends upon its relations to other words in the model.","A standard objection to meaning holism is the charge of instability: any change in the meaning properties of a linguistic system (a human speaker, for example) would lead to many changes or possibly a complete change in the entire system.","When the systems in question are trying to communicate with each other, it has been argued that instability of this kind makes communication impossible (Fodor and Lepore 1992, 1996, 1999).","In this article, we examine whether the instability objection poses a problem for distributional models of meaning.","First, we distinguish between distinct forms of instability that these models could exhibit, and we argue that only one such form is relevant for understanding the relation between instability and communication: what we call differential instability.","Differential instability is variation in the relative distances between points in a space, rather than variation in the absolute position of those points.","We distinguish differential and absolute instability by constructing two of our own models, a toy model constructed from the text of two novels, and a more sophisticated model constructed using the Word2vec algorithm from a combination of Wikipedia and SEP articles.","We demonstrate the two forms of instability by showing how these models change as the corpora they are constructed from increase in size."],"url":"http://arxiv.org/abs/2405.12084v1"}
{"created":"2024-05-20 14:52:05","title":"Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model","abstract":"To obtain high-quality annotations under limited budget, semi-automatic annotation methods are commonly used, where a portion of the data is annotated by experts and a model is then trained to complete the annotations for the remaining data. However, these methods mainly focus on selecting informative data for expert annotations to improve the model predictive ability (i.e., triage-to-human data), while the rest of the data is indiscriminately assigned to model annotation (i.e., triage-to-model data). This may lead to inefficiencies in budget allocation for annotations, as easy data that the model could accurately annotate may be unnecessarily assigned to the expert, and hard data may be misclassified by the model. As a result, the overall annotation quality may be compromised. To address this issue, we propose a selective annotation framework called SANT. It effectively takes advantage of both the triage-to-human and triage-to-model data through the proposed error-aware triage and bi-weighting mechanisms. As such, informative or hard data is assigned to the expert for annotation, while easy data is handled by the model. Experimental results show that SANT consistently outperforms other baselines, leading to higher-quality annotation through its proper allocation of data to both expert and model workers. We provide pioneering work on data annotation within budget constraints, establishing a landmark for future triage-based annotation studies.","sentences":["To obtain high-quality annotations under limited budget, semi-automatic annotation methods are commonly used, where a portion of the data is annotated by experts and a model is then trained to complete the annotations for the remaining data.","However, these methods mainly focus on selecting informative data for expert annotations to improve the model predictive ability (i.e., triage-to-human data), while the rest of the data is indiscriminately assigned to model annotation (i.e., triage-to-model data).","This may lead to inefficiencies in budget allocation for annotations, as easy data that the model could accurately annotate may be unnecessarily assigned to the expert, and hard data may be misclassified by the model.","As a result, the overall annotation quality may be compromised.","To address this issue, we propose a selective annotation framework called SANT.","It effectively takes advantage of both the triage-to-human and triage-to-model data through the proposed error-aware triage and bi-weighting mechanisms.","As such, informative or hard data is assigned to the expert for annotation, while easy data is handled by the model.","Experimental results show that SANT consistently outperforms other baselines, leading to higher-quality annotation through its proper allocation of data to both expert and model workers.","We provide pioneering work on data annotation within budget constraints, establishing a landmark for future triage-based annotation studies."],"url":"http://arxiv.org/abs/2405.12081v1"}
{"created":"2024-05-20 14:49:45","title":"PARALLELGPUOS: A Concurrent OS-level GPU Checkpoint and Restore System using Validated Speculation","abstract":"Checkpointing (C) and restoring (R) are key components for GPU tasks. POS is an OS-level GPU C/R system: It can transparently checkpoint or restore processes that use the GPU, without requiring any cooperation from the application, a key feature required by modern systems like the cloud. Moreover, POS is the first OS-level C/R system that can concurrently execute C/R with the application execution: a critical feature that can be trivially achieved when the processes only running on the CPU, but becomes challenging when the processes use GPU. The problem is how to ensure consistency during concurrent execution with the lack of application semantics due to transparency. CPU processes can leverage OS and hardware paging to fix inconsistency without application semantics. Unfortunately, GPU bypasses OS and paging for high performance. POS fills the semantic gap by speculatively extracting buffer access information of GPU kernels during runtime. Thanks to the simple and well-structured nature of GPU kernels, our speculative extraction (with runtime validation) achieves 100% accuracy on applications from training to inference whose domains span from vision, large language models, and reinforcement learning. Based on the extracted semantics, we systematically overlap C/R with application execution, and achieves orders of magnitude higher performance under various tasks compared with the state-of-the-art OS-level GPU C/R, including training fault tolerance, live GPU process migration, and cold starts acceleration in GPU-based serverless computing.","sentences":["Checkpointing (C) and restoring (R) are key components for GPU tasks.","POS is an OS-level GPU C/R system: It can transparently checkpoint or restore processes that use the GPU, without requiring any cooperation from the application, a key feature required by modern systems like the cloud.","Moreover, POS is the first OS-level C/R system that can concurrently execute C/R with the application execution: a critical feature that can be trivially achieved when the processes only running on the CPU, but becomes challenging when the processes use GPU.","The problem is how to ensure consistency during concurrent execution with the lack of application semantics due to transparency.","CPU processes can leverage OS and hardware paging to fix inconsistency without application semantics.","Unfortunately, GPU bypasses OS and paging for high performance.","POS fills the semantic gap by speculatively extracting buffer access information of GPU kernels during runtime.","Thanks to the simple and well-structured nature of GPU kernels, our speculative extraction (with runtime validation) achieves 100% accuracy on applications from training to inference whose domains span from vision, large language models, and reinforcement learning.","Based on the extracted semantics, we systematically overlap C/R with application execution, and achieves orders of magnitude higher performance under various tasks compared with the state-of-the-art OS-level GPU C/R, including training fault tolerance, live GPU process migration, and cold starts acceleration in GPU-based serverless computing."],"url":"http://arxiv.org/abs/2405.12079v1"}
{"created":"2024-05-20 14:43:46","title":"GAN-GRID: A Novel Generative Attack on Smart Grid Stability Prediction","abstract":"The smart grid represents a pivotal innovation in modernizing the electricity sector, offering an intelligent, digitalized energy network capable of optimizing energy delivery from source to consumer. It hence represents the backbone of the energy sector of a nation. Due to its central role, the availability of the smart grid is paramount and is hence necessary to have in-depth control of its operations and safety. To this aim, researchers developed multiple solutions to assess the smart grid's stability and guarantee that it operates in a safe state. Artificial intelligence and Machine learning algorithms have proven to be effective measures to accurately predict the smart grid's stability. Despite the presence of known adversarial attacks and potential solutions, currently, there exists no standardized measure to protect smart grids against this threat, leaving them open to new adversarial attacks. In this paper, we propose GAN-GRID a novel adversarial attack targeting the stability prediction system of a smart grid tailored to real-world constraints. Our findings reveal that an adversary armed solely with the stability model's output, devoid of data or model knowledge, can craft data classified as stable with an Attack Success Rate (ASR) of 0.99. Also by manipulating authentic data and sensor values, the attacker can amplify grid issues, potentially undetected due to a compromised stability prediction system. These results underscore the imperative of fortifying smart grid security mechanisms against adversarial manipulation to uphold system stability and reliability.","sentences":["The smart grid represents a pivotal innovation in modernizing the electricity sector, offering an intelligent, digitalized energy network capable of optimizing energy delivery from source to consumer.","It hence represents the backbone of the energy sector of a nation.","Due to its central role, the availability of the smart grid is paramount and is hence necessary to have in-depth control of its operations and safety.","To this aim, researchers developed multiple solutions to assess the smart grid's stability and guarantee that it operates in a safe state.","Artificial intelligence and Machine learning algorithms have proven to be effective measures to accurately predict the smart grid's stability.","Despite the presence of known adversarial attacks and potential solutions, currently, there exists no standardized measure to protect smart grids against this threat, leaving them open to new adversarial attacks.","In this paper, we propose GAN-GRID a novel adversarial attack targeting the stability prediction system of a smart grid tailored to real-world constraints.","Our findings reveal that an adversary armed solely with the stability model's output, devoid of data or model knowledge, can craft data classified as stable with an Attack Success Rate (ASR) of 0.99.","Also by manipulating authentic data and sensor values, the attacker can amplify grid issues, potentially undetected due to a compromised stability prediction system.","These results underscore the imperative of fortifying smart grid security mechanisms against adversarial manipulation to uphold system stability and reliability."],"url":"http://arxiv.org/abs/2405.12076v1"}
{"created":"2024-05-20 14:41:48","title":"Goal-Oriented Communication for Networked Control Assisted by Reconfigurable Meta-Surfaces","abstract":"In this paper, we develop a theoretical framework for goal-oriented communication assisted by reconfigurable meta-surfaces in the context of networked control systems. The relation to goal-oriented communication stems from the fact that optimization of the phase shifts of the meta-surfaces is guided by the performance of networked control systems tasks. To that end, we consider a networked control system in which a set of sensors observe the states of a set of physical processes, and communicate this information over an unreliable wireless channel assisted by a reconfigurable intelligent surface with multiple reflecting elements to a set of controllers that correct the behaviors of the physical processes based on the received information. Our objective is to find the optimal control policy for the controllers and the optimal phase policy for the reconfigurable intelligent surface that jointly minimize a regulation cost function associated with the networked control system. We characterize these policies, and also propose an approximate solution based on a semi-definite relaxation technique.","sentences":["In this paper, we develop a theoretical framework for goal-oriented communication assisted by reconfigurable meta-surfaces in the context of networked control systems.","The relation to goal-oriented communication stems from the fact that optimization of the phase shifts of the meta-surfaces is guided by the performance of networked control systems tasks.","To that end, we consider a networked control system in which a set of sensors observe the states of a set of physical processes, and communicate this information over an unreliable wireless channel assisted by a reconfigurable intelligent surface with multiple reflecting elements to a set of controllers that correct the behaviors of the physical processes based on the received information.","Our objective is to find the optimal control policy for the controllers and the optimal phase policy for the reconfigurable intelligent surface that jointly minimize a regulation cost function associated with the networked control system.","We characterize these policies, and also propose an approximate solution based on a semi-definite relaxation technique."],"url":"http://arxiv.org/abs/2405.12073v1"}
{"created":"2024-05-20 14:40:26","title":"AutoSoccerPose: Automated 3D posture Analysis of Soccer Shot Movements","abstract":"Image understanding is a foundational task in computer vision, with recent applications emerging in soccer posture analysis. However, existing publicly available datasets lack comprehensive information, notably in the form of posture sequences and 2D pose annotations. Moreover, current analysis models often rely on interpretable linear models (e.g., PCA and regression), limiting their capacity to capture non-linear spatiotemporal relationships in complex and diverse scenarios. To address these gaps, we introduce the 3D Shot Posture (3DSP) dataset in soccer broadcast videos, which represents the most extensive sports image dataset with 2D pose annotations to our knowledge. Additionally, we present the 3DSP-GRAE (Graph Recurrent AutoEncoder) model, a non-linear approach for embedding pose sequences. Furthermore, we propose AutoSoccerPose, a pipeline aimed at semi-automating 2D and 3D pose estimation and posture analysis. While achieving full automation proved challenging, we provide a foundational baseline, extending its utility beyond the scope of annotated data. We validate AutoSoccerPose on SoccerNet and 3DSP datasets, and present posture analysis results based on 3DSP. The dataset, code, and models are available at: https://github.com/calvinyeungck/3D-Shot-Posture-Dataset.","sentences":["Image understanding is a foundational task in computer vision, with recent applications emerging in soccer posture analysis.","However, existing publicly available datasets lack comprehensive information, notably in the form of posture sequences and","2D pose annotations.","Moreover, current analysis models often rely on interpretable linear models (e.g., PCA and regression), limiting their capacity to capture non-linear spatiotemporal relationships in complex and diverse scenarios.","To address these gaps, we introduce the 3D Shot Posture (3DSP) dataset in soccer broadcast videos, which represents the most extensive sports image dataset with 2D pose annotations to our knowledge.","Additionally, we present the 3DSP-GRAE (Graph Recurrent AutoEncoder) model, a non-linear approach for embedding pose sequences.","Furthermore, we propose AutoSoccerPose, a pipeline aimed at semi-automating 2D and 3D pose estimation and posture analysis.","While achieving full automation proved challenging, we provide a foundational baseline, extending its utility beyond the scope of annotated data.","We validate AutoSoccerPose on SoccerNet and 3DSP datasets, and present posture analysis results based on 3DSP.","The dataset, code, and models are available at: https://github.com/calvinyeungck/3D-Shot-Posture-Dataset."],"url":"http://arxiv.org/abs/2405.12070v1"}
{"created":"2024-05-20 14:39:49","title":"Gaussian Head & Shoulders: High Fidelity Neural Upper Body Avatars with Anchor Gaussian Guided Texture Warping","abstract":"By equipping the most recent 3D Gaussian Splatting representation with head 3D morphable models (3DMM), existing methods manage to create head avatars with high fidelity. However, most existing methods only reconstruct a head without the body, substantially limiting their application scenarios. We found that naively applying Gaussians to model the clothed chest and shoulders tends to result in blurry reconstruction and noisy floaters under novel poses. This is because of the fundamental limitation of Gaussians and point clouds -- each Gaussian or point can only have a single directional radiance without spatial variance, therefore an unnecessarily large number of them is required to represent complicated spatially varying texture, even for simple geometry. In contrast, we propose to model the body part with a neural texture that consists of coarse and pose-dependent fine colors. To properly render the body texture for each view and pose without accurate geometry nor UV mapping, we optimize another sparse set of Gaussians as anchors that constrain the neural warping field that maps image plane coordinates to the texture space. We demonstrate that Gaussian Head & Shoulders can fit the high-frequency details on the clothed upper body with high fidelity and potentially improve the accuracy and fidelity of the head region. We evaluate our method with casual phone-captured and internet videos and show our method archives superior reconstruction quality and robustness in both self and cross reenactment tasks. To fully utilize the efficient rendering speed of Gaussian splatting, we additionally propose an accelerated inference method of our trained model without Multi-Layer Perceptron (MLP) queries and reach a stable rendering speed of around 130 FPS for any subjects.","sentences":["By equipping the most recent 3D Gaussian Splatting representation with head 3D morphable models (3DMM), existing methods manage to create head avatars with high fidelity.","However, most existing methods only reconstruct a head without the body, substantially limiting their application scenarios.","We found that naively applying Gaussians to model the clothed chest and shoulders tends to result in blurry reconstruction and noisy floaters under novel poses.","This is because of the fundamental limitation of Gaussians and point clouds -- each Gaussian or point can only have a single directional radiance without spatial variance, therefore an unnecessarily large number of them is required to represent complicated spatially varying texture, even for simple geometry.","In contrast, we propose to model the body part with a neural texture that consists of coarse and pose-dependent fine colors.","To properly render the body texture for each view and pose without accurate geometry nor UV mapping, we optimize another sparse set of Gaussians as anchors that constrain the neural warping field that maps image plane coordinates to the texture space.","We demonstrate that Gaussian Head & Shoulders can fit the high-frequency details on the clothed upper body with high fidelity and potentially improve the accuracy and fidelity of the head region.","We evaluate our method with casual phone-captured and internet videos and show our method archives superior reconstruction quality and robustness in both self and cross reenactment tasks.","To fully utilize the efficient rendering speed of Gaussian splatting, we additionally propose an accelerated inference method of our trained model without Multi-Layer Perceptron (MLP) queries and reach a stable rendering speed of around 130 FPS for any subjects."],"url":"http://arxiv.org/abs/2405.12069v1"}
{"created":"2024-05-20 14:34:01","title":"CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models","abstract":"Large language models (LLMs) are increasingly used to meet user information needs, but their effectiveness in dealing with user queries that contain various types of ambiguity remains unknown, ultimately risking user trust and satisfaction. To this end, we introduce CLAMBER, a benchmark for evaluating LLMs using a well-organized taxonomy. Building upon the taxonomy, we construct ~12K high-quality data to assess the strengths, weaknesses, and potential risks of various off-the-shelf LLMs. Our findings indicate the limited practical utility of current LLMs in identifying and clarifying ambiguous user queries, even enhanced by chain-of-thought (CoT) and few-shot prompting. These techniques may result in overconfidence in LLMs and yield only marginal enhancements in identifying ambiguity. Furthermore, current LLMs fall short in generating high-quality clarifying questions due to a lack of conflict resolution and inaccurate utilization of inherent knowledge. In this paper, CLAMBER presents a guidance and promotes further research on proactive and trustworthy LLMs. Our dataset is available at https://github.com/zt991211/CLAMBER","sentences":["Large language models (LLMs) are increasingly used to meet user information needs, but their effectiveness in dealing with user queries that contain various types of ambiguity remains unknown, ultimately risking user trust and satisfaction.","To this end, we introduce CLAMBER, a benchmark for evaluating LLMs using a well-organized taxonomy.","Building upon the taxonomy, we construct ~12K high-quality data to assess the strengths, weaknesses, and potential risks of various off-the-shelf LLMs.","Our findings indicate the limited practical utility of current LLMs in identifying and clarifying ambiguous user queries, even enhanced by chain-of-thought (CoT) and few-shot prompting.","These techniques may result in overconfidence in LLMs and yield only marginal enhancements in identifying ambiguity.","Furthermore, current LLMs fall short in generating high-quality clarifying questions due to a lack of conflict resolution and inaccurate utilization of inherent knowledge.","In this paper, CLAMBER presents a guidance and promotes further research on proactive and trustworthy LLMs.","Our dataset is available at https://github.com/zt991211/CLAMBER"],"url":"http://arxiv.org/abs/2405.12063v1"}
{"created":"2024-05-20 14:28:25","title":"STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents","abstract":"Equipping a conversational search engine with strategies regarding when to ask clarification questions is becoming increasingly important across various domains. Attributing to the context understanding capability of LLMs and their access to domain-specific sources of knowledge, LLM-based clarification strategies feature rapid transfer to various domains in a post-hoc manner. However, they still struggle to deliver promising performance on unseen domains, struggling to achieve effective domain transferability. We take the first step to investigate this issue and existing methods tend to produce one-size-fits-all strategies across diverse domains, limiting their search effectiveness. In response, we introduce a novel method, called Style, to achieve effective domain transferability. Our experimental results indicate that Style bears strong domain transferability, resulting in an average search performance improvement of ~10% on four unseen domains.","sentences":["Equipping a conversational search engine with strategies regarding when to ask clarification questions is becoming increasingly important across various domains.","Attributing to the context understanding capability of LLMs and their access to domain-specific sources of knowledge, LLM-based clarification strategies feature rapid transfer to various domains in a post-hoc manner.","However, they still struggle to deliver promising performance on unseen domains, struggling to achieve effective domain transferability.","We take the first step to investigate this issue and existing methods tend to produce one-size-fits-all strategies across diverse domains, limiting their search effectiveness.","In response, we introduce a novel method, called Style, to achieve effective domain transferability.","Our experimental results indicate that Style bears strong domain transferability, resulting in an average search performance improvement of ~10% on four unseen domains."],"url":"http://arxiv.org/abs/2405.12059v1"}
{"created":"2024-05-20 14:26:07","title":"NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo","abstract":"In this work we present a novel multi-view photometric stereo (PS) method. Like many works in 3D reconstruction we are leveraging neural shape representations and learnt renderers. However, our work differs from the state-of-the-art multi-view PS methods such as PS-NeRF or SuperNormal we explicity leverage per-pixel intensity renderings rather than relying mainly on estimated normals.   We model point light attenuation and explicitly raytrace cast shadows in order to best approximate each points incoming radiance. This is used as input to a fully neural material renderer that uses minimal prior assumptions and it is jointly optimised with the surface. Finally, estimated normal and segmentation maps can also incorporated in order to maximise the surface accuracy.   Our method is among the first to outperform the classical approach of DiLiGenT-MV and achieves average 0.2mm Chamfer distance for objects imaged at approx 1.5m distance away with approximate 400x400 resolution. Moreover, we show robustness to poor normals in low light count scenario, achieving 0.27mm Chamfer distance when pixel rendering is used instead of estimated normals.","sentences":["In this work we present a novel multi-view photometric stereo (PS) method.","Like many works in 3D reconstruction we are leveraging neural shape representations and learnt renderers.","However, our work differs from the state-of-the-art multi-view PS methods such as PS-NeRF or SuperNormal we explicity leverage per-pixel intensity renderings rather than relying mainly on estimated normals.   ","We model point light attenuation and explicitly raytrace cast shadows in order to best approximate each points incoming radiance.","This is used as input to a fully neural material renderer that uses minimal prior assumptions and it is jointly optimised with the surface.","Finally, estimated normal and segmentation maps can also incorporated in order to maximise the surface accuracy.   ","Our method is among the first to outperform the classical approach of DiLiGenT-MV and achieves average 0.2mm Chamfer distance for objects imaged at approx 1.5m distance away with approximate 400x400 resolution.","Moreover, we show robustness to poor normals in low light count scenario, achieving 0.27mm Chamfer distance when pixel rendering is used instead of estimated normals."],"url":"http://arxiv.org/abs/2405.12057v1"}
{"created":"2024-05-20 14:24:18","title":"Unveiling factors influencing judgment variation in Sentiment Analysis with Natural Language Processing and Statistics","abstract":"TripAdvisor reviews and comparable data sources play an important role in many tasks in Natural Language Processing (NLP), providing a data basis for the identification and classification of subjective judgments, such as hotel or restaurant reviews, into positive or negative polarities. This study explores three important factors influencing variation in crowdsourced polarity judgments, focusing on TripAdvisor reviews in Spanish. Three hypotheses are tested: the role of Part Of Speech (POS), the impact of sentiment words such as \"tasty\", and the influence of neutral words like \"ok\" on judgment variation. The study's methodology employs one-word titles, demonstrating their efficacy in studying polarity variation of words. Statistical tests on mean equality are performed on word groups of our interest. The results of this study reveal that adjectives in one-word titles tend to result in lower judgment variation compared to other word types or POS. Sentiment words contribute to lower judgment variation as well, emphasizing the significance of sentiment words in research on polarity judgments, and neutral words are associated with higher judgment variation as expected. However, these effects cannot be always reproduced in longer titles, which suggests that longer titles do not represent the best data source for testing the ambiguity of single words due to the influence on word polarity by other words like negation in longer titles. This empirical investigation contributes valuable insights into the factors influencing polarity variation of words, providing a foundation for NLP practitioners that aim to capture and predict polarity judgments in Spanish and for researchers that aim to understand factors influencing judgment variation.","sentences":["TripAdvisor reviews and comparable data sources play an important role in many tasks in Natural Language Processing (NLP), providing a data basis for the identification and classification of subjective judgments, such as hotel or restaurant reviews, into positive or negative polarities.","This study explores three important factors influencing variation in crowdsourced polarity judgments, focusing on TripAdvisor reviews in Spanish.","Three hypotheses are tested: the role of Part Of Speech (POS), the impact of sentiment words such as \"tasty\", and the influence of neutral words like \"ok\" on judgment variation.","The study's methodology employs one-word titles, demonstrating their efficacy in studying polarity variation of words.","Statistical tests on mean equality are performed on word groups of our interest.","The results of this study reveal that adjectives in one-word titles tend to result in lower judgment variation compared to other word types or POS.","Sentiment words contribute to lower judgment variation as well, emphasizing the significance of sentiment words in research on polarity judgments, and neutral words are associated with higher judgment variation as expected.","However, these effects cannot be always reproduced in longer titles, which suggests that longer titles do not represent the best data source for testing the ambiguity of single words due to the influence on word polarity by other words like negation in longer titles.","This empirical investigation contributes valuable insights into the factors influencing polarity variation of words, providing a foundation for NLP practitioners that aim to capture and predict polarity judgments in Spanish and for researchers that aim to understand factors influencing judgment variation."],"url":"http://arxiv.org/abs/2405.12055v1"}
{"created":"2024-05-20 14:18:36","title":"Parallelization of the K-Means Algorithm with Applications to Big Data Clustering","abstract":"The K-Means clustering using LLoyd's algorithm is an iterative approach to partition the given dataset into K different clusters. The algorithm assigns each point to the cluster based on the following objective function   \\[\\ \\min \\Sigma_{i=1}^{n}||x_i-\\mu_{x_i}||^2\\] The serial algorithm involves iterative steps where we compute the distance of each datapoint from the centroids and assign the datapoint to the nearest centroid. This approach is essentially known as the expectation-maximization step. Clustering involves extensive computations to calculate distances at each iteration, which increases as the number of data points increases. This provides scope for parallelism. However, we must ensure that in a parallel process, each thread has access to the updated centroid value and no racing condition exists on any centroid values. We will compare two different approaches in this project. The first approach is an OpenMP flat synchronous method where all processes are run in parallel, and we use synchronization to ensure safe updates of clusters. The second approach we adopt is a GPU based parallelization approach using OpenACC wherein we will try to make use of GPU architecture to parallelize chunks of the algorithm to observe decreased computation time. We will analyze metrics such as speed up, efficiency,time taken with varying data points, and number of processes to compare the two approaches and understand the relative performance improvement we can get.","sentences":["The K-Means clustering using LLoyd's algorithm is an iterative approach to partition the given dataset into K different clusters.","The algorithm assigns each point to the cluster based on the following objective function   \\[\\ \\min \\Sigma_{i=1}^{n}||x_i-\\mu_{x_i}||^2\\]","The serial algorithm involves iterative steps where we compute the distance of each datapoint from the centroids and assign the datapoint to the nearest centroid.","This approach is essentially known as the expectation-maximization step.","Clustering involves extensive computations to calculate distances at each iteration, which increases as the number of data points increases.","This provides scope for parallelism.","However, we must ensure that in a parallel process, each thread has access to the updated centroid value and no racing condition exists on any centroid values.","We will compare two different approaches in this project.","The first approach is an OpenMP flat synchronous method where all processes are run in parallel, and we use synchronization to ensure safe updates of clusters.","The second approach we adopt is a GPU based parallelization approach using OpenACC wherein we will try to make use of GPU architecture to parallelize chunks of the algorithm to observe decreased computation time.","We will analyze metrics such as speed up, efficiency,time taken with varying data points, and number of processes to compare the two approaches and understand the relative performance improvement we can get."],"url":"http://arxiv.org/abs/2405.12052v1"}
{"created":"2024-05-20 14:13:22","title":"Energy-Efficient Federated Edge Learning with Streaming Data: A Lyapunov Optimization Approach","abstract":"Federated learning (FL) has received significant attention in recent years for its advantages in efficient training of machine learning models across distributed clients without disclosing user-sensitive data. Specifically, in federated edge learning (FEEL) systems, the time-varying nature of wireless channels introduces inevitable system dynamics in the communication process, thereby affecting training latency and energy consumption. In this work, we further consider a streaming data scenario where new training data samples are randomly generated over time at edge devices. Our goal is to develop a dynamic scheduling and resource allocation algorithm to address the inherent randomness in data arrivals and resource availability under long-term energy constraints. To achieve this, we formulate a stochastic network optimization problem and use the Lyapunov drift-plus-penalty framework to obtain a dynamic resource management design. Our proposed algorithm makes adaptive decisions on device scheduling, computational capacity adjustment, and allocation of bandwidth and transmit power in every round. We provide convergence analysis for the considered setting with heterogeneous data and time-varying objective functions, which supports the rationale behind our proposed scheduling design. The effectiveness of our scheme is verified through simulation results, demonstrating improved learning performance and energy efficiency as compared to baseline schemes.","sentences":["Federated learning (FL) has received significant attention in recent years for its advantages in efficient training of machine learning models across distributed clients without disclosing user-sensitive data.","Specifically, in federated edge learning (FEEL) systems, the time-varying nature of wireless channels introduces inevitable system dynamics in the communication process, thereby affecting training latency and energy consumption.","In this work, we further consider a streaming data scenario where new training data samples are randomly generated over time at edge devices.","Our goal is to develop a dynamic scheduling and resource allocation algorithm to address the inherent randomness in data arrivals and resource availability under long-term energy constraints.","To achieve this, we formulate a stochastic network optimization problem and use the Lyapunov drift-plus-penalty framework to obtain a dynamic resource management design.","Our proposed algorithm makes adaptive decisions on device scheduling, computational capacity adjustment, and allocation of bandwidth and transmit power in every round.","We provide convergence analysis for the considered setting with heterogeneous data and time-varying objective functions, which supports the rationale behind our proposed scheduling design.","The effectiveness of our scheme is verified through simulation results, demonstrating improved learning performance and energy efficiency as compared to baseline schemes."],"url":"http://arxiv.org/abs/2405.12046v1"}
{"created":"2024-05-20 14:10:35","title":"The Incoherency Risk in the EU's New Cyber Security Policies","abstract":"The European Union (EU) has been pursuing new cyber security policies in recent years. This paper presents a short evaluation of four such policies. The focus is on potential incoherency, meaning a lack of integration, divergence between the member states, institutional dysfunction, and other related problems that should be at least partially avoidable by sound policy-making. According to the evaluation, the four policies have substantially increased the complexity of the EU's cyber security framework. In addition, there are potential problems with trust, divergence between industry sectors and different technologies, bureaucratic conflicts, and technical issues, among other things. With these insights, the paper not only contributes to the study of EU policies but also advances the understanding of cyber security policies in general.","sentences":["The European Union (EU) has been pursuing new cyber security policies in recent years.","This paper presents a short evaluation of four such policies.","The focus is on potential incoherency, meaning a lack of integration, divergence between the member states, institutional dysfunction, and other related problems that should be at least partially avoidable by sound policy-making.","According to the evaluation, the four policies have substantially increased the complexity of the EU's cyber security framework.","In addition, there are potential problems with trust, divergence between industry sectors and different technologies, bureaucratic conflicts, and technical issues, among other things.","With these insights, the paper not only contributes to the study of EU policies but also advances the understanding of cyber security policies in general."],"url":"http://arxiv.org/abs/2405.12043v1"}
{"created":"2024-05-20 14:09:28","title":"Attribute-Based Authentication in Secure Group Messaging for Distributed Environments","abstract":"Messaging Layer security (MLS) and its underlying Continuous Group Key Agreement (CGKA) protocol allows a group of users to share a cryptographic secret in a dynamic manner, such that the secret is modified in member insertions and deletions. Although this flexibility makes MLS ideal for implementations in distributed environments, a number of issues need to be overcome. Particularly, the use of digital certificates for authentication in a group goes against the group members' privacy. In this work we provide an alternative method of authentication in which the solicitors, instead of revealing their identity, only need to prove possession of certain attributes, dynamically defined by the group, to become a member. Instead of digital certificates, we employ Attribute-Based Credentials accompanied with Selective Disclosure in order to reveal the minimum required amount of information and to prevent attackers from linking the activity of a user through multiple groups. We formally define a CGKA variant named Attribute-Authenticated Continuous Group Key Agreement (AA-CGKA) and provide security proofs for its properties of Requirement Integrity, Unforgeability and Unlinkability. We also provide guidelines for an integration of our construction in MLS.","sentences":["Messaging Layer security (MLS) and its underlying Continuous Group Key Agreement (CGKA) protocol allows a group of users to share a cryptographic secret in a dynamic manner, such that the secret is modified in member insertions and deletions.","Although this flexibility makes MLS ideal for implementations in distributed environments, a number of issues need to be overcome.","Particularly, the use of digital certificates for authentication in a group goes against the group members' privacy.","In this work we provide an alternative method of authentication in which the solicitors, instead of revealing their identity, only need to prove possession of certain attributes, dynamically defined by the group, to become a member.","Instead of digital certificates, we employ Attribute-Based Credentials accompanied with Selective Disclosure in order to reveal the minimum required amount of information and to prevent attackers from linking the activity of a user through multiple groups.","We formally define a CGKA variant named Attribute-Authenticated Continuous Group Key Agreement (AA-CGKA) and provide security proofs for its properties of Requirement Integrity, Unforgeability and Unlinkability.","We also provide guidelines for an integration of our construction in MLS."],"url":"http://arxiv.org/abs/2405.12042v1"}
{"created":"2024-05-20 14:07:59","title":"Reputation Transfer in the Twitter Diaspora","abstract":"Social media platforms have witnessed a dynamic landscape of user migration in recent years, fueled by changes in ownership, policy, and user preferences. This paper explores the phenomenon of user migration from established platforms like X/Twitter to emerging alternatives such as Threads, Mastodon, and Truth Social. Leveraging a large dataset from X/Twitter, we investigate the extent of user departure from X/Twitter and the destinations they migrate to. Additionally, we examine whether a user's reputation on one platform correlates with their reputation on another, shedding light on the transferability of digital reputation across social media ecosystems. Overall, we find that users with a large following on X/Twitter are more likely to migrate to another platform; and that their reputation on X/Twitter is highly correlated with reputations on Threads, but not Mastodon or Truth Social.","sentences":["Social media platforms have witnessed a dynamic landscape of user migration in recent years, fueled by changes in ownership, policy, and user preferences.","This paper explores the phenomenon of user migration from established platforms like X/Twitter to emerging alternatives such as Threads, Mastodon, and Truth Social.","Leveraging a large dataset from X/Twitter, we investigate the extent of user departure from X/Twitter and the destinations they migrate to.","Additionally, we examine whether a user's reputation on one platform correlates with their reputation on another, shedding light on the transferability of digital reputation across social media ecosystems.","Overall, we find that users with a large following on X/Twitter are more likely to migrate to another platform; and that their reputation on X/Twitter is highly correlated with reputations on Threads, but not Mastodon or Truth Social."],"url":"http://arxiv.org/abs/2405.12040v1"}
{"created":"2024-05-20 14:05:35","title":"Adaptive Extraction Network for Multivariate Long Sequence Time-Series Forecasting","abstract":"Models employing CNN architecture have made significant progress in multivariate long sequence time-series forecasting (MLSTF), particularly in modeling local time series characteristics. However, during the MLSTF process, extracting the global time series patterns and understanding the correlations among different variables are highly significant. To address this challenge, we introduce multi-resolution convolution and deformable convolution operations. By enlarging the receptive field using convolution kernels with different dilation factors to capture temporal correlation information across different resolutions, and adaptively adjusting the sampling positions through additional offset vectors, we enhance the network's ability to capture correlated features between variables. Building upon this, we propose ATVCNet, an adaptive temporal-variable convolutional network designed to effectively model the local/global temporal dependencies and inter-variable dependencies of multivariate time series. Specifically, extracting and fusing time series features at different resolutions, captures both local contextual information and global patterns in the time series. The designed inter-variable feature adaptive extraction module captures the correlation among different variables in the time series. We evaluated the performance of ATVCNet across eight real-world datasets. The results indicate that ATVCNet achieved a performance improvement of approximately 63.4% over state-of-the-art MLSTF models.","sentences":["Models employing CNN architecture have made significant progress in multivariate long sequence time-series forecasting (MLSTF), particularly in modeling local time series characteristics.","However, during the MLSTF process, extracting the global time series patterns and understanding the correlations among different variables are highly significant.","To address this challenge, we introduce multi-resolution convolution and deformable convolution operations.","By enlarging the receptive field using convolution kernels with different dilation factors to capture temporal correlation information across different resolutions, and adaptively adjusting the sampling positions through additional offset vectors, we enhance the network's ability to capture correlated features between variables.","Building upon this, we propose ATVCNet, an adaptive temporal-variable convolutional network designed to effectively model the local/global temporal dependencies and inter-variable dependencies of multivariate time series.","Specifically, extracting and fusing time series features at different resolutions, captures both local contextual information and global patterns in the time series.","The designed inter-variable feature adaptive extraction module captures the correlation among different variables in the time series.","We evaluated the performance of ATVCNet across eight real-world datasets.","The results indicate that ATVCNet achieved a performance improvement of approximately 63.4% over state-of-the-art MLSTF models."],"url":"http://arxiv.org/abs/2405.12038v1"}
{"created":"2024-05-20 14:03:05","title":"KG-RAG: Bridging the Gap Between Knowledge and Creativity","abstract":"Ensuring factual accuracy while maintaining the creative capabilities of Large Language Model Agents (LMAs) poses significant challenges in the development of intelligent agent systems. LMAs face prevalent issues such as information hallucinations, catastrophic forgetting, and limitations in processing long contexts when dealing with knowledge-intensive tasks. This paper introduces a KG-RAG (Knowledge Graph-Retrieval Augmented Generation) pipeline, a novel framework designed to enhance the knowledge capabilities of LMAs by integrating structured Knowledge Graphs (KGs) with the functionalities of LLMs, thereby significantly reducing the reliance on the latent knowledge of LLMs. The KG-RAG pipeline constructs a KG from unstructured text and then performs information retrieval over the newly created graph to perform KGQA (Knowledge Graph Question Answering). The retrieval methodology leverages a novel algorithm called Chain of Explorations (CoE) which benefits from LLMs reasoning to explore nodes and relationships within the KG sequentially. Preliminary experiments on the ComplexWebQuestions dataset demonstrate notable improvements in the reduction of hallucinated content and suggest a promising path toward developing intelligent systems adept at handling knowledge-intensive tasks.","sentences":["Ensuring factual accuracy while maintaining the creative capabilities of Large Language Model Agents (LMAs) poses significant challenges in the development of intelligent agent systems.","LMAs face prevalent issues such as information hallucinations, catastrophic forgetting, and limitations in processing long contexts when dealing with knowledge-intensive tasks.","This paper introduces a KG-RAG (Knowledge Graph-Retrieval Augmented Generation) pipeline, a novel framework designed to enhance the knowledge capabilities of LMAs by integrating structured Knowledge Graphs (KGs) with the functionalities of LLMs, thereby significantly reducing the reliance on the latent knowledge of LLMs.","The KG-RAG pipeline constructs a KG from unstructured text and then performs information retrieval over the newly created graph to perform KGQA (Knowledge Graph Question Answering).","The retrieval methodology leverages a novel algorithm called Chain of Explorations (CoE) which benefits from LLMs reasoning to explore nodes and relationships within the KG sequentially.","Preliminary experiments on the ComplexWebQuestions dataset demonstrate notable improvements in the reduction of hallucinated content and suggest a promising path toward developing intelligent systems adept at handling knowledge-intensive tasks."],"url":"http://arxiv.org/abs/2405.12035v1"}
{"created":"2024-05-20 14:01:38","title":"Count-Min Sketch with Conservative Updates: Worst-Case Analysis","abstract":"Count-Min Sketch with Conservative Updates (\\texttt{CMS-CU}) is a memory-efficient hash-based data structure used to estimate the occurrences of items within a data stream. \\texttt{CMS-CU} stores~$m$ counters and employs~$d$ hash functions to map items to these counters. We first argue that the estimation error in \\texttt{CMS-CU} is maximal when each item appears at most once in the stream. Next, we study \\texttt{CMS-CU} in this setting. Precisely, \\begin{enumerate}   \\item In the case where~$d=m-1$, we prove that the average estimation error and the average counter rate converge almost surely to~$\\frac{1}{2}$, contrasting with the vanilla Count-Min Sketch, where the average counter rate is equal to~$\\frac{m-1}{m}$.   \\item For any given~$m$ and~$d$, we prove novel lower and upper bounds on the average estimation error, incorporating a positive integer parameter~$g$. Larger values of this parameter improve the accuracy of the bounds. Moreover, the computation of each bound involves examining an ergodic Markov process with a state space of size~$\\binom{m+g-d}{g}$ and a sparse transition probabilities matrix containing~$\\mathcal{O}(m\\binom{m+g-d}{g})$ non-zero entries.   \\item For~$d=m-1$, $g=1$, and as $m\\to \\infty$, we show that the lower and upper bounds coincide. In general, our bounds exhibit high accuracy for small values of $g$, as shown by numerical computation. For example, for $m=50$, $d=4$, and $g=5$, the difference between the lower and upper bounds is smaller than~$10^{-4}$.   \\end{enumerate}","sentences":["Count-Min Sketch with Conservative Updates (\\texttt{CMS-CU}) is a memory-efficient hash-based data structure used to estimate the occurrences of items within a data stream.","\\texttt{CMS-CU} stores~$m$ counters and employs~$d$ hash functions to map items to these counters.","We first argue that the estimation error in \\texttt{CMS-CU} is maximal when each item appears at most once in the stream.","Next, we study \\texttt{CMS-CU} in this setting.","Precisely, \\begin{enumerate}   \\item","In the case where~$d=m-1$, we prove that the average estimation error and the average counter rate converge almost surely to~$\\frac{1}{2}$, contrasting with the vanilla Count-Min Sketch, where the average counter rate is equal to~$\\frac{m-1}{m}$.   \\item","For any given~$m$ and~$d$, we prove novel lower and upper bounds on the average estimation error, incorporating a positive integer parameter~$g$. Larger values of this parameter improve the accuracy of the bounds.","Moreover, the computation of each bound involves examining an ergodic Markov process with a state space of size~$\\binom{m+g-d}{g}$ and a sparse transition probabilities matrix containing~$\\mathcal{O}(m\\binom{m+g-d}{g})$ non-zero entries.   ","\\item For~$d=m-1$, $g=1$, and as $m\\to \\infty$, we show that the lower and upper bounds coincide.","In general, our bounds exhibit high accuracy for small values of $g$, as shown by numerical computation.","For example, for $m=50$, $d=4$, and $g=5$, the difference between the lower and upper bounds is smaller than~$10^{-4}$.   \\end{enumerate}"],"url":"http://arxiv.org/abs/2405.12034v1"}
{"created":"2024-05-20 13:55:19","title":"Neighborhood Attention Transformer with Progressive Channel Fusion for Speaker Verification","abstract":"Transformer-based architectures for speaker verification typically require more training data than ECAPA-TDNN. Therefore, recent work has generally been trained on VoxCeleb1&2. We propose a backbone network based on self-attention, which can achieve competitive results when trained on VoxCeleb2 alone. The network alternates between neighborhood attention and global attention to capture local and global features, then aggregates features of different hierarchical levels, and finally performs attentive statistical pooling. Additionally, we employ a progressive channel fusion strategy to expand the receptive field in the channel dimension as the network deepens. We trained the proposed PCF-NAT model on VoxCeleb2 and evaluated it on VoxCeleb1 and the validation sets of VoxSRC. The EER and minDCF of the shallow PCF-NAT are on average more than 20% lower than those of similarly sized ECAPA-TDNN. Deep PCF-NAT achieves an EER lower than 0.5% on VoxCeleb1-O.","sentences":["Transformer-based architectures for speaker verification typically require more training data than ECAPA-TDNN.","Therefore, recent work has generally been trained on VoxCeleb1&2.","We propose a backbone network based on self-attention, which can achieve competitive results when trained on VoxCeleb2 alone.","The network alternates between neighborhood attention and global attention to capture local and global features, then aggregates features of different hierarchical levels, and finally performs attentive statistical pooling.","Additionally, we employ a progressive channel fusion strategy to expand the receptive field in the channel dimension as the network deepens.","We trained the proposed PCF-NAT model on VoxCeleb2 and evaluated it on VoxCeleb1 and the validation sets of VoxSRC.","The EER and minDCF of the shallow PCF-NAT are on average more than 20% lower than those of similarly sized ECAPA-TDNN.","Deep PCF-NAT achieves an EER lower than 0.5% on VoxCeleb1-O."],"url":"http://arxiv.org/abs/2405.12031v1"}
{"created":"2024-05-20 13:44:50","title":"Enzymatic cycle-based receivers with high input impedance for approximate maximum a posteriori demodulation of concentration modulated signals","abstract":"Molecular communication is a bio-inspired communication paradigm where molecules are used as the information carrier. This paper considers a molecular communication network where the transmitter uses concentration modulated signals for communication. Our focus is to design receivers that can demodulate these signals. We impose three features on our receivers. We want the receivers to use enzymatic cycles as their building blocks, have high input impedance and can work approximately as a maximum a posteriori (MAP) demodulator. No receivers with all these three features exist in the current molecular communication literature. We consider enzymatic cycles because they are a very common class of chemical reactions that are found in living cells. Since a receiver is to be placed in the communication environment, it should ideally have a high input impedance so that it has minimal impact on the environment and on other receivers. Lastly, a MAP receiver has good statistical performance. In this paper, we show how we can use time-scale separation to make an enzymatic cycle to have high input impedance and how the parameters of the enzymatic cycles can be chosen so that the receiver can approximately implement a MAP demodulator. We use simulation to study the performance of this receiver. In particular, we consider an environment with multiple receivers and show that a receiver has little impact on the bit error ratio of a nearby receiver because they have high input impedance.","sentences":["Molecular communication is a bio-inspired communication paradigm where molecules are used as the information carrier.","This paper considers a molecular communication network where the transmitter uses concentration modulated signals for communication.","Our focus is to design receivers that can demodulate these signals.","We impose three features on our receivers.","We want the receivers to use enzymatic cycles as their building blocks, have high input impedance and can work approximately as a maximum a posteriori (MAP) demodulator.","No receivers with all these three features exist in the current molecular communication literature.","We consider enzymatic cycles because they are a very common class of chemical reactions that are found in living cells.","Since a receiver is to be placed in the communication environment, it should ideally have a high input impedance so that it has minimal impact on the environment and on other receivers.","Lastly, a MAP receiver has good statistical performance.","In this paper, we show how we can use time-scale separation to make an enzymatic cycle to have high input impedance and how the parameters of the enzymatic cycles can be chosen so that the receiver can approximately implement a MAP demodulator.","We use simulation to study the performance of this receiver.","In particular, we consider an environment with multiple receivers and show that a receiver has little impact on the bit error ratio of a nearby receiver because they have high input impedance."],"url":"http://arxiv.org/abs/2405.12026v1"}
{"created":"2024-05-20 13:42:27","title":"Can AI Relate: Testing Large Language Model Response for Mental Health Support","abstract":"Large language models (LLMs) are already being piloted for clinical use in hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed deployment use case is psychotherapy, where a LLM-powered chatbot can treat a patient undergoing a mental health crisis. Deployment of LLMs for mental health response could hypothetically broaden access to psychotherapy and provide new possibilities for personalizing care. However, recent high-profile failures, like damaging dieting advice offered by the Tessa chatbot to patients with eating disorders, have led to doubt about their reliability in high-stakes and safety-critical settings.   In this work, we develop an evaluation framework for determining whether LLM response is a viable and ethical path forward for the automation of mental health treatment. Using human evaluation with trained clinicians and automatic quality-of-care metrics grounded in psychology research, we compare the responses provided by peer-to-peer responders to those provided by a state-of-the-art LLM.   We show that LLMs like GPT-4 use implicit and explicit cues to infer patient demographics like race. We then show that there are statistically significant discrepancies between patient subgroups: Responses to Black posters consistently have lower empathy than for any other demographic group (2%-13% lower than the control group). Promisingly, we do find that the manner in which responses are generated significantly impacts the quality of the response. We conclude by proposing safety guidelines for the potential deployment of LLMs for mental health response.","sentences":["Large language models (LLMs) are already being piloted for clinical use in hospital systems like NYU Langone, Dana-Farber and the NHS.","A proposed deployment use case is psychotherapy, where a LLM-powered chatbot can treat a patient undergoing a mental health crisis.","Deployment of LLMs for mental health response could hypothetically broaden access to psychotherapy and provide new possibilities for personalizing care.","However, recent high-profile failures, like damaging dieting advice offered by the Tessa chatbot to patients with eating disorders, have led to doubt about their reliability in high-stakes and safety-critical settings.   ","In this work, we develop an evaluation framework for determining whether LLM response is a viable and ethical path forward for the automation of mental health treatment.","Using human evaluation with trained clinicians and automatic quality-of-care metrics grounded in psychology research, we compare the responses provided by peer-to-peer responders to those provided by a state-of-the-art LLM.   ","We show that LLMs like GPT-4 use implicit and explicit cues to infer patient demographics like race.","We then show that there are statistically significant discrepancies between patient subgroups: Responses to Black posters consistently have lower empathy than for any other demographic group (2%-13% lower than the control group).","Promisingly, we do find that the manner in which responses are generated significantly impacts the quality of the response.","We conclude by proposing safety guidelines for the potential deployment of LLMs for mental health response."],"url":"http://arxiv.org/abs/2405.12021v1"}
