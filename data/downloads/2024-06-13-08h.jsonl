{"created":"2024-06-12 17:59:52","title":"ICE-G: Image Conditional Editing of 3D Gaussian Splats","abstract":"Recently many techniques have emerged to create high quality 3D assets and scenes. When it comes to editing of these objects, however, existing approaches are either slow, compromise on quality, or do not provide enough customization. We introduce a novel approach to quickly edit a 3D model from a single reference view. Our technique first segments the edit image, and then matches semantically corresponding regions across chosen segmented dataset views using DINO features. A color or texture change from a particular region of the edit image can then be applied to other views automatically in a semantically sensible manner. These edited views act as an updated dataset to further train and re-style the 3D scene. The end-result is therefore an edited 3D model. Our framework enables a wide variety of editing tasks such as manual local edits, correspondence based style transfer from any example image, and a combination of different styles from multiple example images. We use Gaussian Splats as our primary 3D representation due to their speed and ease of local editing, but our technique works for other methods such as NeRFs as well. We show through multiple examples that our method produces higher quality results while offering fine-grained control of editing. Project page: ice-gaussian.github.io","sentences":["Recently many techniques have emerged to create high quality 3D assets and scenes.","When it comes to editing of these objects, however, existing approaches are either slow, compromise on quality, or do not provide enough customization.","We introduce a novel approach to quickly edit a 3D model from a single reference view.","Our technique first segments the edit image, and then matches semantically corresponding regions across chosen segmented dataset views using DINO features.","A color or texture change from a particular region of the edit image can then be applied to other views automatically in a semantically sensible manner.","These edited views act as an updated dataset to further train and re-style the 3D scene.","The end-result is therefore an edited 3D model.","Our framework enables a wide variety of editing tasks such as manual local edits, correspondence based style transfer from any example image, and a combination of different styles from multiple example images.","We use Gaussian Splats as our primary 3D representation due to their speed and ease of local editing, but our technique works for other methods such as NeRFs as well.","We show through multiple examples that our method produces higher quality results while offering fine-grained control of editing.","Project page: ice-gaussian.github.io"],"url":"http://arxiv.org/abs/2406.08488v1"}
{"created":"2024-06-12 17:59:49","title":"Beyond LLaVA-HD: Diving into High-Resolution Large Multimodal Models","abstract":"Seeing clearly with high resolution is a foundation of Large Multimodal Models (LMMs), which has been proven to be vital for visual perception and reasoning. Existing works usually employ a straightforward resolution upscaling method, where the image consists of global and local branches, with the latter being the sliced image patches but resized to the same resolution as the former. This means that higher resolution requires more local patches, resulting in exorbitant computational expenses, and meanwhile, the dominance of local image tokens may diminish the global context. In this paper, we dive into the problems and propose a new framework as well as an elaborate optimization strategy. Specifically, we extract contextual information from the global view using a mixture of adapters, based on the observation that different adapters excel at different tasks. With regard to local patches, learnable query embeddings are introduced to reduce image tokens, the most important tokens accounting for the user question will be further selected by a similarity-based selector. Our empirical results demonstrate a `less is more' pattern, where \\textit{utilizing fewer but more informative local image tokens leads to improved performance}. Besides, a significant challenge lies in the training strategy, as simultaneous end-to-end training of the global mining block and local compression block does not yield optimal results. We thus advocate for an alternating training way, ensuring balanced learning between global and local aspects. Finally, we also introduce a challenging dataset with high requirements for image detail, enhancing the training of the local compression layer. The proposed method, termed LMM with Sophisticated Tasks, Local image compression, and Mixture of global Experts (SliME), achieves leading performance across various benchmarks with only 2 million training data.","sentences":["Seeing clearly with high resolution is a foundation of Large Multimodal Models (LMMs), which has been proven to be vital for visual perception and reasoning.","Existing works usually employ a straightforward resolution upscaling method, where the image consists of global and local branches, with the latter being the sliced image patches but resized to the same resolution as the former.","This means that higher resolution requires more local patches, resulting in exorbitant computational expenses, and meanwhile, the dominance of local image tokens may diminish the global context.","In this paper, we dive into the problems and propose a new framework as well as an elaborate optimization strategy.","Specifically, we extract contextual information from the global view using a mixture of adapters, based on the observation that different adapters excel at different tasks.","With regard to local patches, learnable query embeddings are introduced to reduce image tokens, the most important tokens accounting for the user question will be further selected by a similarity-based selector.","Our empirical results demonstrate a `less is more' pattern, where \\textit{utilizing fewer but more informative local image tokens leads to improved performance}.","Besides, a significant challenge lies in the training strategy, as simultaneous end-to-end training of the global mining block and local compression block does not yield optimal results.","We thus advocate for an alternating training way, ensuring balanced learning between global and local aspects.","Finally, we also introduce a challenging dataset with high requirements for image detail, enhancing the training of the local compression layer.","The proposed method, termed LMM with Sophisticated Tasks, Local image compression, and Mixture of global Experts (SliME), achieves leading performance across various benchmarks with only 2 million training data."],"url":"http://arxiv.org/abs/2406.08487v1"}
{"created":"2024-06-12 17:59:27","title":"Words Worth a Thousand Pictures: Measuring and Understanding Perceptual Variability in Text-to-Image Generation","abstract":"Diffusion models are the state of the art in text-to-image generation, but their perceptual variability remains understudied. In this paper, we examine how prompts affect image variability in black-box diffusion-based models. We propose W1KP, a human-calibrated measure of variability in a set of images, bootstrapped from existing image-pair perceptual distances. Current datasets do not cover recent diffusion models, thus we curate three test sets for evaluation. Our best perceptual distance outperforms nine baselines by up to 18 points in accuracy, and our calibration matches graded human judgements 78% of the time. Using W1KP, we study prompt reusability and show that Imagen prompts can be reused for 10-50 random seeds before new images become too similar to already generated images, while Stable Diffusion XL and DALL-E 3 can be reused 50-200 times. Lastly, we analyze 56 linguistic features of real prompts, finding that the prompt's length, CLIP embedding norm, concreteness, and word senses influence variability most. As far as we are aware, we are the first to analyze diffusion variability from a visuolinguistic perspective. Our project page is at http://w1kp.com","sentences":["Diffusion models are the state of the art in text-to-image generation, but their perceptual variability remains understudied.","In this paper, we examine how prompts affect image variability in black-box diffusion-based models.","We propose W1KP, a human-calibrated measure of variability in a set of images, bootstrapped from existing image-pair perceptual distances.","Current datasets do not cover recent diffusion models, thus we curate three test sets for evaluation.","Our best perceptual distance outperforms nine baselines by up to 18 points in accuracy, and our calibration matches graded human judgements 78% of the time.","Using W1KP, we study prompt reusability and show that Imagen prompts can be reused for 10-50 random seeds before new images become too similar to already generated images, while Stable Diffusion XL and DALL-E 3 can be reused 50-200 times.","Lastly, we analyze 56 linguistic features of real prompts, finding that the prompt's length, CLIP embedding norm, concreteness, and word senses influence variability most.","As far as we are aware, we are the first to analyze diffusion variability from a visuolinguistic perspective.","Our project page is at http://w1kp.com"],"url":"http://arxiv.org/abs/2406.08482v1"}
{"created":"2024-06-12 17:59:21","title":"Enhancing End-to-End Autonomous Driving with Latent World Model","abstract":"End-to-end autonomous driving has garnered widespread attention. Current end-to-end approaches largely rely on the supervision from perception tasks such as detection, tracking, and map segmentation to aid in learning scene representations. However, these methods require extensive annotations, hindering the data scalability. To address this challenge, we propose a novel self-supervised method to enhance end-to-end driving without the need for costly labels. Specifically, our framework \\textbf{LAW} uses a LAtent World model to predict future latent features based on the predicted ego actions and the latent feature of the current frame. The predicted latent features are supervised by the actually observed features in the future. This supervision jointly optimizes the latent feature learning and action prediction, which greatly enhances the driving performance. As a result, our approach achieves state-of-the-art performance in both open-loop and closed-loop benchmarks without costly annotations.","sentences":["End-to-end autonomous driving has garnered widespread attention.","Current end-to-end approaches largely rely on the supervision from perception tasks such as detection, tracking, and map segmentation to aid in learning scene representations.","However, these methods require extensive annotations, hindering the data scalability.","To address this challenge, we propose a novel self-supervised method to enhance end-to-end driving without the need for costly labels.","Specifically, our framework \\textbf{LAW} uses a LAtent World model to predict future latent features based on the predicted ego actions and the latent feature of the current frame.","The predicted latent features are supervised by the actually observed features in the future.","This supervision jointly optimizes the latent feature learning and action prediction, which greatly enhances the driving performance.","As a result, our approach achieves state-of-the-art performance in both open-loop and closed-loop benchmarks without costly annotations."],"url":"http://arxiv.org/abs/2406.08481v1"}
{"created":"2024-06-12 17:59:14","title":"Linear equations with monomial constraints and decision problems in abelian-by-cyclic groups","abstract":"We show that it is undecidable whether a system of linear equations over the Laurent polynomial ring $\\mathbb{Z}[X^{\\pm}]$ admit solutions where a specified subset of variables take value in the set of monomials $\\{X^z \\mid z \\in \\mathbb{Z}\\}$. In particular, we construct a finitely presented $\\mathbb{Z}[X^{\\pm}]$-module, where it is undecidable whether a linear equation $X^{z_1} \\boldsymbol{f}_1 + \\cdots + X^{z_n} \\boldsymbol{f}_n = \\boldsymbol{f}_0$ has solutions $z_1, \\ldots, z_n \\in \\mathbb{Z}$. This contrasts the decidability of the case $n = 1$, which can be deduced from Noskov's Lemma.   As applications, we show that there exists a finitely generated abelian-by-cyclic group in which the Knapsack Problem is undecidable, and in which the problem of solving quadratic equations is also undecidable. In contrast, we show that the problem of Coset Intersection is decidable in all finitely generated abelian-by-cyclic groups.","sentences":["We show that it is undecidable whether a system of linear equations over the Laurent polynomial ring $\\mathbb{Z}[X^{\\pm}]$ admit solutions where a specified subset of variables take value in the set of monomials $\\{X^z \\mid z \\in \\mathbb{Z}\\}$. In particular, we construct a finitely presented $\\mathbb{Z}[X^{\\pm}]$-module, where it is undecidable whether a linear equation $X^{z_1} \\boldsymbol{f}_1 + \\cdots + X^{z_n} \\boldsymbol{f}_n = \\boldsymbol{f}_0$ has solutions $z_1, \\ldots, z_n","\\in \\mathbb{Z}$. This contrasts the decidability of the case $n = 1$, which can be deduced from Noskov's Lemma.   ","As applications, we show that there exists a finitely generated abelian-by-cyclic group in which the Knapsack Problem is undecidable, and in which the problem of solving quadratic equations is also undecidable.","In contrast, we show that the problem of Coset Intersection is decidable in all finitely generated abelian-by-cyclic groups."],"url":"http://arxiv.org/abs/2406.08480v1"}
{"created":"2024-06-12 17:59:08","title":"Real3D: Scaling Up Large Reconstruction Models with Real-World Images","abstract":"The default strategy for training single-view Large Reconstruction Models (LRMs) follows the fully supervised route using large-scale datasets of synthetic 3D assets or multi-view captures. Although these resources simplify the training procedure, they are hard to scale up beyond the existing datasets and they are not necessarily representative of the real distribution of object shapes. To address these limitations, in this paper, we introduce Real3D, the first LRM system that can be trained using single-view real-world images. Real3D introduces a novel self-training framework that can benefit from both the existing synthetic data and diverse single-view real images. We propose two unsupervised losses that allow us to supervise LRMs at the pixel- and semantic-level, even for training examples without ground-truth 3D or novel views. To further improve performance and scale up the image data, we develop an automatic data curation approach to collect high-quality examples from in-the-wild images. Our experiments show that Real3D consistently outperforms prior work in four diverse evaluation settings that include real and synthetic data, as well as both in-domain and out-of-domain shapes. Code and model can be found here: https://hwjiang1510.github.io/Real3D/","sentences":["The default strategy for training single-view Large Reconstruction Models (LRMs) follows the fully supervised route using large-scale datasets of synthetic 3D assets or multi-view captures.","Although these resources simplify the training procedure, they are hard to scale up beyond the existing datasets and they are not necessarily representative of the real distribution of object shapes.","To address these limitations, in this paper, we introduce Real3D, the first LRM system that can be trained using single-view real-world images.","Real3D introduces a novel self-training framework that can benefit from both the existing synthetic data and diverse single-view real images.","We propose two unsupervised losses that allow us to supervise LRMs at the pixel- and semantic-level, even for training examples without ground-truth 3D or novel views.","To further improve performance and scale up the image data, we develop an automatic data curation approach to collect high-quality examples from in-the-wild images.","Our experiments show that Real3D consistently outperforms prior work in four diverse evaluation settings that include real and synthetic data, as well as both in-domain and out-of-domain shapes.","Code and model can be found here: https://hwjiang1510.github.io/Real3D/"],"url":"http://arxiv.org/abs/2406.08479v1"}
{"created":"2024-06-12 17:59:07","title":"What If We Recaption Billions of Web Images with LLaMA-3?","abstract":"Web-crawled image-text pairs are inherently noisy. Prior studies demonstrate that semantically aligning and enriching textual descriptions of these pairs can significantly enhance model training across various vision-language tasks, particularly text-to-image generation. However, large-scale investigations in this area remain predominantly closed-source. Our paper aims to bridge this community effort, leveraging the powerful and \\textit{open-sourced} LLaMA-3, a GPT-4 level LLM. Our recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered LLaVA-1.5 and then employ it to recaption 1.3 billion images from the DataComp-1B dataset. Our empirical results confirm that this enhanced dataset, Recap-DataComp-1B, offers substantial benefits in training advanced vision-language models. For discriminative models like CLIP, we observe enhanced zero-shot performance in cross-modal retrieval tasks. For generative models like text-to-image Diffusion Transformers, the generated images exhibit a significant improvement in alignment with users' text instructions, especially in following complex queries. Our project page is https://www.haqtu.me/Recap-Datacomp-1B/","sentences":["Web-crawled image-text pairs are inherently noisy.","Prior studies demonstrate that semantically aligning and enriching textual descriptions of these pairs can significantly enhance model training across various vision-language tasks, particularly text-to-image generation.","However, large-scale investigations in this area remain predominantly closed-source.","Our paper aims to bridge this community effort, leveraging the powerful and \\textit{open-sourced} LLaMA-3, a GPT-4 level LLM.","Our recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered LLaVA-1.5 and then employ it to recaption 1.3 billion images from the DataComp-1B dataset.","Our empirical results confirm that this enhanced dataset, Recap-DataComp-1B, offers substantial benefits in training advanced vision-language models.","For discriminative models like CLIP, we observe enhanced zero-shot performance in cross-modal retrieval tasks.","For generative models like text-to-image Diffusion Transformers, the generated images exhibit a significant improvement in alignment with users' text instructions, especially in following complex queries.","Our project page is https://www.haqtu.me/Recap-Datacomp-1B/"],"url":"http://arxiv.org/abs/2406.08478v1"}
{"created":"2024-06-12 17:59:05","title":"Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens","abstract":"Characterizing users and items through vector representations is crucial for various tasks in recommender systems. Recent approaches attempt to apply Large Language Models (LLMs) in recommendation through a question and answer format, where real users and items (e.g., Item No.2024) are represented with in-vocabulary tokens (e.g., \"item\", \"20\", \"24\"). However, since LLMs are typically pretrained on natural language tasks, these in-vocabulary tokens lack the expressive power for distinctive users and items, thereby weakening the recommendation ability even after fine-tuning on recommendation tasks. In this paper, we explore how to effectively tokenize users and items in LLM-based recommender systems. We emphasize the role of out-of-vocabulary (OOV) tokens in addition to the in-vocabulary ones and claim the memorization of OOV tokens that capture correlations of users/items as well as diversity of OOV tokens. By clustering the learned representations from historical user-item interactions, we make the representations of user/item combinations share the same OOV tokens if they have similar properties. Furthermore, integrating these OOV tokens into the LLM's vocabulary allows for better distinction between users and items and enhanced capture of user-item relationships during fine-tuning on downstream tasks. Our proposed framework outperforms existing state-of-the-art methods across various downstream recommendation tasks.","sentences":["Characterizing users and items through vector representations is crucial for various tasks in recommender systems.","Recent approaches attempt to apply Large Language Models (LLMs) in recommendation through a question and answer format, where real users and items (e.g., Item No.2024) are represented with in-vocabulary tokens (e.g., \"item\", \"20\", \"24\").","However, since LLMs are typically pretrained on natural language tasks, these in-vocabulary tokens lack the expressive power for distinctive users and items, thereby weakening the recommendation ability even after fine-tuning on recommendation tasks.","In this paper, we explore how to effectively tokenize users and items in LLM-based recommender systems.","We emphasize the role of out-of-vocabulary (OOV) tokens in addition to the in-vocabulary ones and claim the memorization of OOV tokens that capture correlations of users/items as well as diversity of OOV tokens.","By clustering the learned representations from historical user-item interactions, we make the representations of user/item combinations share the same OOV tokens if they have similar properties.","Furthermore, integrating these OOV tokens into the LLM's vocabulary allows for better distinction between users and items and enhanced capture of user-item relationships during fine-tuning on downstream tasks.","Our proposed framework outperforms existing state-of-the-art methods across various downstream recommendation tasks."],"url":"http://arxiv.org/abs/2406.08477v1"}
{"created":"2024-06-12 17:59:04","title":"RMem: Restricted Memory Banks Improve Video Object Segmentation","abstract":"With recent video object segmentation (VOS) benchmarks evolving to challenging scenarios, we revisit a simple but overlooked strategy: restricting the size of memory banks. This diverges from the prevalent practice of expanding memory banks to accommodate extensive historical information. Our specially designed \"memory deciphering\" study offers a pivotal insight underpinning such a strategy: expanding memory banks, while seemingly beneficial, actually increases the difficulty for VOS modules to decode relevant features due to the confusion from redundant information. By restricting memory banks to a limited number of essential frames, we achieve a notable improvement in VOS accuracy. This process balances the importance and freshness of frames to maintain an informative memory bank within a bounded capacity. Additionally, restricted memory banks reduce the training-inference discrepancy in memory lengths compared with continuous expansion. This fosters new opportunities in temporal reasoning and enables us to introduce the previously overlooked \"temporal positional embedding.\" Finally, our insights are embodied in \"RMem\" (\"R\" for restricted), a simple yet effective VOS modification that excels at challenging VOS scenarios and establishes new state of the art for object state changes (on the VOST dataset) and long videos (on the Long Videos dataset). Our code and demo are available at https://restricted-memory.github.io/.","sentences":["With recent video object segmentation (VOS) benchmarks evolving to challenging scenarios, we revisit a simple but overlooked strategy: restricting the size of memory banks.","This diverges from the prevalent practice of expanding memory banks to accommodate extensive historical information.","Our specially designed \"memory deciphering\" study offers a pivotal insight underpinning such a strategy: expanding memory banks, while seemingly beneficial, actually increases the difficulty for VOS modules to decode relevant features due to the confusion from redundant information.","By restricting memory banks to a limited number of essential frames, we achieve a notable improvement in VOS accuracy.","This process balances the importance and freshness of frames to maintain an informative memory bank within a bounded capacity.","Additionally, restricted memory banks reduce the training-inference discrepancy in memory lengths compared with continuous expansion.","This fosters new opportunities in temporal reasoning and enables us to introduce the previously overlooked \"temporal positional embedding.\"","Finally, our insights are embodied in \"RMem\" (\"R\" for restricted), a simple yet effective VOS modification that excels at challenging VOS scenarios and establishes new state of the art for object state changes (on the VOST dataset) and long videos (on the Long Videos dataset).","Our code and demo are available at https://restricted-memory.github.io/."],"url":"http://arxiv.org/abs/2406.08476v1"}
{"created":"2024-06-12 17:57:25","title":"Human 3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models","abstract":"Creating realistic avatars from a single RGB image is an attractive yet challenging problem. Due to its ill-posed nature, recent works leverage powerful prior from 2D diffusion models pretrained on large datasets. Although 2D diffusion models demonstrate strong generalization capability, they cannot provide multi-view shape priors with guaranteed 3D consistency. We propose Human 3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion. Our key insight is that 2D multi-view diffusion and 3D reconstruction models provide complementary information for each other, and by coupling them in a tight manner, we can fully leverage the potential of both models. We introduce a novel image-conditioned generative 3D Gaussian Splats reconstruction model that leverages the priors from 2D multi-view diffusion models, and provides an explicit 3D representation, which further guides the 2D reverse sampling process to have better 3D consistency. Experiments show that our proposed framework outperforms state-of-the-art methods and enables the creation of realistic avatars from a single RGB image, achieving high-fidelity in both geometry and appearance. Extensive ablations also validate the efficacy of our design, (1) multi-view 2D priors conditioning in generative 3D reconstruction and (2) consistency refinement of sampling trajectory via the explicit 3D representation. Our code and models will be released on https://yuxuan-xue.com/human-3diffusion.","sentences":["Creating realistic avatars from a single RGB image is an attractive yet challenging problem.","Due to its ill-posed nature, recent works leverage powerful prior from 2D diffusion models pretrained on large datasets.","Although 2D diffusion models demonstrate strong generalization capability, they cannot provide multi-view shape priors with guaranteed 3D consistency.","We propose Human 3Diffusion:","Realistic Avatar Creation via Explicit 3D Consistent Diffusion.","Our key insight is that 2D multi-view diffusion and 3D reconstruction models provide complementary information for each other, and by coupling them in a tight manner, we can fully leverage the potential of both models.","We introduce a novel image-conditioned generative 3D Gaussian Splats reconstruction model that leverages the priors from 2D multi-view diffusion models, and provides an explicit 3D representation, which further guides the 2D reverse sampling process to have better 3D consistency.","Experiments show that our proposed framework outperforms state-of-the-art methods and enables the creation of realistic avatars from a single RGB image, achieving high-fidelity in both geometry and appearance.","Extensive ablations also validate the efficacy of our design, (1) multi-view 2D priors conditioning in generative 3D reconstruction and (2) consistency refinement of sampling trajectory via the explicit 3D representation.","Our code and models will be released on https://yuxuan-xue.com/human-3diffusion."],"url":"http://arxiv.org/abs/2406.08475v1"}
{"created":"2024-06-12 17:57:06","title":"Real2Code: Reconstruct Articulated Objects via Code Generation","abstract":"We present Real2Code, a novel approach to reconstructing articulated objects via code generation. Given visual observations of an object, we first reconstruct its part geometry using an image segmentation model and a shape completion model. We then represent the object parts with oriented bounding boxes, which are input to a fine-tuned large language model (LLM) to predict joint articulation as code. By leveraging pre-trained vision and language models, our approach scales elegantly with the number of articulated parts, and generalizes from synthetic training data to real world objects in unstructured environments. Experimental results demonstrate that Real2Code significantly outperforms previous state-of-the-art in reconstruction accuracy, and is the first approach to extrapolate beyond objects' structural complexity in the training set, and reconstructs objects with up to 10 articulated parts. When incorporated with a stereo reconstruction model, Real2Code also generalizes to real world objects from a handful of multi-view RGB images, without the need for depth or camera information.","sentences":["We present Real2Code, a novel approach to reconstructing articulated objects via code generation.","Given visual observations of an object, we first reconstruct its part geometry using an image segmentation model and a shape completion model.","We then represent the object parts with oriented bounding boxes, which are input to a fine-tuned large language model (LLM) to predict joint articulation as code.","By leveraging pre-trained vision and language models, our approach scales elegantly with the number of articulated parts, and generalizes from synthetic training data to real world objects in unstructured environments.","Experimental results demonstrate that Real2Code significantly outperforms previous state-of-the-art in reconstruction accuracy, and is the first approach to extrapolate beyond objects' structural complexity in the training set, and reconstructs objects with up to 10 articulated parts.","When incorporated with a stereo reconstruction model, Real2Code also generalizes to real world objects from a handful of multi-view RGB images, without the need for depth or camera information."],"url":"http://arxiv.org/abs/2406.08474v1"}
{"created":"2024-06-12 17:56:46","title":"Strategies for Pretraining Neural Operators","abstract":"Pretraining for partial differential equation (PDE) modeling has recently shown promise in scaling neural operators across datasets to improve generalizability and performance. Despite these advances, our understanding of how pretraining affects neural operators is still limited; studies generally propose tailored architectures and datasets that make it challenging to compare or examine different pretraining frameworks. To address this, we compare various pretraining methods without optimizing architecture choices to characterize pretraining dynamics on different models and datasets as well as to understand its scaling and generalization behavior. We find that pretraining is highly dependent on model and dataset choices, but in general transfer learning or physics-based pretraining strategies work best. In addition, pretraining performance can be further improved by using data augmentations. Lastly, pretraining is additionally beneficial when fine-tuning in scarce data regimes or when generalizing to downstream data similar to the pretraining distribution. Through providing insights into pretraining neural operators for physics prediction, we hope to motivate future work in developing and evaluating pretraining methods for PDEs.","sentences":["Pretraining for partial differential equation (PDE) modeling has recently shown promise in scaling neural operators across datasets to improve generalizability and performance.","Despite these advances, our understanding of how pretraining affects neural operators is still limited; studies generally propose tailored architectures and datasets that make it challenging to compare or examine different pretraining frameworks.","To address this, we compare various pretraining methods without optimizing architecture choices to characterize pretraining dynamics on different models and datasets as well as to understand its scaling and generalization behavior.","We find that pretraining is highly dependent on model and dataset choices, but in general transfer learning or physics-based pretraining strategies work best.","In addition, pretraining performance can be further improved by using data augmentations.","Lastly, pretraining is additionally beneficial when fine-tuning in scarce data regimes or when generalizing to downstream data similar to the pretraining distribution.","Through providing insights into pretraining neural operators for physics prediction, we hope to motivate future work in developing and evaluating pretraining methods for PDEs."],"url":"http://arxiv.org/abs/2406.08473v1"}
{"created":"2024-06-12 17:56:31","title":"RILe: Reinforced Imitation Learning","abstract":"Reinforcement Learning has achieved significant success in generating complex behavior but often requires extensive reward function engineering. Adversarial variants of Imitation Learning and Inverse Reinforcement Learning offer an alternative by learning policies from expert demonstrations via a discriminator. Employing discriminators increases their data- and computational efficiency over the standard approaches; however, results in sensitivity to imperfections in expert data. We propose RILe, a teacher-student system that achieves both robustness to imperfect data and efficiency. In RILe, the student learns an action policy while the teacher dynamically adjusts a reward function based on the student's performance and its alignment with expert demonstrations. By tailoring the reward function to both performance of the student and expert similarity, our system reduces dependence on the discriminator and, hence, increases robustness against data imperfections. Experiments show that RILe outperforms existing methods by 2x in settings with limited or noisy expert data.","sentences":["Reinforcement Learning has achieved significant success in generating complex behavior but often requires extensive reward function engineering.","Adversarial variants of Imitation Learning and Inverse Reinforcement Learning offer an alternative by learning policies from expert demonstrations via a discriminator.","Employing discriminators increases their data- and computational efficiency over the standard approaches; however, results in sensitivity to imperfections in expert data.","We propose RILe, a teacher-student system that achieves both robustness to imperfect data and efficiency.","In RILe, the student learns an action policy while the teacher dynamically adjusts a reward function based on the student's performance and its alignment with expert demonstrations.","By tailoring the reward function to both performance of the student and expert similarity, our system reduces dependence on the discriminator and, hence, increases robustness against data imperfections.","Experiments show that RILe outperforms existing methods by 2x in settings with limited or noisy expert data."],"url":"http://arxiv.org/abs/2406.08472v1"}
{"created":"2024-06-12 17:56:15","title":"Surprise! Using Physiological Stress for Allostatic Regulation Under the Active Inference Framework [Pre-Print]","abstract":"Allostasis proposes that long-term viability of a living system is achieved through anticipatory adjustments of its physiology and behaviour: emphasising physiological and affective stress as an adaptive state of adaptation that minimizes long-term prediction errors. More recently, the active inference framework (AIF) has also sought to explain action and long-term adaptation through the minimization of future errors (free energy), through the learning of statistical contingencies of the world, offering a formalism for allostatic regulation. We suggest that framing prediction errors through the lens of biological hormonal dynamics proposed by allostasis offers a way to integrate these two models together in a biologically-plausible manner. In this paper, we describe our initial work in developing a model that grounds prediction errors (surprisal) into the secretion of a physiological stress hormone (cortisol) acting as an adaptive, allostatic mediator on a homeostatically-controlled physiology. We evaluate this using a computational model in simulations using an active inference agent endowed with an artificial physiology, regulated through homeostatic and allostatic control in a stochastic environment. Our results find that allostatic functions of cortisol (stress), secreted as a function of prediction errors, provide adaptive advantages to the agent's long-term physiological regulation. We argue that the coupling of information-theoretic prediction errors to low-level, biological hormonal dynamics of stress can provide a computationally efficient model to long-term regulation for embodied intelligent systems.","sentences":["Allostasis proposes that long-term viability of a living system is achieved through anticipatory adjustments of its physiology and behaviour: emphasising physiological and affective stress as an adaptive state of adaptation that minimizes long-term prediction errors.","More recently, the active inference framework (AIF) has also sought to explain action and long-term adaptation through the minimization of future errors (free energy), through the learning of statistical contingencies of the world, offering a formalism for allostatic regulation.","We suggest that framing prediction errors through the lens of biological hormonal dynamics proposed by allostasis offers a way to integrate these two models together in a biologically-plausible manner.","In this paper, we describe our initial work in developing a model that grounds prediction errors (surprisal) into the secretion of a physiological stress hormone (cortisol) acting as an adaptive, allostatic mediator on a homeostatically-controlled physiology.","We evaluate this using a computational model in simulations using an active inference agent endowed with an artificial physiology, regulated through homeostatic and allostatic control in a stochastic environment.","Our results find that allostatic functions of cortisol (stress), secreted as a function of prediction errors, provide adaptive advantages to the agent's long-term physiological regulation.","We argue that the coupling of information-theoretic prediction errors to low-level, biological hormonal dynamics of stress can provide a computationally efficient model to long-term regulation for embodied intelligent systems."],"url":"http://arxiv.org/abs/2406.08471v1"}
{"created":"2024-06-12 17:54:54","title":"PAL: Pluralistic Alignment Framework for Learning from Heterogeneous Preferences","abstract":"Large foundation models pretrained on raw web-scale data are not readily deployable without additional step of extensive alignment to human preferences. Such alignment is typically done by collecting large amounts of pairwise comparisons from humans (\"Do you prefer output A or B?\") and learning a reward model or a policy with the Bradley-Terry-Luce (BTL) model as a proxy for a human's underlying implicit preferences. These methods generally suffer from assuming a universal preference shared by all humans, which lacks the flexibility of adapting to plurality of opinions and preferences. In this work, we propose PAL, a framework to model human preference complementary to existing pretraining strategies, which incorporates plurality from the ground up. We propose using the ideal point model as a lens to view alignment using preference comparisons. Together with our novel reformulation and using mixture modeling, our framework captures the plurality of population preferences while simultaneously learning a common preference latent space across different preferences, which can few-shot generalize to new, unseen users. Our approach enables us to use the penultimate-layer representation of large foundation models and simple MLP layers to learn reward functions that are on-par with the existing large state-of-the-art reward models, thereby enhancing efficiency of reward modeling significantly. We show that PAL achieves competitive reward model accuracy compared to strong baselines on 1) Language models with Summary dataset ; 2) Image Generative models with Pick-a-Pic dataset ; 3) A new semisynthetic heterogeneous dataset generated using Anthropic Personas. Finally, our experiments also highlight the shortcoming of current preference datasets that are created using rigid rubrics which wash away heterogeneity, and call for more nuanced data collection approaches.","sentences":["Large foundation models pretrained on raw web-scale data are not readily deployable without additional step of extensive alignment to human preferences.","Such alignment is typically done by collecting large amounts of pairwise comparisons from humans (\"Do you prefer output A or B?\") and learning a reward model or a policy with the Bradley-Terry-Luce (BTL) model as a proxy for a human's underlying implicit preferences.","These methods generally suffer from assuming a universal preference shared by all humans, which lacks the flexibility of adapting to plurality of opinions and preferences.","In this work, we propose PAL, a framework to model human preference complementary to existing pretraining strategies, which incorporates plurality from the ground up.","We propose using the ideal point model as a lens to view alignment using preference comparisons.","Together with our novel reformulation and using mixture modeling, our framework captures the plurality of population preferences while simultaneously learning a common preference latent space across different preferences, which can few-shot generalize to new, unseen users.","Our approach enables us to use the penultimate-layer representation of large foundation models and simple MLP layers to learn reward functions that are on-par with the existing large state-of-the-art reward models, thereby enhancing efficiency of reward modeling significantly.","We show that PAL achieves competitive reward model accuracy compared to strong baselines on 1) Language models with Summary dataset ; 2) Image Generative models with Pick-a-Pic dataset ; 3) A new semisynthetic heterogeneous dataset generated using Anthropic Personas.","Finally, our experiments also highlight the shortcoming of current preference datasets that are created using rigid rubrics which wash away heterogeneity, and call for more nuanced data collection approaches."],"url":"http://arxiv.org/abs/2406.08469v1"}
{"created":"2024-06-12 17:53:31","title":"DafnyBench: A Benchmark for Formal Software Verification","abstract":"We introduce DafnyBench, the largest benchmark of its kind for training and evaluating machine learning systems for formal software verification. We test the ability of LLMs such as GPT-4 and Claude 3 to auto-generate enough hints for the Dafny formal verification engine to successfully verify over 750 programs with about 53,000 lines of code. The best model and prompting scheme achieved 68% success rate, and we quantify how this rate improves when retrying with error message feedback and how it deteriorates with the amount of required code and hints. We hope that DafnyBench will enable rapid improvements from this baseline as LLMs and verification techniques grow in quality.","sentences":["We introduce DafnyBench, the largest benchmark of its kind for training and evaluating machine learning systems for formal software verification.","We test the ability of LLMs such as GPT-4 and Claude 3 to auto-generate enough hints for the Dafny formal verification engine to successfully verify over 750 programs with about 53,000 lines of code.","The best model and prompting scheme achieved 68% success rate, and we quantify how this rate improves when retrying with error message feedback and how it deteriorates with the amount of required code and hints.","We hope that DafnyBench will enable rapid improvements from this baseline as LLMs and verification techniques grow in quality."],"url":"http://arxiv.org/abs/2406.08467v1"}
{"created":"2024-06-12 17:53:29","title":"Scaling Laws in Linear Regression: Compute, Parameters, and Data","abstract":"Empirically, large-scale deep learning models often satisfy a neural scaling law: the test error of the trained model improves polynomially as the model size and data size grow. However, conventional wisdom suggests the test error consists of approximation, bias, and variance errors, where the variance error increases with model size. This disagrees with the general form of neural scaling laws, which predict that increasing model size monotonically improves performance.   We study the theory of scaling laws in an infinite dimensional linear regression setup. Specifically, we consider a model with $M$ parameters as a linear function of sketched covariates. The model is trained by one-pass stochastic gradient descent (SGD) using $N$ data. Assuming the optimal parameter satisfies a Gaussian prior and the data covariance matrix has a power-law spectrum of degree $a>1$, we show that the reducible part of the test error is $\\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which increases with $M$, is dominated by the other errors due to the implicit regularization of SGD, thus disappearing from the bound. Our theory is consistent with the empirical neural scaling laws and verified by numerical simulation.","sentences":["Empirically, large-scale deep learning models often satisfy a neural scaling law: the test error of the trained model improves polynomially as the model size and data size grow.","However, conventional wisdom suggests the test error consists of approximation, bias, and variance errors, where the variance error increases with model size.","This disagrees with the general form of neural scaling laws, which predict that increasing model size monotonically improves performance.   ","We study the theory of scaling laws in an infinite dimensional linear regression setup.","Specifically, we consider a model with $M$ parameters as a linear function of sketched covariates.","The model is trained by one-pass stochastic gradient descent (SGD) using $N$ data.","Assuming the optimal parameter satisfies a Gaussian prior and the data covariance matrix has a power-law spectrum of degree $a>1$, we show that the reducible part of the test error is $\\Theta(M^{-(a-1)}","+ N^{-(a-1)/a})$. The variance error, which increases with $M$, is dominated by the other errors due to the implicit regularization of SGD, thus disappearing from the bound.","Our theory is consistent with the empirical neural scaling laws and verified by numerical simulation."],"url":"http://arxiv.org/abs/2406.08466v1"}
{"created":"2024-06-12 17:53:28","title":"Nonconvex Federated Learning on Compact Smooth Submanifolds With Heterogeneous Data","abstract":"Many machine learning tasks, such as principal component analysis and low-rank matrix completion, give rise to manifold optimization problems. Although there is a large body of work studying the design and analysis of algorithms for manifold optimization in the centralized setting, there are currently very few works addressing the federated setting. In this paper, we consider nonconvex federated learning over a compact smooth submanifold in the setting of heterogeneous client data. We propose an algorithm that leverages stochastic Riemannian gradients and a manifold projection operator to improve computational efficiency, uses local updates to improve communication efficiency, and avoids client drift. Theoretically, we show that our proposed algorithm converges sub-linearly to a neighborhood of a first-order optimal solution by using a novel analysis that jointly exploits the manifold structure and properties of the loss functions. Numerical experiments demonstrate that our algorithm has significantly smaller computational and communication overhead than existing methods.","sentences":["Many machine learning tasks, such as principal component analysis and low-rank matrix completion, give rise to manifold optimization problems.","Although there is a large body of work studying the design and analysis of algorithms for manifold optimization in the centralized setting, there are currently very few works addressing the federated setting.","In this paper, we consider nonconvex federated learning over a compact smooth submanifold in the setting of heterogeneous client data.","We propose an algorithm that leverages stochastic Riemannian gradients and a manifold projection operator to improve computational efficiency, uses local updates to improve communication efficiency, and avoids client drift.","Theoretically, we show that our proposed algorithm converges sub-linearly to a neighborhood of a first-order optimal solution by using a novel analysis that jointly exploits the manifold structure and properties of the loss functions.","Numerical experiments demonstrate that our algorithm has significantly smaller computational and communication overhead than existing methods."],"url":"http://arxiv.org/abs/2406.08465v1"}
{"created":"2024-06-12 17:52:30","title":"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing","abstract":"High-quality instruction data is critical for aligning large language models (LLMs). Although some models, such as Llama-3-Instruct, have open weights, their alignment data remain private, which hinders the democratization of AI. High human labor costs and a limited, predefined scope for prompting prevent existing open-source data creation methods from scaling effectively, potentially limiting the diversity and quality of public alignment datasets. Is it possible to synthesize high-quality instruction data at scale by extracting it directly from an aligned LLM? We present a self-synthesis method for generating large-scale alignment data named Magpie. Our key observation is that aligned LLMs like Llama-3-Instruct can generate a user query when we input only the left-side templates up to the position reserved for user messages, thanks to their auto-regressive nature. We use this method to prompt Llama-3-Instruct and generate 4 million instructions along with their corresponding responses. We perform a comprehensive analysis of the extracted data and select 300K high-quality instances. To compare Magpie data with other public instruction datasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the performance of the fine-tuned models. Our results indicate that in some tasks, models fine-tuned with Magpie perform comparably to the official Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data points through supervised fine-tuning (SFT) and subsequent feedback learning. We also show that using Magpie solely for SFT can surpass the performance of previous public datasets utilized for both SFT and preference optimization, such as direct preference optimization with UltraFeedback. This advantage is evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.","sentences":["High-quality instruction data is critical for aligning large language models (LLMs).","Although some models, such as Llama-3-Instruct, have open weights, their alignment data remain private, which hinders the democratization of AI.","High human labor costs and a limited, predefined scope for prompting prevent existing open-source data creation methods from scaling effectively, potentially limiting the diversity and quality of public alignment datasets.","Is it possible to synthesize high-quality instruction data at scale by extracting it directly from an aligned LLM?","We present a self-synthesis method for generating large-scale alignment data named Magpie.","Our key observation is that aligned LLMs like Llama-3-Instruct can generate a user query when we input only the left-side templates up to the position reserved for user messages, thanks to their auto-regressive nature.","We use this method to prompt Llama-3-Instruct and generate 4 million instructions along with their corresponding responses.","We perform a comprehensive analysis of the extracted data and select 300K high-quality instances.","To compare Magpie data with other public instruction datasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the performance of the fine-tuned models.","Our results indicate that in some tasks, models fine-tuned with Magpie perform comparably to the official Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data points through supervised fine-tuning (SFT) and subsequent feedback learning.","We also show that using Magpie solely for SFT can surpass the performance of previous public datasets utilized for both SFT and preference optimization, such as direct preference optimization with UltraFeedback.","This advantage is evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench."],"url":"http://arxiv.org/abs/2406.08464v1"}
{"created":"2024-06-12 17:51:53","title":"Self-supervised Learning of Neural Implicit Feature Fields for Camera Pose Refinement","abstract":"Visual localization techniques rely upon some underlying scene representation to localize against. These representations can be explicit such as 3D SFM map or implicit, such as a neural network that learns to encode the scene. The former requires sparse feature extractors and matchers to build the scene representation. The latter might lack geometric grounding not capturing the 3D structure of the scene well enough. This paper proposes to jointly learn the scene representation along with a 3D dense feature field and a 2D feature extractor whose outputs are embedded in the same metric space. Through a contrastive framework we align this volumetric field with the image-based extractor and regularize the latter with a ranking loss from learned surface information. We learn the underlying geometry of the scene with an implicit field through volumetric rendering and design our feature field to leverage intermediate geometric information encoded in the implicit field. The resulting features are discriminative and robust to viewpoint change while maintaining rich encoded information. Visual localization is then achieved by aligning the image-based features and the rendered volumetric features. We show the effectiveness of our approach on real-world scenes, demonstrating that our approach outperforms prior and concurrent work on leveraging implicit scene representations for localization.","sentences":["Visual localization techniques rely upon some underlying scene representation to localize against.","These representations can be explicit such as 3D SFM map or implicit, such as a neural network that learns to encode the scene.","The former requires sparse feature extractors and matchers to build the scene representation.","The latter might lack geometric grounding not capturing the 3D structure of the scene well enough.","This paper proposes to jointly learn the scene representation along with a 3D dense feature field and a 2D feature extractor whose outputs are embedded in the same metric space.","Through a contrastive framework we align this volumetric field with the image-based extractor and regularize the latter with a ranking loss from learned surface information.","We learn the underlying geometry of the scene with an implicit field through volumetric rendering and design our feature field to leverage intermediate geometric information encoded in the implicit field.","The resulting features are discriminative and robust to viewpoint change while maintaining rich encoded information.","Visual localization is then achieved by aligning the image-based features and the rendered volumetric features.","We show the effectiveness of our approach on real-world scenes, demonstrating that our approach outperforms prior and concurrent work on leveraging implicit scene representations for localization."],"url":"http://arxiv.org/abs/2406.08463v1"}
{"created":"2024-06-12 17:51:47","title":"Bridging the Gap: Unravelling Local Government Data Sharing Barriers in Estonia and Beyond","abstract":"Estonia's digital government success has received global acclaim, yet its Open Government Data (OGD) initiatives, especially at the local level, encounter persistent challenges. Despite significant progress of national OGD initiative in OGD rankings, local governments lag in OGD provision. This study aims to examine barriers hindering municipalities from openly sharing OGD. Employing a qualitative approach through interviews with Estonian municipalities and drawing on the OGD-adapted Innovation Resistance Theory model, the study sheds light on barriers impeding OGD sharing. Practical recommendations are proposed to bridge the gap between national policies and local implementation, including enhancing awareness, improving data governance frameworks, and fostering collaboration be-tween local and national authorities. By addressing overlooked weaknesses in the Estonian open data ecosystem and providing actionable recommendations, this research contributes to a more resilient and sustainable open data ecosystem. Additionally, by validating the OGD-adapted Innovation Resistance Theory model and proposing a revised version tailored for local government contexts, the study advances theoretical frameworks for understanding data sharing resistance. Ultimately, this study serves as a call to action for policymakers and practitioners to prioritize local OGD initiatives.","sentences":["Estonia's digital government success has received global acclaim, yet its Open Government Data (OGD) initiatives, especially at the local level, encounter persistent challenges.","Despite significant progress of national OGD initiative in OGD rankings, local governments lag in OGD provision.","This study aims to examine barriers hindering municipalities from openly sharing OGD.","Employing a qualitative approach through interviews with Estonian municipalities and drawing on the OGD-adapted Innovation Resistance Theory model, the study sheds light on barriers impeding OGD sharing.","Practical recommendations are proposed to bridge the gap between national policies and local implementation, including enhancing awareness, improving data governance frameworks, and fostering collaboration be-tween local and national authorities.","By addressing overlooked weaknesses in the Estonian open data ecosystem and providing actionable recommendations, this research contributes to a more resilient and sustainable open data ecosystem.","Additionally, by validating the OGD-adapted Innovation Resistance Theory model and proposing a revised version tailored for local government contexts, the study advances theoretical frameworks for understanding data sharing resistance.","Ultimately, this study serves as a call to action for policymakers and practitioners to prioritize local OGD initiatives."],"url":"http://arxiv.org/abs/2406.08461v1"}
{"created":"2024-06-12 17:49:26","title":"ConceptHash: Interpretable Fine-Grained Hashing via Concept Discovery","abstract":"Existing fine-grained hashing methods typically lack code interpretability as they compute hash code bits holistically using both global and local features. To address this limitation, we propose ConceptHash, a novel method that achieves sub-code level interpretability. In ConceptHash, each sub-code corresponds to a human-understandable concept, such as an object part, and these concepts are automatically discovered without human annotations. Specifically, we leverage a Vision Transformer architecture and introduce concept tokens as visual prompts, along with image patch tokens as model inputs. Each concept is then mapped to a specific sub-code at the model output, providing natural sub-code interpretability. To capture subtle visual differences among highly similar sub-categories (e.g., bird species), we incorporate language guidance to ensure that the learned hash codes are distinguishable within fine-grained object classes while maintaining semantic alignment. This approach allows us to develop hash codes that exhibit similarity within families of species while remaining distinct from species in other families. Extensive experiments on four fine-grained image retrieval benchmarks demonstrate that ConceptHash outperforms previous methods by a significant margin, offering unique sub-code interpretability as an additional benefit. Code at: https://github.com/kamwoh/concepthash.","sentences":["Existing fine-grained hashing methods typically lack code interpretability as they compute hash code bits holistically using both global and local features.","To address this limitation, we propose ConceptHash, a novel method that achieves sub-code level interpretability.","In ConceptHash, each sub-code corresponds to a human-understandable concept, such as an object part, and these concepts are automatically discovered without human annotations.","Specifically, we leverage a Vision Transformer architecture and introduce concept tokens as visual prompts, along with image patch tokens as model inputs.","Each concept is then mapped to a specific sub-code at the model output, providing natural sub-code interpretability.","To capture subtle visual differences among highly similar sub-categories (e.g., bird species), we incorporate language guidance to ensure that the learned hash codes are distinguishable within fine-grained object classes while maintaining semantic alignment.","This approach allows us to develop hash codes that exhibit similarity within families of species while remaining distinct from species in other families.","Extensive experiments on four fine-grained image retrieval benchmarks demonstrate that ConceptHash outperforms previous methods by a significant margin, offering unique sub-code interpretability as an additional benefit.","Code at: https://github.com/kamwoh/concepthash."],"url":"http://arxiv.org/abs/2406.08457v1"}
{"created":"2024-06-12 17:47:04","title":"AToM-Bot: Embodied Fulfillment of Unspoken Human Needs with Affective Theory of Mind","abstract":"We propose AToM-Bot, a novel task generation and execution framework for proactive robot-human interaction, which leverages the human mental and physical state inference capabilities of the Vision Language Model (VLM) prompted by the Affective Theory of Mind (AToM). Without requiring explicit commands by humans, AToM-Bot proactively generates and follows feasible tasks to improve general human well-being. When around humans, AToM-Bot first detects current human needs based on inferred human states and observations of the surrounding environment. It then generates tasks to fulfill these needs, taking into account its embodied constraints. We designed 16 daily life scenarios spanning 4 common scenes and tasked the same visual stimulus to 59 human subjects and our robot. We used the similarity between human open-ended answers and robot output, and the human satisfaction scores to metric robot performance. AToM-Bot received high human evaluations in need detection (6.42/7, 91.7%), embodied solution (6.15/7, 87.8%) and task execution (6.17/7, 88.1%). We show that AToM-Bot excels in generating and executing feasible plans to fulfill unspoken human needs. Videos and code are available at https://affective-tom-bot.github.io.","sentences":["We propose AToM-Bot, a novel task generation and execution framework for proactive robot-human interaction, which leverages the human mental and physical state inference capabilities of the Vision Language Model (VLM) prompted by the Affective Theory of Mind (AToM).","Without requiring explicit commands by humans, AToM-Bot proactively generates and follows feasible tasks to improve general human well-being.","When around humans, AToM-Bot first detects current human needs based on inferred human states and observations of the surrounding environment.","It then generates tasks to fulfill these needs, taking into account its embodied constraints.","We designed 16 daily life scenarios spanning 4 common scenes and tasked the same visual stimulus to 59 human subjects and our robot.","We used the similarity between human open-ended answers and robot output, and the human satisfaction scores to metric robot performance.","AToM-Bot received high human evaluations in need detection (6.42/7, 91.7%), embodied solution (6.15/7, 87.8%) and task execution (6.17/7, 88.1%).","We show that AToM-Bot excels in generating and executing feasible plans to fulfill unspoken human needs.","Videos and code are available at https://affective-tom-bot.github.io."],"url":"http://arxiv.org/abs/2406.08455v1"}
{"created":"2024-06-12 17:45:28","title":"Towards Musically Informed Evaluation of Piano Transcription Models","abstract":"Automatic piano transcription models are typically evaluated using simple frame- or note-wise information retrieval (IR) metrics. Such benchmark metrics do not provide insights into the transcription quality of specific musical aspects such as articulation, dynamics, or rhythmic precision of the output, which are essential in the context of expressive performance analysis. Furthermore, in recent years, MAESTRO has become the de-facto training and evaluation dataset for such models. However, inference performance has been observed to deteriorate substantially when applied on out-of-distribution data, thereby questioning the suitability and reliability of transcribed outputs from such models for specific MIR tasks. In this work, we investigate the performance of three state-of-the-art piano transcription models in two experiments. In the first one, we propose a variety of musically informed evaluation metrics which, in contrast to the IR metrics, offer more detailed insight into the musical quality of the transcriptions. In the second experiment, we compare inference performance on real-world and perturbed audio recordings, and highlight musical dimensions which our metrics can help explain. Our experimental results highlight the weaknesses of existing piano transcription metrics and contribute to a more musically sound error analysis of transcription outputs.","sentences":["Automatic piano transcription models are typically evaluated using simple frame- or note-wise information retrieval (IR) metrics.","Such benchmark metrics do not provide insights into the transcription quality of specific musical aspects such as articulation, dynamics, or rhythmic precision of the output, which are essential in the context of expressive performance analysis.","Furthermore, in recent years, MAESTRO has become the de-facto training and evaluation dataset for such models.","However, inference performance has been observed to deteriorate substantially when applied on out-of-distribution data, thereby questioning the suitability and reliability of transcribed outputs from such models for specific MIR tasks.","In this work, we investigate the performance of three state-of-the-art piano transcription models in two experiments.","In the first one, we propose a variety of musically informed evaluation metrics which, in contrast to the IR metrics, offer more detailed insight into the musical quality of the transcriptions.","In the second experiment, we compare inference performance on real-world and perturbed audio recordings, and highlight musical dimensions which our metrics can help explain.","Our experimental results highlight the weaknesses of existing piano transcription metrics and contribute to a more musically sound error analysis of transcription outputs."],"url":"http://arxiv.org/abs/2406.08454v1"}
{"created":"2024-06-12 17:45:04","title":"ORES-Inspect: A technology probe for machine learning audits on enwiki","abstract":"Auditing the machine learning (ML) models used on Wikipedia is important for ensuring that vandalism-detection processes remain fair and effective. However, conducting audits is challenging because stakeholders have diverse priorities and assembling evidence for a model's [in]efficacy is technically complex. We designed an interface to enable editors to learn about and audit the performance of the ORES edit quality model. ORES-Inspect is an open-source web tool and a provocative technology probe for researching how editors think about auditing the many ML models used on Wikipedia. We describe the design of ORES-Inspect and our plans for further research with this system.","sentences":["Auditing the machine learning (ML) models used on Wikipedia is important for ensuring that vandalism-detection processes remain fair and effective.","However, conducting audits is challenging because stakeholders have diverse priorities and assembling evidence for a model's [in]efficacy is technically complex.","We designed an interface to enable editors to learn about and audit the performance of the ORES edit quality model.","ORES-Inspect is an open-source web tool and a provocative technology probe for researching how editors think about auditing the many ML models used on Wikipedia.","We describe the design of ORES-Inspect and our plans for further research with this system."],"url":"http://arxiv.org/abs/2406.08453v1"}
{"created":"2024-06-12 17:44:26","title":"GUI Odyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices","abstract":"Smartphone users often navigate across multiple applications (apps) to complete tasks such as sharing content between social media platforms. Autonomous Graphical User Interface (GUI) navigation agents can enhance user experience in communication, entertainment, and productivity by streamlining workflows and reducing manual intervention. However, prior GUI agents often trained with datasets comprising simple tasks that can be completed within a single app, leading to poor performance in cross-app navigation. To address this problem, we introduce GUI Odyssey, a comprehensive dataset for training and evaluating cross-app navigation agents. GUI Odyssey consists of 7,735 episodes from 6 mobile devices, spanning 6 types of cross-app tasks, 201 apps, and 1.4K app combos. Leveraging GUI Odyssey, we developed OdysseyAgent, a multimodal cross-app navigation agent by fine-tuning the Qwen-VL model with a history resampling module. Extensive experiments demonstrate OdysseyAgent's superior accuracy compared to existing models. For instance, OdysseyAgent surpasses fine-tuned Qwen-VL and zero-shot GPT-4V by 1.44\\% and 55.49\\% in-domain accuracy, and 2.29\\% and 48.14\\% out-of-domain accuracy on average. The dataset and code will be released in \\url{https://github.com/OpenGVLab/GUI-Odyssey}.","sentences":["Smartphone users often navigate across multiple applications (apps) to complete tasks such as sharing content between social media platforms.","Autonomous Graphical User Interface (GUI) navigation agents can enhance user experience in communication, entertainment, and productivity by streamlining workflows and reducing manual intervention.","However, prior GUI agents often trained with datasets comprising simple tasks that can be completed within a single app, leading to poor performance in cross-app navigation.","To address this problem, we introduce GUI Odyssey, a comprehensive dataset for training and evaluating cross-app navigation agents.","GUI Odyssey consists of 7,735 episodes from 6 mobile devices, spanning 6 types of cross-app tasks, 201 apps, and 1.4K app combos.","Leveraging GUI Odyssey, we developed OdysseyAgent, a multimodal cross-app navigation agent by fine-tuning the Qwen-VL model with a history resampling module.","Extensive experiments demonstrate OdysseyAgent's superior accuracy compared to existing models.","For instance, OdysseyAgent surpasses fine-tuned Qwen-VL and zero-shot GPT-4V by 1.44\\% and 55.49\\% in-domain accuracy, and 2.29\\% and 48.14\\% out-of-domain accuracy on average.","The dataset and code will be released in \\url{https://github.com/OpenGVLab/GUI-Odyssey}."],"url":"http://arxiv.org/abs/2406.08451v1"}
{"created":"2024-06-12 17:38:20","title":"The Impact of Initialization on LoRA Finetuning Dynamics","abstract":"In this paper, we study the role of initialization in Low Rank Adaptation (LoRA) as originally introduced in Hu et al. (2021). Essentially, to start from the pretrained model as initialization for finetuning, one can either initialize B to zero and A to random (default initialization in PEFT package), or vice-versa. In both cases, the product BA is equal to zero at initialization, which makes finetuning starts from the pretrained model. These two initialization schemes are seemingly similar. They should in-principle yield the same performance and share the same optimal learning rate. We demonstrate that this is an incorrect intuition and that the first scheme (initializing B to zero and A to random) on average yields better performance compared to the other scheme. Our theoretical analysis shows that the reason behind this might be that the first initialization allows the use of larger learning rates (without causing output instability) compared to the second initialization, resulting in more efficient learning of the first scheme. We validate our results with extensive experiments on LLMs.","sentences":["In this paper, we study the role of initialization in Low Rank Adaptation (LoRA) as originally introduced in Hu et al. (2021).","Essentially, to start from the pretrained model as initialization for finetuning, one can either initialize B to zero and A to random (default initialization in PEFT package), or vice-versa.","In both cases, the product BA is equal to zero at initialization, which makes finetuning starts from the pretrained model.","These two initialization schemes are seemingly similar.","They should in-principle yield the same performance and share the same optimal learning rate.","We demonstrate that this is an incorrect intuition and that the first scheme (initializing B to zero and A to random) on average yields better performance compared to the other scheme.","Our theoretical analysis shows that the reason behind this might be that the first initialization allows the use of larger learning rates (without causing output instability) compared to the second initialization, resulting in more efficient learning of the first scheme.","We validate our results with extensive experiments on LLMs."],"url":"http://arxiv.org/abs/2406.08447v1"}
{"created":"2024-06-12 17:37:09","title":"OLMES: A Standard for Language Model Evaluations","abstract":"Progress in AI is often demonstrated by new models claiming improved performance on tasks measuring model capabilities. Evaluating language models in particular is challenging, as small changes to how a model is evaluated on a task can lead to large changes in measured performance. There is no common standard setup, so different models are evaluated on the same tasks in different ways, leading to claims about which models perform best not being reproducible. We propose OLMES, a completely documented, practical, open standard for reproducible LLM evaluations. In developing this standard, we identify and review the varying factors in evaluation practices adopted by the community - such as details of prompt formatting, choice of in-context examples, probability normalizations, and task formulation. In particular, OLMES supports meaningful comparisons between smaller base models that require the unnatural \"cloze\" formulation of multiple-choice questions against larger models that can utilize the original formulation. OLMES includes well-considered recommendations guided by results from existing literature as well as new experiments investigating open questions.","sentences":["Progress in AI is often demonstrated by new models claiming improved performance on tasks measuring model capabilities.","Evaluating language models in particular is challenging, as small changes to how a model is evaluated on a task can lead to large changes in measured performance.","There is no common standard setup, so different models are evaluated on the same tasks in different ways, leading to claims about which models perform best not being reproducible.","We propose OLMES, a completely documented, practical, open standard for reproducible LLM evaluations.","In developing this standard, we identify and review the varying factors in evaluation practices adopted by the community - such as details of prompt formatting, choice of in-context examples, probability normalizations, and task formulation.","In particular, OLMES supports meaningful comparisons between smaller base models that require the unnatural \"cloze\" formulation of multiple-choice questions against larger models that can utilize the original formulation.","OLMES includes well-considered recommendations guided by results from existing literature as well as new experiments investigating open questions."],"url":"http://arxiv.org/abs/2406.08446v1"}
{"created":"2024-06-12 17:34:38","title":"PixMamba: Leveraging State Space Models in a Dual-Level Architecture for Underwater Image Enhancement","abstract":"Underwater Image Enhancement (UIE) is critical for marine research and exploration but hindered by complex color distortions and severe blurring. Recent deep learning-based methods have achieved remarkable results, yet these methods struggle with high computational costs and insufficient global modeling, resulting in locally under- or over- adjusted regions. We present PixMamba, a novel architecture, designed to overcome these challenges by leveraging State Space Models (SSMs) for efficient global dependency modeling. Unlike convolutional neural networks (CNNs) with limited receptive fields and transformer networks with high computational costs, PixMamba efficiently captures global contextual information while maintaining computational efficiency. Our dual-level strategy features the patch-level Efficient Mamba Net (EMNet) for reconstructing enhanced image feature and the pixel-level PixMamba Net (PixNet) to ensure fine-grained feature capturing and global consistency of enhanced image that were previously difficult to obtain. PixMamba achieves state-of-the-art performance across various underwater image datasets and delivers visually superior results. Code is available at: https://github.com/weitunglin/pixmamba.","sentences":["Underwater Image Enhancement (UIE) is critical for marine research and exploration but hindered by complex color distortions and severe blurring.","Recent deep learning-based methods have achieved remarkable results, yet these methods struggle with high computational costs and insufficient global modeling, resulting in locally under- or over- adjusted regions.","We present PixMamba, a novel architecture, designed to overcome these challenges by leveraging State Space Models (SSMs) for efficient global dependency modeling.","Unlike convolutional neural networks (CNNs) with limited receptive fields and transformer networks with high computational costs, PixMamba efficiently captures global contextual information while maintaining computational efficiency.","Our dual-level strategy features the patch-level Efficient Mamba Net (EMNet) for reconstructing enhanced image feature and the pixel-level PixMamba Net (PixNet) to ensure fine-grained feature capturing and global consistency of enhanced image that were previously difficult to obtain.","PixMamba achieves state-of-the-art performance across various underwater image datasets and delivers visually superior results.","Code is available at: https://github.com/weitunglin/pixmamba."],"url":"http://arxiv.org/abs/2406.08444v1"}
{"created":"2024-06-12 17:31:36","title":"Transformation-Dependent Adversarial Attacks","abstract":"We introduce transformation-dependent adversarial attacks, a new class of threats where a single additive perturbation can trigger diverse, controllable mis-predictions by systematically transforming the input (e.g., scaling, blurring, compression). Unlike traditional attacks with static effects, our perturbations embed metamorphic properties to enable different adversarial attacks as a function of the transformation parameters. We demonstrate the transformation-dependent vulnerability across models (e.g., convolutional networks and vision transformers) and vision tasks (e.g., image classification and object detection). Our proposed geometric and photometric transformations enable a range of targeted errors from one crafted input (e.g., higher than 90% attack success rate for classifiers). We analyze effects of model architecture and type/variety of transformations on attack effectiveness. This work forces a paradigm shift by redefining adversarial inputs as dynamic, controllable threats. We highlight the need for robust defenses against such multifaceted, chameleon-like perturbations that current techniques are ill-prepared for.","sentences":["We introduce transformation-dependent adversarial attacks, a new class of threats where a single additive perturbation can trigger diverse, controllable mis-predictions by systematically transforming the input (e.g., scaling, blurring, compression).","Unlike traditional attacks with static effects, our perturbations embed metamorphic properties to enable different adversarial attacks as a function of the transformation parameters.","We demonstrate the transformation-dependent vulnerability across models (e.g., convolutional networks and vision transformers) and vision tasks (e.g., image classification and object detection).","Our proposed geometric and photometric transformations enable a range of targeted errors from one crafted input (e.g., higher than 90% attack success rate for classifiers).","We analyze effects of model architecture and type/variety of transformations on attack effectiveness.","This work forces a paradigm shift by redefining adversarial inputs as dynamic, controllable threats.","We highlight the need for robust defenses against such multifaceted, chameleon-like perturbations that current techniques are ill-prepared for."],"url":"http://arxiv.org/abs/2406.08443v1"}
{"created":"2024-06-12 17:26:54","title":"Adaptive Swarm Mesh Refinement using Deep Reinforcement Learning with Local Rewards","abstract":"Simulating physical systems is essential in engineering, but analytical solutions are limited to straightforward problems. Consequently, numerical methods like the Finite Element Method (FEM) are widely used. However, the FEM becomes computationally expensive as problem complexity and accuracy demands increase. Adaptive Mesh Refinement (AMR) improves the FEM by dynamically allocating mesh elements on the domain, balancing computational speed and accuracy. Classical AMR depends on heuristics or expensive error estimators, limiting its use in complex simulations. While learning-based AMR methods are promising, they currently only scale to simple problems. In this work, we formulate AMR as a system of collaborating, homogeneous agents that iteratively split into multiple new agents. This agent-wise perspective enables a spatial reward formulation focused on reducing the maximum mesh element error. Our approach, Adaptive Swarm Mesh Refinement (ASMR), offers efficient, stable optimization and generates highly adaptive meshes at user-defined resolution during inference. Extensive experiments, including volumetric meshes and Neumann boundary conditions, demonstrate that ASMR exceeds heuristic approaches and learned baselines, matching the performance of expensive error-based oracle AMR strategies. ASMR additionally generalizes to different domains during inference, and produces meshes that simulate up to 2 orders of magnitude faster than uniform refinements in more demanding settings.","sentences":["Simulating physical systems is essential in engineering, but analytical solutions are limited to straightforward problems.","Consequently, numerical methods like the Finite Element Method (FEM) are widely used.","However, the FEM becomes computationally expensive as problem complexity and accuracy demands increase.","Adaptive Mesh Refinement (AMR) improves the FEM by dynamically allocating mesh elements on the domain, balancing computational speed and accuracy.","Classical AMR depends on heuristics or expensive error estimators, limiting its use in complex simulations.","While learning-based AMR methods are promising, they currently only scale to simple problems.","In this work, we formulate AMR as a system of collaborating, homogeneous agents that iteratively split into multiple new agents.","This agent-wise perspective enables a spatial reward formulation focused on reducing the maximum mesh element error.","Our approach, Adaptive Swarm Mesh Refinement (ASMR), offers efficient, stable optimization and generates highly adaptive meshes at user-defined resolution during inference.","Extensive experiments, including volumetric meshes and Neumann boundary conditions, demonstrate that ASMR exceeds heuristic approaches and learned baselines, matching the performance of expensive error-based oracle AMR strategies.","ASMR additionally generalizes to different domains during inference, and produces meshes that simulate up to 2 orders of magnitude faster than uniform refinements in more demanding settings."],"url":"http://arxiv.org/abs/2406.08440v1"}
{"created":"2024-06-12 17:24:41","title":"Coherent Optical Modems for Full-Wavefield Lidar","abstract":"The advent of the digital age has driven the development of coherent optical modems -- devices that modulate the amplitude and phase of light in multiple polarization states. These modems transmit data through fiber optic cables that are thousands of kilometers in length at data rates exceeding one terabit per second. This remarkable technology is made possible through near-THz-rate programmable control and sensing of the full optical wavefield. While coherent optical modems form the backbone of telecommunications networks around the world, their extraordinary capabilities also provide unique opportunities for imaging. Here, we introduce full-wavefield lidar: a new imaging modality that repurposes off-the-shelf coherent optical modems to simultaneously measure distance, axial velocity, and polarization. We demonstrate this modality by combining a 74 GHz-bandwidth coherent optical modem with free-space coupling optics and scanning mirrors. We develop a time-resolved image formation model for this system and formulate a maximum-likelihood reconstruction algorithm to recover depth, velocity, and polarization information at each scene point from the modem's raw transmitted and received symbols. Compared to existing lidars, full-wavefield lidar promises improved mm-scale ranging accuracy from brief, microsecond exposure times, reliable velocimetry, and robustness to intererence from ambient light or other lidar signals.","sentences":["The advent of the digital age has driven the development of coherent optical modems -- devices that modulate the amplitude and phase of light in multiple polarization states.","These modems transmit data through fiber optic cables that are thousands of kilometers in length at data rates exceeding one terabit per second.","This remarkable technology is made possible through near-THz-rate programmable control and sensing of the full optical wavefield.","While coherent optical modems form the backbone of telecommunications networks around the world, their extraordinary capabilities also provide unique opportunities for imaging.","Here, we introduce full-wavefield lidar: a new imaging modality that repurposes off-the-shelf coherent optical modems to simultaneously measure distance, axial velocity, and polarization.","We demonstrate this modality by combining a 74 GHz-bandwidth coherent optical modem with free-space coupling optics and scanning mirrors.","We develop a time-resolved image formation model for this system and formulate a maximum-likelihood reconstruction algorithm to recover depth, velocity, and polarization information at each scene point from the modem's raw transmitted and received symbols.","Compared to existing lidars, full-wavefield lidar promises improved mm-scale ranging accuracy from brief, microsecond exposure times, reliable velocimetry, and robustness to intererence from ambient light or other lidar signals."],"url":"http://arxiv.org/abs/2406.08439v1"}
{"created":"2024-06-12 17:22:00","title":"Wiki Entity Summarization Benchmark","abstract":"Entity summarization aims to compute concise summaries for entities in knowledge graphs. Existing datasets and benchmarks are often limited to a few hundred entities and discard graph structure in source knowledge graphs. This limitation is particularly pronounced when it comes to ground-truth summaries, where there exist only a few labeled summaries for evaluation and training. We propose WikES, a comprehensive benchmark comprising of entities, their summaries, and their connections. Additionally, WikES features a dataset generator to test entity summarization algorithms in different areas of the knowledge graph. Importantly, our approach combines graph algorithms and NLP models as well as different data sources such that WikES does not require human annotation, rendering the approach cost-effective and generalizable to multiple domains. Finally, WikES is scalable and capable of capturing the complexities of knowledge graphs in terms of topology and semantics. WikES features existing datasets for comparison. Empirical studies of entity summarization methods confirm the usefulness of our benchmark. Data, code, and models are available at: https://github.com/msorkhpar/wiki-entity-summarization.","sentences":["Entity summarization aims to compute concise summaries for entities in knowledge graphs.","Existing datasets and benchmarks are often limited to a few hundred entities and discard graph structure in source knowledge graphs.","This limitation is particularly pronounced when it comes to ground-truth summaries, where there exist only a few labeled summaries for evaluation and training.","We propose WikES, a comprehensive benchmark comprising of entities, their summaries, and their connections.","Additionally, WikES features a dataset generator to test entity summarization algorithms in different areas of the knowledge graph.","Importantly, our approach combines graph algorithms and NLP models as well as different data sources such that WikES does not require human annotation, rendering the approach cost-effective and generalizable to multiple domains.","Finally, WikES is scalable and capable of capturing the complexities of knowledge graphs in terms of topology and semantics.","WikES features existing datasets for comparison.","Empirical studies of entity summarization methods confirm the usefulness of our benchmark.","Data, code, and models are available at: https://github.com/msorkhpar/wiki-entity-summarization."],"url":"http://arxiv.org/abs/2406.08435v1"}
{"created":"2024-06-12 17:21:21","title":"TasTe: Teaching Large Language Models to Translate through Self-Reflection","abstract":"Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks. Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation. However, the existing approaches fail to yield satisfactory translation outputs that match the quality of supervised neural machine translation (NMT) systems. One plausible explanation for this discrepancy is that the straightforward prompts employed in these methodologies are unable to fully exploit the acquired instruction-following capabilities. To this end, we propose the TasTe framework, which stands for translating through self-reflection. The self-reflection process includes two stages of inference. In the first stage, LLMs are instructed to generate preliminary translations and conduct self-assessments on these translations simultaneously. In the second stage, LLMs are tasked to refine these preliminary translations according to the evaluation results. The evaluation results in four language directions on the WMT22 benchmark reveal the effectiveness of our approach compared to existing methods. Our work presents a promising approach to unleash the potential of LLMs and enhance their capabilities in MT. The codes and datasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT.","sentences":["Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks.","Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation.","However, the existing approaches fail to yield satisfactory translation outputs that match the quality of supervised neural machine translation (NMT) systems.","One plausible explanation for this discrepancy is that the straightforward prompts employed in these methodologies are unable to fully exploit the acquired instruction-following capabilities.","To this end, we propose the TasTe framework, which stands for translating through self-reflection.","The self-reflection process includes two stages of inference.","In the first stage, LLMs are instructed to generate preliminary translations and conduct self-assessments on these translations simultaneously.","In the second stage, LLMs are tasked to refine these preliminary translations according to the evaluation results.","The evaluation results in four language directions on the WMT22 benchmark reveal the effectiveness of our approach compared to existing methods.","Our work presents a promising approach to unleash the potential of LLMs and enhance their capabilities in MT.","The codes and datasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT."],"url":"http://arxiv.org/abs/2406.08434v1"}
{"created":"2024-06-12 17:16:16","title":"Diffusion Soup: Model Merging for Text-to-Image Diffusion Models","abstract":"We present Diffusion Soup, a compartmentalization method for Text-to-Image Generation that averages the weights of diffusion models trained on sharded data. By construction, our approach enables training-free continual learning and unlearning with no additional memory or inference costs, since models corresponding to data shards can be added or removed by re-averaging. We show that Diffusion Soup samples from a point in weight space that approximates the geometric mean of the distributions of constituent datasets, which offers anti-memorization guarantees and enables zero-shot style mixing. Empirically, Diffusion Soup outperforms a paragon model trained on the union of all data shards and achieves a 30% improvement in Image Reward (.34 $\\to$ .44) on domain sharded data, and a 59% improvement in IR (.37 $\\to$ .59) on aesthetic data. In both cases, souping also prevails in TIFA score (respectively, 85.5 $\\to$ 86.5 and 85.6 $\\to$ 86.8). We demonstrate robust unlearning -- removing any individual domain shard only lowers performance by 1% in IR (.45 $\\to$ .44) -- and validate our theoretical insights on anti-memorization using real data. Finally, we showcase Diffusion Soup's ability to blend the distinct styles of models finetuned on different shards, resulting in the zero-shot generation of hybrid styles.","sentences":["We present Diffusion Soup, a compartmentalization method for Text-to-Image Generation that averages the weights of diffusion models trained on sharded data.","By construction, our approach enables training-free continual learning and unlearning with no additional memory or inference costs, since models corresponding to data shards can be added or removed by re-averaging.","We show that Diffusion Soup samples from a point in weight space that approximates the geometric mean of the distributions of constituent datasets, which offers anti-memorization guarantees and enables zero-shot style mixing.","Empirically, Diffusion Soup outperforms a paragon model trained on the union of all data shards and achieves a 30% improvement in Image Reward (.34 $\\to$ .44) on domain sharded data, and a 59% improvement in IR (.37 $\\to$ .59) on aesthetic data.","In both cases, souping also prevails in TIFA score (respectively, 85.5 $\\to$ 86.5 and 85.6 $\\to$ 86.8).","We demonstrate robust unlearning -- removing any individual domain shard only lowers performance by 1% in IR (.45 $\\to$ .44) -- and validate our theoretical insights on anti-memorization using real data.","Finally, we showcase Diffusion Soup's ability to blend the distinct styles of models finetuned on different shards, resulting in the zero-shot generation of hybrid styles."],"url":"http://arxiv.org/abs/2406.08431v1"}
{"created":"2024-06-12 17:15:25","title":"A Sticker is Worth a Thousand Words: Characterizing the Use of Stickers in WhatsApp Political Groups in Brazil","abstract":"With the increasing use of smartphones, instant messaging platforms turned into important communication tools. According to WhatsApp, more than 100 billion messages are sent each day on the app. Communication on these platforms has allowed individuals to express themselves in other types of media, rather than simple text, including audio, videos, images, and stickers. Particularly, stickers are a new multimedia format that emerged with messaging apps, promoting new forms of interactions among users, especially in the Brazilian context, transcending their role as a mere form of humor to become a key element in political strategy. In this regard, we investigate how stickers are being used, unveiling unique characteristics that these media bring to WhatsApp chats and the political use of this new media format. To achieve that, we collected a large sample of messages from WhatsApp public political discussion groups in Brazil and analyzed the sticker messages shared in this context","sentences":["With the increasing use of smartphones, instant messaging platforms turned into important communication tools.","According to WhatsApp, more than 100 billion messages are sent each day on the app.","Communication on these platforms has allowed individuals to express themselves in other types of media, rather than simple text, including audio, videos, images, and stickers.","Particularly, stickers are a new multimedia format that emerged with messaging apps, promoting new forms of interactions among users, especially in the Brazilian context, transcending their role as a mere form of humor to become a key element in political strategy.","In this regard, we investigate how stickers are being used, unveiling unique characteristics that these media bring to WhatsApp chats and the political use of this new media format.","To achieve that, we collected a large sample of messages from WhatsApp public political discussion groups in Brazil and analyzed the sticker messages shared in this context"],"url":"http://arxiv.org/abs/2406.08429v1"}
{"created":"2024-06-12 17:14:44","title":"Improving Noise Robustness through Abstractions and its Impact on Machine Learning","abstract":"Noise is a fundamental problem in learning theory with huge effects in the application of Machine Learning (ML) methods, due to real world data tendency to be noisy. Additionally, introduction of malicious noise can make ML methods fail critically, as is the case with adversarial attacks. Thus, finding and developing alternatives to improve robustness to noise is a fundamental problem in ML. In this paper, we propose a method to deal with noise: mitigating its effect through the use of data abstractions. The goal is to reduce the effect of noise over the model's performance through the loss of information produced by the abstraction. However, this information loss comes with a cost: it can result in an accuracy reduction due to the missing information. First, we explored multiple methodologies to create abstractions, using the training dataset, for the specific case of numerical data and binary classification tasks. We also tested how these abstractions can affect robustness to noise with several experiments that explore the robustness of an Artificial Neural Network to noise when trained using raw data \\emph{vs} when trained using abstracted data. The results clearly show that using abstractions is a viable approach for developing noise robust ML methods.","sentences":["Noise is a fundamental problem in learning theory with huge effects in the application of Machine Learning (ML) methods, due to real world data tendency to be noisy.","Additionally, introduction of malicious noise can make ML methods fail critically, as is the case with adversarial attacks.","Thus, finding and developing alternatives to improve robustness to noise is a fundamental problem in ML.","In this paper, we propose a method to deal with noise: mitigating its effect through the use of data abstractions.","The goal is to reduce the effect of noise over the model's performance through the loss of information produced by the abstraction.","However, this information loss comes with a cost: it can result in an accuracy reduction due to the missing information.","First, we explored multiple methodologies to create abstractions, using the training dataset, for the specific case of numerical data and binary classification tasks.","We also tested how these abstractions can affect robustness to noise with several experiments that explore the robustness of an Artificial Neural Network to noise when trained using raw data \\emph{vs} when trained using abstracted data.","The results clearly show that using abstractions is a viable approach for developing noise robust ML methods."],"url":"http://arxiv.org/abs/2406.08428v1"}
{"created":"2024-06-12 17:13:17","title":"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL","abstract":"Generating accurate SQL according to natural language questions (text-to-SQL) is a long-standing problem since it is challenging in user question understanding, database schema comprehension, and SQL generation. Conventional text-to-SQL systems include human engineering and deep neural networks. Subsequently, pre-trained language models (PLMs) have been developed and utilized for text-to-SQL tasks, achieving promising performance. As modern databases become more complex and corresponding user questions more challenging, PLMs with limited comprehension capabilities can lead to incorrect SQL generation. This necessitates more sophisticated and tailored optimization methods, which, in turn, restricts the applications of PLM-based systems. Most recently, large language models (LLMs) have demonstrated significant abilities in natural language understanding as the model scale remains increasing. Therefore, integrating the LLM-based implementation can bring unique opportunities, challenges, and solutions to text-to-SQL research. In this survey, we present a comprehensive review of LLM-based text-to-SQL. Specifically, we propose a brief overview of the current challenges and the evolutionary process of text-to-SQL. Then, we provide a detailed introduction to the datasets and metrics designed to evaluate text-to-SQL systems. After that, we present a systematic analysis of recent advances in LLM-based text-to-SQL. Finally, we discuss the remaining challenges in this field and propose expectations for future directions.","sentences":["Generating accurate SQL according to natural language questions (text-to-SQL) is a long-standing problem since it is challenging in user question understanding, database schema comprehension, and SQL generation.","Conventional text-to-SQL systems include human engineering and deep neural networks.","Subsequently, pre-trained language models (PLMs) have been developed and utilized for text-to-SQL tasks, achieving promising performance.","As modern databases become more complex and corresponding user questions more challenging, PLMs with limited comprehension capabilities can lead to incorrect SQL generation.","This necessitates more sophisticated and tailored optimization methods, which, in turn, restricts the applications of PLM-based systems.","Most recently, large language models (LLMs) have demonstrated significant abilities in natural language understanding as the model scale remains increasing.","Therefore, integrating the LLM-based implementation can bring unique opportunities, challenges, and solutions to text-to-SQL research.","In this survey, we present a comprehensive review of LLM-based text-to-SQL.","Specifically, we propose a brief overview of the current challenges and the evolutionary process of text-to-SQL.","Then, we provide a detailed introduction to the datasets and metrics designed to evaluate text-to-SQL systems.","After that, we present a systematic analysis of recent advances in LLM-based text-to-SQL.","Finally, we discuss the remaining challenges in this field and propose expectations for future directions."],"url":"http://arxiv.org/abs/2406.08426v1"}
{"created":"2024-06-12 17:10:27","title":"AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images","abstract":"Accurate nuclei segmentation in histopathological images is crucial for cancer diagnosis. Automating this process offers valuable support to clinical experts, as manual annotation is time-consuming and prone to human errors. However, automating nuclei segmentation presents challenges due to uncertain cell boundaries, intricate staining, and diverse structures. In this paper, we present a segmentation approach that combines the U-Net architecture with a DenseNet-121 backbone, harnessing the strengths of both to capture comprehensive contextual and spatial information. Our model introduces the Wavelet-guided channel attention module to enhance cell boundary delineation, along with a learnable weighted global attention module for channel-specific attention. The decoder module, composed of an upsample block and convolution block, further refines segmentation in handling staining patterns. The experimental results conducted on two publicly accessible histopathology datasets, namely Monuseg and TNBC, underscore the superiority of our proposed model, demonstrating its potential to advance histopathological image analysis and cancer diagnosis. The code is made available at: https://github.com/AyushRoy2001/AWGUNET.","sentences":["Accurate nuclei segmentation in histopathological images is crucial for cancer diagnosis.","Automating this process offers valuable support to clinical experts, as manual annotation is time-consuming and prone to human errors.","However, automating nuclei segmentation presents challenges due to uncertain cell boundaries, intricate staining, and diverse structures.","In this paper, we present a segmentation approach that combines the U-Net architecture with a DenseNet-121 backbone, harnessing the strengths of both to capture comprehensive contextual and spatial information.","Our model introduces the Wavelet-guided channel attention module to enhance cell boundary delineation, along with a learnable weighted global attention module for channel-specific attention.","The decoder module, composed of an upsample block and convolution block, further refines segmentation in handling staining patterns.","The experimental results conducted on two publicly accessible histopathology datasets, namely Monuseg and TNBC, underscore the superiority of our proposed model, demonstrating its potential to advance histopathological image analysis and cancer diagnosis.","The code is made available at: https://github.com/AyushRoy2001/AWGUNET."],"url":"http://arxiv.org/abs/2406.08425v1"}
{"created":"2024-06-12 17:06:07","title":"State Soup: In-Context Skill Learning, Retrieval and Mixing","abstract":"A new breed of gated-linear recurrent neural networks has reached state-of-the-art performance on a range of sequence modeling problems. Such models naturally handle long sequences efficiently, as the cost of processing a new input is independent of sequence length. Here, we explore another advantage of these stateful sequence models, inspired by the success of model merging through parameter interpolation. Building on parallels between fine-tuning and in-context learning, we investigate whether we can treat internal states as task vectors that can be stored, retrieved, and then linearly combined, exploiting the linearity of recurrence. We study this form of fast model merging on Mamba-2.8b, a pretrained recurrent model, and present preliminary evidence that simple linear state interpolation methods suffice to improve next-token perplexity as well as downstream in-context learning task performance.","sentences":["A new breed of gated-linear recurrent neural networks has reached state-of-the-art performance on a range of sequence modeling problems.","Such models naturally handle long sequences efficiently, as the cost of processing a new input is independent of sequence length.","Here, we explore another advantage of these stateful sequence models, inspired by the success of model merging through parameter interpolation.","Building on parallels between fine-tuning and in-context learning, we investigate whether we can treat internal states as task vectors that can be stored, retrieved, and then linearly combined, exploiting the linearity of recurrence.","We study this form of fast model merging on Mamba-2.8b, a pretrained recurrent model, and present preliminary evidence that simple linear state interpolation methods suffice to improve next-token perplexity as well as downstream in-context learning task performance."],"url":"http://arxiv.org/abs/2406.08423v1"}
{"created":"2024-06-12 17:05:08","title":"PRIBOOT: A New Data-Driven Expert for Improved Driving Simulations","abstract":"The development of Autonomous Driving (AD) systems in simulated environments like CARLA is crucial for advancing real-world automotive technologies. To drive innovation, CARLA introduced Leaderboard 2.0, significantly more challenging than its predecessor. However, current AD methods have struggled to achieve satisfactory outcomes due to a lack of sufficient ground truth data. Human driving logs provided by CARLA are insufficient, and previously successful expert agents like Autopilot and Roach, used for collecting datasets, have seen reduced effectiveness under these more demanding conditions. To overcome these data limitations, we introduce PRIBOOT, an expert agent that leverages limited human logs with privileged information. We have developed a novel BEV representation specifically tailored to meet the demands of this new benchmark and processed it as an RGB image to facilitate the application of transfer learning techniques, instead of using a set of masks. Additionally, we propose the Infraction Rate Score (IRS), a new evaluation metric designed to provide a more balanced assessment of driving performance over extended routes. PRIBOOT is the first model to achieve a Route Completion (RC) of 75% in Leaderboard 2.0, along with a Driving Score (DS) and IRS of 20% and 45%, respectively. With PRIBOOT, researchers can now generate extensive datasets, potentially solving the data availability issues that have hindered progress in this benchmark.","sentences":["The development of Autonomous Driving (AD) systems in simulated environments like CARLA is crucial for advancing real-world automotive technologies.","To drive innovation, CARLA introduced Leaderboard 2.0, significantly more challenging than its predecessor.","However, current AD methods have struggled to achieve satisfactory outcomes due to a lack of sufficient ground truth data.","Human driving logs provided by CARLA are insufficient, and previously successful expert agents like Autopilot and Roach, used for collecting datasets, have seen reduced effectiveness under these more demanding conditions.","To overcome these data limitations, we introduce PRIBOOT, an expert agent that leverages limited human logs with privileged information.","We have developed a novel BEV representation specifically tailored to meet the demands of this new benchmark and processed it as an RGB image to facilitate the application of transfer learning techniques, instead of using a set of masks.","Additionally, we propose the Infraction Rate Score (IRS), a new evaluation metric designed to provide a more balanced assessment of driving performance over extended routes.","PRIBOOT is the first model to achieve a Route Completion (RC) of 75% in Leaderboard 2.0, along with a Driving Score (DS) and IRS of 20% and 45%, respectively.","With PRIBOOT, researchers can now generate extensive datasets, potentially solving the data availability issues that have hindered progress in this benchmark."],"url":"http://arxiv.org/abs/2406.08421v1"}
{"created":"2024-06-12 17:04:36","title":"Designing Child-Centered Content Exposure and Moderation","abstract":"Research on children's online experience and computer interaction often overlooks the relationship children have with hidden algorithms that control the content they encounter. Furthermore, it is not only about how children interact with targeted content but also how their development and agency are largely affected by these. By engaging with the body of literature at the intersection of i) human-centered design approaches, ii) exclusion and discrimination in A.I., iii) privacy, transparency, and accountability, and iv) children's online citizenship, this article dives into the question of \"How can we approach the design of a child-centered moderation process to (1) include aspects that families value for their children and (2) provide explanations for content appropriateness and removal so that we can scale (according to systems and human needs) the moderation process assisted by A.I.?\".   This article contributes a sociotechnical highlight of core challenges and opportunities of designing child-centered content control tools. The article concludes by grounding and characterizing design considerations for a child-centered, family-guided moderation system. We hope this work serves as a stepping stone for designers and researchers pursuing children's safety online with an eye on hidden agents controlling children's online experiences and, by extension, the values and opportunities children are exposed to.","sentences":["Research on children's online experience and computer interaction often overlooks the relationship children have with hidden algorithms that control the content they encounter.","Furthermore, it is not only about how children interact with targeted content but also how their development and agency are largely affected by these.","By engaging with the body of literature at the intersection of i) human-centered design approaches, ii) exclusion and discrimination in A.I., iii) privacy, transparency, and accountability, and iv) children's online citizenship, this article dives into the question of \"How can we approach the design of a child-centered moderation process to (1) include aspects that families value for their children and (2) provide explanations for content appropriateness and removal so that we can scale (according to systems and human needs)","the moderation process assisted by A.I.?\".   ","This article contributes a sociotechnical highlight of core challenges and opportunities of designing child-centered content control tools.","The article concludes by grounding and characterizing design considerations for a child-centered, family-guided moderation system.","We hope this work serves as a stepping stone for designers and researchers pursuing children's safety online with an eye on hidden agents controlling children's online experiences and, by extension, the values and opportunities children are exposed to."],"url":"http://arxiv.org/abs/2406.08420v1"}
{"created":"2024-06-12 17:01:04","title":"OmniCorpus: An Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text","abstract":"Image-text interleaved data, consisting of multiple images and texts arranged in a natural document format, aligns with the presentation paradigm of internet data and closely resembles human reading habits. Recent studies have shown that such data aids multimodal in-context learning and maintains the capabilities of large language models during multimodal fine-tuning. However, the limited scale and diversity of current image-text interleaved data restrict the development of multimodal large language models. In this paper, we introduce OmniCorpus, a 10 billion-scale image-text interleaved dataset. Using an efficient data engine, we filter and extract large-scale high-quality documents, which contain 8.6 billion images and 1,696 billion text tokens. Compared to counterparts (e.g., MMC4, OBELICS), our dataset 1) has 15 times larger scales while maintaining good data quality; 2) features more diverse sources, including both English and non-English websites as well as video-centric websites; 3) is more flexible, easily degradable from an image-text interleaved format to pure text corpus and image-text pairs. Through comprehensive analysis and experiments, we validate the quality, usability, and effectiveness of the proposed dataset. We hope this could provide a solid data foundation for future multimodal model research. Code and data are released at https://github.com/OpenGVLab/OmniCorpus.","sentences":["Image-text interleaved data, consisting of multiple images and texts arranged in a natural document format, aligns with the presentation paradigm of internet data and closely resembles human reading habits.","Recent studies have shown that such data aids multimodal in-context learning and maintains the capabilities of large language models during multimodal fine-tuning.","However, the limited scale and diversity of current image-text interleaved data restrict the development of multimodal large language models.","In this paper, we introduce OmniCorpus, a 10 billion-scale image-text interleaved dataset.","Using an efficient data engine, we filter and extract large-scale high-quality documents, which contain 8.6 billion images and 1,696 billion text tokens.","Compared to counterparts (e.g., MMC4, OBELICS), our dataset 1) has 15 times larger scales while maintaining good data quality; 2) features more diverse sources, including both English and non-English websites as well as video-centric websites; 3) is more flexible, easily degradable from an image-text interleaved format to pure text corpus and image-text pairs.","Through comprehensive analysis and experiments, we validate the quality, usability, and effectiveness of the proposed dataset.","We hope this could provide a solid data foundation for future multimodal model research.","Code and data are released at https://github.com/OpenGVLab/OmniCorpus."],"url":"http://arxiv.org/abs/2406.08418v1"}
{"created":"2024-06-12 16:59:24","title":"TokSing: Singing Voice Synthesis based on Discrete Tokens","abstract":"Recent advancements in speech synthesis witness significant benefits by leveraging discrete tokens extracted from self-supervised learning (SSL) models. Discrete tokens offer higher storage efficiency and greater operability in intermediate representations compared to traditional continuous Mel spectrograms. However, when it comes to singing voice synthesis(SVS), achieving higher levels of melody expression poses a great challenge for utilizing discrete tokens. In this paper, we introduce TokSing, a discrete-based SVS system equipped with a token formulator that offers flexible token blendings. We observe a melody degradation during discretization, prompting us to integrate a melody signal with the discrete token and incorporate a specially-designed melody enhancement strategy in the musical encoder. Extensive experiments demonstrate that our TokSing achieves better performance against the Mel spectrogram baselines while offering advantages in intermediate representation space cost and convergence speed.","sentences":["Recent advancements in speech synthesis witness significant benefits by leveraging discrete tokens extracted from self-supervised learning (SSL) models.","Discrete tokens offer higher storage efficiency and greater operability in intermediate representations compared to traditional continuous Mel spectrograms.","However, when it comes to singing voice synthesis(SVS), achieving higher levels of melody expression poses a great challenge for utilizing discrete tokens.","In this paper, we introduce TokSing, a discrete-based SVS system equipped with a token formulator that offers flexible token blendings.","We observe a melody degradation during discretization, prompting us to integrate a melody signal with the discrete token and incorporate a specially-designed melody enhancement strategy in the musical encoder.","Extensive experiments demonstrate that our TokSing achieves better performance against the Mel spectrogram baselines while offering advantages in intermediate representation space cost and convergence speed."],"url":"http://arxiv.org/abs/2406.08416v1"}
{"created":"2024-06-12 16:58:41","title":"Discovering Preference Optimization Algorithms with and for Large Language Models","abstract":"Offline preference optimization is a key method for enhancing and controlling the quality of Large Language Model (LLM) outputs. Typically, preference optimization is approached as an offline supervised learning task using manually-crafted convex loss functions. While these methods are based on theoretical insights, they are inherently constrained by human creativity, so the large search space of possible loss functions remains under explored. We address this by performing LLM-driven objective discovery to automatically discover new state-of-the-art preference optimization algorithms without (expert) human intervention. Specifically, we iteratively prompt an LLM to propose and implement new preference optimization loss functions based on previously-evaluated performance metrics. This process leads to the discovery of previously-unknown and performant preference optimization algorithms. The best performing of these we call Discovered Preference Optimization (DiscoPOP), a novel algorithm that adaptively blends logistic and exponential losses. Experiments demonstrate the state-of-the-art performance of DiscoPOP and its successful transfer to held-out tasks.","sentences":["Offline preference optimization is a key method for enhancing and controlling the quality of Large Language Model (LLM) outputs.","Typically, preference optimization is approached as an offline supervised learning task using manually-crafted convex loss functions.","While these methods are based on theoretical insights, they are inherently constrained by human creativity, so the large search space of possible loss functions remains under explored.","We address this by performing LLM-driven objective discovery to automatically discover new state-of-the-art preference optimization algorithms without (expert) human intervention.","Specifically, we iteratively prompt an LLM to propose and implement new preference optimization loss functions based on previously-evaluated performance metrics.","This process leads to the discovery of previously-unknown and performant preference optimization algorithms.","The best performing of these we call Discovered Preference Optimization (DiscoPOP), a novel algorithm that adaptively blends logistic and exponential losses.","Experiments demonstrate the state-of-the-art performance of DiscoPOP and its successful transfer to held-out tasks."],"url":"http://arxiv.org/abs/2406.08414v1"}
{"created":"2024-06-12 16:57:58","title":"Memory Is All You Need: An Overview of Compute-in-Memory Architectures for Accelerating Large Language Model Inference","abstract":"Large language models (LLMs) have recently transformed natural language processing, enabling machines to generate human-like text and engage in meaningful conversations. This development necessitates speed, efficiency, and accessibility in LLM inference as the computational and memory requirements of these systems grow exponentially. Meanwhile, advancements in computing and memory capabilities are lagging behind, exacerbated by the discontinuation of Moore's law. With LLMs exceeding the capacity of single GPUs, they require complex, expert-level configurations for parallel processing. Memory accesses become significantly more expensive than computation, posing a challenge for efficient scaling, known as the memory wall. Here, compute-in-memory (CIM) technologies offer a promising solution for accelerating AI inference by directly performing analog computations in memory, potentially reducing latency and power consumption. By closely integrating memory and compute elements, CIM eliminates the von Neumann bottleneck, reducing data movement and improving energy efficiency. This survey paper provides an overview and analysis of transformer-based models, reviewing various CIM architectures and exploring how they can address the imminent challenges of modern AI computing systems. We discuss transformer-related operators and their hardware acceleration schemes and highlight challenges, trends, and insights in corresponding CIM designs.","sentences":["Large language models (LLMs) have recently transformed natural language processing, enabling machines to generate human-like text and engage in meaningful conversations.","This development necessitates speed, efficiency, and accessibility in LLM inference as the computational and memory requirements of these systems grow exponentially.","Meanwhile, advancements in computing and memory capabilities are lagging behind, exacerbated by the discontinuation of Moore's law.","With LLMs exceeding the capacity of single GPUs, they require complex, expert-level configurations for parallel processing.","Memory accesses become significantly more expensive than computation, posing a challenge for efficient scaling, known as the memory wall.","Here, compute-in-memory (CIM) technologies offer a promising solution for accelerating AI inference by directly performing analog computations in memory, potentially reducing latency and power consumption.","By closely integrating memory and compute elements, CIM eliminates the von Neumann bottleneck, reducing data movement and improving energy efficiency.","This survey paper provides an overview and analysis of transformer-based models, reviewing various CIM architectures and exploring how they can address the imminent challenges of modern AI computing systems.","We discuss transformer-related operators and their hardware acceleration schemes and highlight challenges, trends, and insights in corresponding CIM designs."],"url":"http://arxiv.org/abs/2406.08413v1"}
{"created":"2024-06-12 16:57:28","title":"Tailoring Generative AI Chatbots for Multiethnic Communities in Disaster Preparedness Communication: Extending the CASA Paradigm","abstract":"This study is among the first to develop different prototypes of generative AI (GenAI) chatbots powered by GPT 4 to communicate hurricane preparedness information to diverse residents. Drawing from the Computers Are Social Actors (CASA) paradigm and the literature on disaster vulnerability and cultural tailoring, this study conducted a between-subjects experiment with 441 Black, Hispanic, and Caucasian residents of Florida. A computational analysis of chat logs (N = 7,848) shows that anthropomorphism and personalization are key communication topics in GenAI chatbot-user interactions. SEM results (N = 441) suggest that GenAI chatbots varying in tone formality and cultural tailoring significantly predict bot perceptions and, subsequently, hurricane preparedness outcomes. These results highlight the potential of using GenAI chatbots to improve diverse communities' disaster preparedness.","sentences":["This study is among the first to develop different prototypes of generative AI (GenAI) chatbots powered by GPT 4 to communicate hurricane preparedness information to diverse residents.","Drawing from the Computers Are Social Actors (CASA) paradigm and the literature on disaster vulnerability and cultural tailoring, this study conducted a between-subjects experiment with 441 Black, Hispanic, and Caucasian residents of Florida.","A computational analysis of chat logs (N = 7,848) shows that anthropomorphism and personalization are key communication topics in GenAI chatbot-user interactions.","SEM results (N = 441) suggest that GenAI chatbots varying in tone formality and cultural tailoring significantly predict bot perceptions and, subsequently, hurricane preparedness outcomes.","These results highlight the potential of using GenAI chatbots to improve diverse communities' disaster preparedness."],"url":"http://arxiv.org/abs/2406.08411v1"}
{"created":"2024-06-12 16:54:54","title":"MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos","abstract":"Multimodal Language Language Models (MLLMs) demonstrate the emerging abilities of \"world models\" -- interpreting and reasoning about complex real-world dynamics. To assess these abilities, we posit videos are the ideal medium, as they encapsulate rich representations of real-world dynamics and causalities. To this end, we introduce MMWorld, a new benchmark for multi-discipline, multi-faceted multimodal video understanding. MMWorld distinguishes itself from previous video understanding benchmarks with two unique advantages: (1) multi-discipline, covering various disciplines that often require domain expertise for comprehensive understanding; (2) multi-faceted reasoning, including explanation, counterfactual thinking, future prediction, etc. MMWorld consists of a human-annotated dataset to evaluate MLLMs with questions about the whole videos and a synthetic dataset to analyze MLLMs within a single modality of perception. Together, MMWorld encompasses 1,910 videos across seven broad disciplines and 69 subdisciplines, complete with 6,627 question-answer pairs and associated captions. The evaluation includes 2 proprietary and 10 open-source MLLMs, which struggle on MMWorld (e.g., GPT-4V performs the best with only 52.3\\% accuracy), showing large room for improvement. Further ablation studies reveal other interesting findings such as models' different skill sets from humans. We hope MMWorld can serve as an essential step towards world model evaluation in videos.","sentences":["Multimodal Language Language Models (MLLMs) demonstrate the emerging abilities of \"world models\" -- interpreting and reasoning about complex real-world dynamics.","To assess these abilities, we posit videos are the ideal medium, as they encapsulate rich representations of real-world dynamics and causalities.","To this end, we introduce MMWorld, a new benchmark for multi-discipline, multi-faceted multimodal video understanding.","MMWorld distinguishes itself from previous video understanding benchmarks with two unique advantages: (1) multi-discipline, covering various disciplines that often require domain expertise for comprehensive understanding; (2) multi-faceted reasoning, including explanation, counterfactual thinking, future prediction, etc.","MMWorld consists of a human-annotated dataset to evaluate MLLMs with questions about the whole videos and a synthetic dataset to analyze MLLMs within a single modality of perception.","Together, MMWorld encompasses 1,910 videos across seven broad disciplines and 69 subdisciplines, complete with 6,627 question-answer pairs and associated captions.","The evaluation includes 2 proprietary and 10 open-source MLLMs, which struggle on MMWorld (e.g., GPT-4V performs the best with only 52.3\\% accuracy), showing large room for improvement.","Further ablation studies reveal other interesting findings such as models' different skill sets from humans.","We hope MMWorld can serve as an essential step towards world model evaluation in videos."],"url":"http://arxiv.org/abs/2406.08407v1"}
{"created":"2024-06-12 16:53:51","title":"RRLS : Robust Reinforcement Learning Suite","abstract":"Robust reinforcement learning is the problem of learning control policies that provide optimal worst-case performance against a span of adversarial environments. It is a crucial ingredient for deploying algorithms in real-world scenarios with prevalent environmental uncertainties and has been a long-standing object of attention in the community, without a standardized set of benchmarks. This contribution endeavors to fill this gap. We introduce the Robust Reinforcement Learning Suite (RRLS), a benchmark suite based on Mujoco environments. RRLS provides six continuous control tasks with two types of uncertainty sets for training and evaluation. Our benchmark aims to standardize robust reinforcement learning tasks, facilitating reproducible and comparable experiments, in particular those from recent state-of-the-art contributions, for which we demonstrate the use of RRLS. It is also designed to be easily expandable to new environments. The source code is available at \\href{https://github.com/SuReLI/RRLS}{https://github.com/SuReLI/RRLS}.","sentences":["Robust reinforcement learning is the problem of learning control policies that provide optimal worst-case performance against a span of adversarial environments.","It is a crucial ingredient for deploying algorithms in real-world scenarios with prevalent environmental uncertainties and has been a long-standing object of attention in the community, without a standardized set of benchmarks.","This contribution endeavors to fill this gap.","We introduce the Robust Reinforcement Learning Suite (RRLS), a benchmark suite based on Mujoco environments.","RRLS provides six continuous control tasks with two types of uncertainty sets for training and evaluation.","Our benchmark aims to standardize robust reinforcement learning tasks, facilitating reproducible and comparable experiments, in particular those from recent state-of-the-art contributions, for which we demonstrate the use of RRLS.","It is also designed to be easily expandable to new environments.","The source code is available at \\href{https://github.com/SuReLI/RRLS}{https://github.com/SuReLI/RRLS}."],"url":"http://arxiv.org/abs/2406.08406v1"}
{"created":"2024-06-12 16:52:54","title":"Scaling Value Iteration Networks to 5000 Layers for Extreme Long-Term Planning","abstract":"The Value Iteration Network (VIN) is an end-to-end differentiable architecture that performs value iteration on a latent MDP for planning in reinforcement learning (RL). However, VINs struggle to scale to long-term and large-scale planning tasks, such as navigating a $100\\times 100$ maze -- a task which typically requires thousands of planning steps to solve. We observe that this deficiency is due to two issues: the representation capacity of the latent MDP and the planning module's depth. We address these by augmenting the latent MDP with a dynamic transition kernel, dramatically improving its representational capacity, and, to mitigate the vanishing gradient problem, introducing an \"adaptive highway loss\" that constructs skip connections to improve gradient flow. We evaluate our method on both 2D maze navigation environments and the ViZDoom 3D navigation benchmark. We find that our new method, named Dynamic Transition VIN (DT-VIN), easily scales to 5000 layers and casually solves challenging versions of the above tasks. Altogether, we believe that DT-VIN represents a concrete step forward in performing long-term large-scale planning in RL environments.","sentences":["The Value Iteration Network (VIN) is an end-to-end differentiable architecture that performs value iteration on a latent MDP for planning in reinforcement learning (RL).","However, VINs struggle to scale to long-term and large-scale planning tasks, such as navigating a $100\\times 100$ maze -- a task which typically requires thousands of planning steps to solve.","We observe that this deficiency is due to two issues: the representation capacity of the latent MDP and the planning module's depth.","We address these by augmenting the latent MDP with a dynamic transition kernel, dramatically improving its representational capacity, and, to mitigate the vanishing gradient problem, introducing an \"adaptive highway loss\" that constructs skip connections to improve gradient flow.","We evaluate our method on both 2D maze navigation environments and the ViZDoom 3D navigation benchmark.","We find that our new method, named Dynamic Transition VIN (DT-VIN), easily scales to 5000 layers and casually solves challenging versions of the above tasks.","Altogether, we believe that DT-VIN represents a concrete step forward in performing long-term large-scale planning in RL environments."],"url":"http://arxiv.org/abs/2406.08404v1"}
{"created":"2024-06-12 16:46:12","title":"cPAPERS: A Dataset of Situated and Multimodal Interactive Conversations in Scientific Papers","abstract":"An emerging area of research in situated and multimodal interactive conversations (SIMMC) includes interactions in scientific papers. Since scientific papers are primarily composed of text, equations, figures, and tables, SIMMC methods must be developed specifically for each component to support the depth of inquiry and interactions required by research scientists. This work introduces Conversational Papers (cPAPERS), a dataset of conversational question-answer pairs from reviews of academic papers grounded in these paper components and their associated references from scientific documents available on arXiv. We present a data collection strategy to collect these question-answer pairs from OpenReview and associate them with contextual information from LaTeX source files. Additionally, we present a series of baseline approaches utilizing Large Language Models (LLMs) in both zero-shot and fine-tuned configurations to address the cPAPERS dataset.","sentences":["An emerging area of research in situated and multimodal interactive conversations (SIMMC) includes interactions in scientific papers.","Since scientific papers are primarily composed of text, equations, figures, and tables, SIMMC methods must be developed specifically for each component to support the depth of inquiry and interactions required by research scientists.","This work introduces Conversational Papers (cPAPERS), a dataset of conversational question-answer pairs from reviews of academic papers grounded in these paper components and their associated references from scientific documents available on arXiv.","We present a data collection strategy to collect these question-answer pairs from OpenReview and associate them with contextual information from LaTeX source files.","Additionally, we present a series of baseline approaches utilizing Large Language Models (LLMs) in both zero-shot and fine-tuned configurations to address the cPAPERS dataset."],"url":"http://arxiv.org/abs/2406.08398v1"}
{"created":"2024-06-12 16:45:09","title":"Time-Constrained Robust MDPs","abstract":"Robust reinforcement learning is essential for deploying reinforcement learning algorithms in real-world scenarios where environmental uncertainty predominates. Traditional robust reinforcement learning often depends on rectangularity assumptions, where adverse probability measures of outcome states are assumed to be independent across different states and actions. This assumption, rarely fulfilled in practice, leads to overly conservative policies. To address this problem, we introduce a new time-constrained robust MDP (TC-RMDP) formulation that considers multifactorial, correlated, and time-dependent disturbances, thus more accurately reflecting real-world dynamics. This formulation goes beyond the conventional rectangularity paradigm, offering new perspectives and expanding the analytical framework for robust RL. We propose three distinct algorithms, each using varying levels of environmental information, and evaluate them extensively on continuous control benchmarks. Our results demonstrate that these algorithms yield an efficient tradeoff between performance and robustness, outperforming traditional deep robust RL methods in time-constrained environments while preserving robustness in classical benchmarks. This study revisits the prevailing assumptions in robust RL and opens new avenues for developing more practical and realistic RL applications.","sentences":["Robust reinforcement learning is essential for deploying reinforcement learning algorithms in real-world scenarios where environmental uncertainty predominates.","Traditional robust reinforcement learning often depends on rectangularity assumptions, where adverse probability measures of outcome states are assumed to be independent across different states and actions.","This assumption, rarely fulfilled in practice, leads to overly conservative policies.","To address this problem, we introduce a new time-constrained robust MDP (TC-RMDP) formulation that considers multifactorial, correlated, and time-dependent disturbances, thus more accurately reflecting real-world dynamics.","This formulation goes beyond the conventional rectangularity paradigm, offering new perspectives and expanding the analytical framework for robust RL.","We propose three distinct algorithms, each using varying levels of environmental information, and evaluate them extensively on continuous control benchmarks.","Our results demonstrate that these algorithms yield an efficient tradeoff between performance and robustness, outperforming traditional deep robust RL methods in time-constrained environments while preserving robustness in classical benchmarks.","This study revisits the prevailing assumptions in robust RL and opens new avenues for developing more practical and realistic RL applications."],"url":"http://arxiv.org/abs/2406.08395v1"}
{"created":"2024-06-12 16:44:50","title":"VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks","abstract":"We present VisionLLM v2, an end-to-end generalist multimodal large model (MLLM) that unifies visual perception, understanding, and generation within a single framework. Unlike traditional MLLMs limited to text output, VisionLLM v2 significantly broadens its application scope. It excels not only in conventional visual question answering (VQA) but also in open-ended, cross-domain vision tasks such as object localization, pose estimation, and image generation and editing. To this end, we propose a new information transmission mechanism termed \"super link\", as a medium to connect MLLM with task-specific decoders. It not only allows flexible transmission of task information and gradient feedback between the MLLM and multiple downstream decoders but also effectively resolves training conflicts in multi-tasking scenarios. In addition, to support the diverse range of tasks, we carefully collected and combed training data from hundreds of public vision and vision-language tasks. In this way, our model can be joint-trained end-to-end on hundreds of vision language tasks and generalize to these tasks using a set of shared parameters through different user prompts, achieving performance comparable to task-specific models. We believe VisionLLM v2 will offer a new perspective on the generalization of MLLMs.","sentences":["We present VisionLLM v2, an end-to-end generalist multimodal large model (MLLM) that unifies visual perception, understanding, and generation within a single framework.","Unlike traditional MLLMs limited to text output, VisionLLM v2 significantly broadens its application scope.","It excels not only in conventional visual question answering (VQA) but also in open-ended, cross-domain vision tasks such as object localization, pose estimation, and image generation and editing.","To this end, we propose a new information transmission mechanism termed \"super link\", as a medium to connect MLLM with task-specific decoders.","It not only allows flexible transmission of task information and gradient feedback between the MLLM and multiple downstream decoders but also effectively resolves training conflicts in multi-tasking scenarios.","In addition, to support the diverse range of tasks, we carefully collected and combed training data from hundreds of public vision and vision-language tasks.","In this way, our model can be joint-trained end-to-end on hundreds of vision language tasks and generalize to these tasks using a set of shared parameters through different user prompts, achieving performance comparable to task-specific models.","We believe VisionLLM v2 will offer a new perspective on the generalization of MLLMs."],"url":"http://arxiv.org/abs/2406.08394v1"}
{"created":"2024-06-12 16:43:47","title":"FontStudio: Shape-Adaptive Diffusion Model for Coherent and Consistent Font Effect Generation","abstract":"Recently, the application of modern diffusion-based text-to-image generation models for creating artistic fonts, traditionally the domain of professional designers, has garnered significant interest. Diverging from the majority of existing studies that concentrate on generating artistic typography, our research aims to tackle a novel and more demanding challenge: the generation of text effects for multilingual fonts. This task essentially requires generating coherent and consistent visual content within the confines of a font-shaped canvas, as opposed to a traditional rectangular canvas. To address this task, we introduce a novel shape-adaptive diffusion model capable of interpreting the given shape and strategically planning pixel distributions within the irregular canvas. To achieve this, we curate a high-quality shape-adaptive image-text dataset and incorporate the segmentation mask as a visual condition to steer the image generation process within the irregular-canvas. This approach enables the traditionally rectangle canvas-based diffusion model to produce the desired concepts in accordance with the provided geometric shapes. Second, to maintain consistency across multiple letters, we also present a training-free, shape-adaptive effect transfer method for transferring textures from a generated reference letter to others. The key insights are building a font effect noise prior and propagating the font effect information in a concatenated latent space. The efficacy of our FontStudio system is confirmed through user preference studies, which show a marked preference (78% win-rates on aesthetics) for our system even when compared to the latest unrivaled commercial product, Adobe Firefly.","sentences":["Recently, the application of modern diffusion-based text-to-image generation models for creating artistic fonts, traditionally the domain of professional designers, has garnered significant interest.","Diverging from the majority of existing studies that concentrate on generating artistic typography, our research aims to tackle a novel and more demanding challenge: the generation of text effects for multilingual fonts.","This task essentially requires generating coherent and consistent visual content within the confines of a font-shaped canvas, as opposed to a traditional rectangular canvas.","To address this task, we introduce a novel shape-adaptive diffusion model capable of interpreting the given shape and strategically planning pixel distributions within the irregular canvas.","To achieve this, we curate a high-quality shape-adaptive image-text dataset and incorporate the segmentation mask as a visual condition to steer the image generation process within the irregular-canvas.","This approach enables the traditionally rectangle canvas-based diffusion model to produce the desired concepts in accordance with the provided geometric shapes.","Second, to maintain consistency across multiple letters, we also present a training-free, shape-adaptive effect transfer method for transferring textures from a generated reference letter to others.","The key insights are building a font effect noise prior and propagating the font effect information in a concatenated latent space.","The efficacy of our FontStudio system is confirmed through user preference studies, which show a marked preference (78% win-rates on aesthetics) for our system even when compared to the latest unrivaled commercial product, Adobe Firefly."],"url":"http://arxiv.org/abs/2406.08392v1"}
{"created":"2024-06-12 16:41:31","title":"Large Language Models Must Be Taught to Know What They Don't Know","abstract":"When using large language models (LLMs) in high-stakes applications, we need to know when we can trust their predictions. Some works argue that prompting high-performance LLMs is sufficient to produce calibrated uncertainties, while others introduce sampling methods that can be prohibitively expensive. In this work, we first argue that prompting on its own is insufficient to achieve good calibration and then show that fine-tuning on a small dataset of correct and incorrect answers can create an uncertainty estimate with good generalization and small computational overhead. We show that a thousand graded examples are sufficient to outperform baseline methods and that training through the features of a model is necessary for good performance and tractable for large open-source models when using LoRA. We also investigate the mechanisms that enable reliable LLM uncertainty estimation, finding that many models can be used as general-purpose uncertainty estimators, applicable not just to their own uncertainties but also the uncertainty of other models. Lastly, we show that uncertainty estimates inform human use of LLMs in human-AI collaborative settings through a user study.","sentences":["When using large language models (LLMs) in high-stakes applications, we need to know when we can trust their predictions.","Some works argue that prompting high-performance LLMs is sufficient to produce calibrated uncertainties, while others introduce sampling methods that can be prohibitively expensive.","In this work, we first argue that prompting on its own is insufficient to achieve good calibration and then show that fine-tuning on a small dataset of correct and incorrect answers can create an uncertainty estimate with good generalization and small computational overhead.","We show that a thousand graded examples are sufficient to outperform baseline methods and that training through the features of a model is necessary for good performance and tractable for large open-source models when using LoRA.","We also investigate the mechanisms that enable reliable LLM uncertainty estimation, finding that many models can be used as general-purpose uncertainty estimators, applicable not just to their own uncertainties but also the uncertainty of other models.","Lastly, we show that uncertainty estimates inform human use of LLMs in human-AI collaborative settings through a user study."],"url":"http://arxiv.org/abs/2406.08391v1"}
{"created":"2024-06-12 16:36:06","title":"Banal Deception Human-AI Ecosystems: A Study of People's Perceptions of LLM-generated Deceptive Behaviour","abstract":"Large language models (LLMs) can provide users with false, inaccurate, or misleading information, and we consider the output of this type of information as what Natale (2021) calls `banal' deceptive behaviour. Here, we investigate peoples' perceptions of ChatGPT-generated deceptive behaviour and how this affects peoples' own behaviour and trust. To do this, we use a mixed-methods approach comprising of (i) an online survey with 220 participants and (ii) semi-structured interviews with 12 participants. Our results show that (i) the most common types of deceptive information encountered were over-simplifications and outdated information; (ii) humans' perceptions of trust and `worthiness' of talking to ChatGPT are impacted by `banal' deceptive behaviour; (iii) the perceived responsibility for deception is influenced by education level and the frequency of deceptive information; and (iv) users become more cautious after encountering deceptive information, but they come to trust the technology more when they identify advantages of using it. Our findings contribute to the understanding of human-AI interaction dynamics in the context of \\textit{Deceptive AI Ecosystems}, and highlight the importance of user-centric approaches to mitigating the potential harms of deceptive AI technologies.","sentences":["Large language models (LLMs) can provide users with false, inaccurate, or misleading information, and we consider the output of this type of information as what Natale (2021) calls `banal' deceptive behaviour.","Here, we investigate peoples' perceptions of ChatGPT-generated deceptive behaviour and how this affects peoples' own behaviour and trust.","To do this, we use a mixed-methods approach comprising of (i) an online survey with 220 participants and (ii) semi-structured interviews with 12 participants.","Our results show that (i) the most common types of deceptive information encountered were over-simplifications and outdated information; (ii) humans' perceptions of trust and `worthiness' of talking to ChatGPT are impacted by `banal' deceptive behaviour; (iii) the perceived responsibility for deception is influenced by education level and the frequency of deceptive information; and (iv) users become more cautious after encountering deceptive information, but they come to trust the technology more when they identify advantages of using it.","Our findings contribute to the understanding of human-AI interaction dynamics in the context of \\textit{Deceptive AI Ecosystems}, and highlight the importance of user-centric approaches to mitigating the potential harms of deceptive AI technologies."],"url":"http://arxiv.org/abs/2406.08386v1"}
{"created":"2024-06-12 16:34:26","title":"Diff-A-Riff: Musical Accompaniment Co-creation via Latent Diffusion Models","abstract":"Recent advancements in deep generative models present new opportunities for music production but also pose challenges, such as high computational demands and limited audio quality. Moreover, current systems frequently rely solely on text input and typically focus on producing complete musical pieces, which is incompatible with existing workflows in music production. To address these issues, we introduce \"Diff-A-Riff,\" a Latent Diffusion Model designed to generate high-quality instrumental accompaniments adaptable to any musical context. This model offers control through either audio references, text prompts, or both, and produces 48kHz pseudo-stereo audio while significantly reducing inference time and memory usage. We demonstrate the model's capabilities through objective metrics and subjective listening tests, with extensive examples available on the accompanying website: sonycslparis.github.io/diffariff-companion/","sentences":["Recent advancements in deep generative models present new opportunities for music production but also pose challenges, such as high computational demands and limited audio quality.","Moreover, current systems frequently rely solely on text input and typically focus on producing complete musical pieces, which is incompatible with existing workflows in music production.","To address these issues, we introduce \"Diff-A-Riff,\" a Latent Diffusion Model designed to generate high-quality instrumental accompaniments adaptable to any musical context.","This model offers control through either audio references, text prompts, or both, and produces 48kHz pseudo-stereo audio while significantly reducing inference time and memory usage.","We demonstrate the model's capabilities through objective metrics and subjective listening tests, with extensive examples available on the accompanying website: sonycslparis.github.io/diffariff-companion/"],"url":"http://arxiv.org/abs/2406.08384v1"}
{"created":"2024-06-12 16:31:06","title":"LaneCPP: Continuous 3D Lane Detection using Physical Priors","abstract":"Monocular 3D lane detection has become a fundamental problem in the context of autonomous driving, which comprises the tasks of finding the road surface and locating lane markings. One major challenge lies in a flexible but robust line representation capable of modeling complex lane structures, while still avoiding unpredictable behavior. While previous methods rely on fully data-driven approaches, we instead introduce a novel approach LaneCPP that uses a continuous 3D lane detection model leveraging physical prior knowledge about the lane structure and road geometry. While our sophisticated lane model is capable of modeling complex road structures, it also shows robust behavior since physical constraints are incorporated by means of a regularization scheme that can be analytically applied to our parametric representation. Moreover, we incorporate prior knowledge about the road geometry into the 3D feature space by modeling geometry-aware spatial features, guiding the network to learn an internal road surface representation. In our experiments, we show the benefits of our contributions and prove the meaningfulness of using priors to make 3D lane detection more robust. The results show that LaneCPP achieves state-of-the-art performance in terms of F-Score and geometric errors.","sentences":["Monocular 3D lane detection has become a fundamental problem in the context of autonomous driving, which comprises the tasks of finding the road surface and locating lane markings.","One major challenge lies in a flexible but robust line representation capable of modeling complex lane structures, while still avoiding unpredictable behavior.","While previous methods rely on fully data-driven approaches, we instead introduce a novel approach LaneCPP that uses a continuous 3D lane detection model leveraging physical prior knowledge about the lane structure and road geometry.","While our sophisticated lane model is capable of modeling complex road structures, it also shows robust behavior since physical constraints are incorporated by means of a regularization scheme that can be analytically applied to our parametric representation.","Moreover, we incorporate prior knowledge about the road geometry into the 3D feature space by modeling geometry-aware spatial features, guiding the network to learn an internal road surface representation.","In our experiments, we show the benefits of our contributions and prove the meaningfulness of using priors to make 3D lane detection more robust.","The results show that LaneCPP achieves state-of-the-art performance in terms of F-Score and geometric errors."],"url":"http://arxiv.org/abs/2406.08381v1"}
{"created":"2024-06-12 16:30:58","title":"Towards Unsupervised Speech Recognition Without Pronunciation Models","abstract":"Recent advancements in supervised automatic speech recognition (ASR) have achieved remarkable performance, largely due to the growing availability of large transcribed speech corpora. However, most languages lack sufficient paired speech and text data to effectively train these systems. In this article, we tackle the challenge of developing ASR systems without paired speech and text corpora by proposing the removal of reliance on a phoneme lexicon. We explore a new research direction: word-level unsupervised ASR. Using a curated speech corpus containing only high-frequency English words, our system achieves a word error rate of nearly 20% without parallel transcripts or oracle word boundaries. Furthermore, we experimentally demonstrate that an unsupervised speech recognizer can emerge from joint speech-to-speech and text-to-text masked token-infilling. This innovative model surpasses the performance of previous unsupervised ASR models trained with direct distribution matching.","sentences":["Recent advancements in supervised automatic speech recognition (ASR) have achieved remarkable performance, largely due to the growing availability of large transcribed speech corpora.","However, most languages lack sufficient paired speech and text data to effectively train these systems.","In this article, we tackle the challenge of developing ASR systems without paired speech and text corpora by proposing the removal of reliance on a phoneme lexicon.","We explore a new research direction: word-level unsupervised ASR.","Using a curated speech corpus containing only high-frequency English words, our system achieves a word error rate of nearly 20% without parallel transcripts or oracle word boundaries.","Furthermore, we experimentally demonstrate that an unsupervised speech recognizer can emerge from joint speech-to-speech and text-to-text masked token-infilling.","This innovative model surpasses the performance of previous unsupervised ASR models trained with direct distribution matching."],"url":"http://arxiv.org/abs/2406.08380v1"}
{"created":"2024-06-12 16:29:45","title":"Eyes Wide Unshut: Unsupervised Mistake Detection in Egocentric Video by Detecting Unpredictable Gaze","abstract":"In this paper, we address the challenge of unsupervised mistake detection in egocentric video through the analysis of gaze signals, a critical component for advancing user assistance in smart glasses. Traditional supervised methods, reliant on manually labeled mistakes, suffer from domain-dependence and scalability issues. This research introduces an unsupervised method for detecting mistakes in videos of human activities, overcoming the challenges of domain-specific requirements and the necessity for annotated data. By analyzing unusual gaze patterns that signal user disorientation during tasks, we propose a gaze completion model that forecasts eye gaze trajectories from incomplete inputs. The difference between the anticipated and observed gaze paths acts as an indicator for identifying errors. Our method is validated on the EPIC-Tent dataset, showing its superiority compared to current one-class supervised and unsupervised techniques.","sentences":["In this paper, we address the challenge of unsupervised mistake detection in egocentric video through the analysis of gaze signals, a critical component for advancing user assistance in smart glasses.","Traditional supervised methods, reliant on manually labeled mistakes, suffer from domain-dependence and scalability issues.","This research introduces an unsupervised method for detecting mistakes in videos of human activities, overcoming the challenges of domain-specific requirements and the necessity for annotated data.","By analyzing unusual gaze patterns that signal user disorientation during tasks, we propose a gaze completion model that forecasts eye gaze trajectories from incomplete inputs.","The difference between the anticipated and observed gaze paths acts as an indicator for identifying errors.","Our method is validated on the EPIC-Tent dataset, showing its superiority compared to current one-class supervised and unsupervised techniques."],"url":"http://arxiv.org/abs/2406.08379v1"}
{"created":"2024-06-12 16:26:56","title":"DDR: Exploiting Deep Degradation Response as Flexible Image Descriptor","abstract":"Image deep features extracted by pre-trained networks are known to contain rich and informative representations. In this paper, we present Deep Degradation Response (DDR), a method to quantify changes in image deep features under varying degradation conditions. Specifically, our approach facilitates flexible and adaptive degradation, enabling the controlled synthesis of image degradation through text-driven prompts. Extensive evaluations demonstrate the versatility of DDR as an image descriptor, with strong correlations observed with key image attributes such as complexity, colorfulness, sharpness, and overall quality. Moreover, we demonstrate the efficacy of DDR across a spectrum of applications. It excels as a blind image quality assessment metric, outperforming existing methodologies across multiple datasets. Additionally, DDR serves as an effective unsupervised learning objective in image restoration tasks, yielding notable advancements in image deblurring and single-image super-resolution. Our code will be made available.","sentences":["Image deep features extracted by pre-trained networks are known to contain rich and informative representations.","In this paper, we present Deep Degradation Response (DDR), a method to quantify changes in image deep features under varying degradation conditions.","Specifically, our approach facilitates flexible and adaptive degradation, enabling the controlled synthesis of image degradation through text-driven prompts.","Extensive evaluations demonstrate the versatility of DDR as an image descriptor, with strong correlations observed with key image attributes such as complexity, colorfulness, sharpness, and overall quality.","Moreover, we demonstrate the efficacy of DDR across a spectrum of applications.","It excels as a blind image quality assessment metric, outperforming existing methodologies across multiple datasets.","Additionally, DDR serves as an effective unsupervised learning objective in image restoration tasks, yielding notable advancements in image deblurring and single-image super-resolution.","Our code will be made available."],"url":"http://arxiv.org/abs/2406.08377v1"}
{"created":"2024-06-12 16:22:41","title":"2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction","abstract":"Positron Emission Tomography (PET) is an important clinical imaging tool but inevitably introduces radiation hazards to patients and healthcare providers. Reducing the tracer injection dose and eliminating the CT acquisition for attenuation correction can reduce the overall radiation dose, but often results in PET with high noise and bias. Thus, it is desirable to develop 3D methods to translate the non-attenuation-corrected low-dose PET (NAC-LDPET) into attenuation-corrected standard-dose PET (AC-SDPET). Recently, diffusion models have emerged as a new state-of-the-art deep learning method for image-to-image translation, better than traditional CNN-based methods. However, due to the high computation cost and memory burden, it is largely limited to 2D applications. To address these challenges, we developed a novel 2.5D Multi-view Averaging Diffusion Model (MADM) for 3D image-to-image translation with application on NAC-LDPET to AC-SDPET translation. Specifically, MADM employs separate diffusion models for axial, coronal, and sagittal views, whose outputs are averaged in each sampling step to ensure the 3D generation quality from multiple views. To accelerate the 3D sampling process, we also proposed a strategy to use the CNN-based 3D generation as a prior for the diffusion model. Our experimental results on human patient studies suggested that MADM can generate high-quality 3D translation images, outperforming previous CNN-based and Diffusion-based baseline methods.","sentences":["Positron Emission Tomography (PET) is an important clinical imaging tool but inevitably introduces radiation hazards to patients and healthcare providers.","Reducing the tracer injection dose and eliminating the CT acquisition for attenuation correction can reduce the overall radiation dose, but often results in PET with high noise and bias.","Thus, it is desirable to develop 3D methods to translate the non-attenuation-corrected low-dose PET (NAC-LDPET) into attenuation-corrected standard-dose PET (AC-SDPET).","Recently, diffusion models have emerged as a new state-of-the-art deep learning method for image-to-image translation, better than traditional CNN-based methods.","However, due to the high computation cost and memory burden, it is largely limited to 2D applications.","To address these challenges, we developed a novel 2.5D Multi-view Averaging Diffusion Model (MADM) for 3D image-to-image translation with application on NAC-LDPET to AC-SDPET translation.","Specifically, MADM employs separate diffusion models for axial, coronal, and sagittal views, whose outputs are averaged in each sampling step to ensure the 3D generation quality from multiple views.","To accelerate the 3D sampling process, we also proposed a strategy to use the CNN-based 3D generation as a prior for the diffusion model.","Our experimental results on human patient studies suggested that MADM can generate high-quality 3D translation images, outperforming previous CNN-based and Diffusion-based baseline methods."],"url":"http://arxiv.org/abs/2406.08374v1"}
{"created":"2024-06-12 16:21:11","title":"Deep Learning Based Joint Multi-User MISO Power Allocation and Beamforming Design","abstract":"The evolution of fifth generation (5G) wireless communication networks has led to an increased need for wireless resource management solutions that provide higher data rates, wide coverage, low latency, and power efficiency. Yet, many of existing traditional approaches remain non-practical due to computational limitations, and unrealistic presumptions of static network conditions and algorithm initialization dependencies. This creates an important gap between theoretical analysis and real-time processing of algorithms. To bridge this gap, deep learning based techniques offer promising solutions with their representational capabilities for universal function approximation. We propose a novel unsupervised deep learning based joint power allocation and beamforming design for multi-user multiple-input single-output (MU-MISO) system. The objective is to enhance the spectral efficiency by maximizing the sum-rate with the proposed joint design framework, NNBF-P while also offering computationally efficient solution in contrast to conventional approaches. We conduct experiments for diverse settings to compare the performance of NNBF-P with zero-forcing beamforming (ZFBF), minimum mean square error (MMSE) beamforming, and NNBF, which is also our deep learning based beamforming design without joint power allocation scheme. Experiment results demonstrate the superiority of NNBF-P compared to ZFBF, and MMSE while NNBF can have lower performances than MMSE and ZFBF in some experiment settings. It can also demonstrate the effectiveness of joint design framework with respect to NNBF.","sentences":["The evolution of fifth generation (5G) wireless communication networks has led to an increased need for wireless resource management solutions that provide higher data rates, wide coverage, low latency, and power efficiency.","Yet, many of existing traditional approaches remain non-practical due to computational limitations, and unrealistic presumptions of static network conditions and algorithm initialization dependencies.","This creates an important gap between theoretical analysis and real-time processing of algorithms.","To bridge this gap, deep learning based techniques offer promising solutions with their representational capabilities for universal function approximation.","We propose a novel unsupervised deep learning based joint power allocation and beamforming design for multi-user multiple-input single-output (MU-MISO) system.","The objective is to enhance the spectral efficiency by maximizing the sum-rate with the proposed joint design framework, NNBF-P while also offering computationally efficient solution in contrast to conventional approaches.","We conduct experiments for diverse settings to compare the performance of NNBF-P with zero-forcing beamforming (ZFBF), minimum mean square error (MMSE) beamforming, and NNBF, which is also our deep learning based beamforming design without joint power allocation scheme.","Experiment results demonstrate the superiority of NNBF-P compared to ZFBF, and MMSE while NNBF can have lower performances than MMSE and ZFBF in some experiment settings.","It can also demonstrate the effectiveness of joint design framework with respect to NNBF."],"url":"http://arxiv.org/abs/2406.08373v1"}
{"created":"2024-06-12 16:20:58","title":"APSeg: Auto-Prompt Network for Cross-Domain Few-Shot Semantic Segmentatio","abstract":"Few-shot semantic segmentation (FSS) endeavors to segment unseen classes with only a few labeled samples. Current FSS methods are commonly built on the assumption that their training and application scenarios share similar domains, and their performances degrade significantly while applied to a distinct domain. To this end, we propose to leverage the cutting-edge foundation model, the Segment Anything Model (SAM), for generalization enhancement. The SAM however performs unsatisfactorily on domains that are distinct from its training data, which primarily comprise natural scene images, and it does not support automatic segmentation of specific semantics due to its interactive prompting mechanism. In our work, we introduce APSeg, a novel auto-prompt network for cross-domain few-shot semantic segmentation (CD-FSS), which is designed to be auto-prompted for guiding cross-domain segmentation. Specifically, we propose a Dual Prototype Anchor Transformation (DPAT) module that fuses pseudo query prototypes extracted based on cycle-consistency with support prototypes, allowing features to be transformed into a more stable domain-agnostic space. Additionally, a Meta Prompt Generator (MPG) module is introduced to automatically generate prompt embeddings, eliminating the need for manual visual prompts. We build an efficient model which can be applied directly to target domains without fine-tuning. Extensive experiments on four cross-domain datasets show that our model outperforms the state-of-the-art CD-FSS method by 5.24% and 3.10% in average accuracy on 1-shot and 5-shot settings, respectively.","sentences":["Few-shot semantic segmentation (FSS) endeavors to segment unseen classes with only a few labeled samples.","Current FSS methods are commonly built on the assumption that their training and application scenarios share similar domains, and their performances degrade significantly while applied to a distinct domain.","To this end, we propose to leverage the cutting-edge foundation model, the Segment Anything Model (SAM), for generalization enhancement.","The SAM however performs unsatisfactorily on domains that are distinct from its training data, which primarily comprise natural scene images, and it does not support automatic segmentation of specific semantics due to its interactive prompting mechanism.","In our work, we introduce APSeg, a novel auto-prompt network for cross-domain few-shot semantic segmentation (CD-FSS), which is designed to be auto-prompted for guiding cross-domain segmentation.","Specifically, we propose a Dual Prototype Anchor Transformation (DPAT) module that fuses pseudo query prototypes extracted based on cycle-consistency with support prototypes, allowing features to be transformed into a more stable domain-agnostic space.","Additionally, a Meta Prompt Generator (MPG) module is introduced to automatically generate prompt embeddings, eliminating the need for manual visual prompts.","We build an efficient model which can be applied directly to target domains without fine-tuning.","Extensive experiments on four cross-domain datasets show that our model outperforms the state-of-the-art CD-FSS method by 5.24% and 3.10% in average accuracy on 1-shot and 5-shot settings, respectively."],"url":"http://arxiv.org/abs/2406.08372v1"}
{"created":"2024-06-12 16:16:29","title":"Teaching Literature Reviewing for Software Engineering Research","abstract":"The goal of this chapter is to support teachers in holistically introducing graduate students to literature reviews, with a particular focus on secondary research. It provides an overview of the overall literature review process and the different types of literature review before diving into guidelines for selecting and conducting different types of literature review. The chapter also provides recommendations for evaluating the quality of existing literature reviews and concludes with a summary of our learning goals and how the chapter supports teachers in addressing them.","sentences":["The goal of this chapter is to support teachers in holistically introducing graduate students to literature reviews, with a particular focus on secondary research.","It provides an overview of the overall literature review process and the different types of literature review before diving into guidelines for selecting and conducting different types of literature review.","The chapter also provides recommendations for evaluating the quality of existing literature reviews and concludes with a summary of our learning goals and how the chapter supports teachers in addressing them."],"url":"http://arxiv.org/abs/2406.08369v1"}
{"created":"2024-06-12 16:02:28","title":"From a Social Cognitive Perspective: Context-aware Visual Social Relationship Recognition","abstract":"People's social relationships are often manifested through their surroundings, with certain objects or interactions acting as symbols for specific relationships, e.g., wedding rings, roses, hugs, or holding hands. This brings unique challenges to recognizing social relationships, requiring understanding and capturing the essence of these contexts from visual appearances. However, current methods of social relationship understanding rely on the basic classification paradigm of detected persons and objects, which fails to understand the comprehensive context and often overlooks decisive social factors, especially subtle visual cues. To highlight the social-aware context and intricate details, we propose a novel approach that recognizes \\textbf{Con}textual \\textbf{So}cial \\textbf{R}elationships (\\textbf{ConSoR}) from a social cognitive perspective. Specifically, to incorporate social-aware semantics, we build a lightweight adapter upon the frozen CLIP to learn social concepts via our novel multi-modal side adapter tuning mechanism. Further, we construct social-aware descriptive language prompts (e.g., scene, activity, objects, emotions) with social relationships for each image, and then compel ConSoR to concentrate more intensively on the decisive visual social factors via visual-linguistic contrasting. Impressively, ConSoR outperforms previous methods with a 12.2\\% gain on the People-in-Social-Context (PISC) dataset and a 9.8\\% increase on the People-in-Photo-Album (PIPA) benchmark. Furthermore, we observe that ConSoR excels at finding critical visual evidence to reveal social relationships.","sentences":["People's social relationships are often manifested through their surroundings, with certain objects or interactions acting as symbols for specific relationships, e.g., wedding rings, roses, hugs, or holding hands.","This brings unique challenges to recognizing social relationships, requiring understanding and capturing the essence of these contexts from visual appearances.","However, current methods of social relationship understanding rely on the basic classification paradigm of detected persons and objects, which fails to understand the comprehensive context and often overlooks decisive social factors, especially subtle visual cues.","To highlight the social-aware context and intricate details, we propose a novel approach that recognizes \\textbf{Con}textual \\textbf{So}cial \\textbf{R}elationships (\\textbf{ConSoR}) from a social cognitive perspective.","Specifically, to incorporate social-aware semantics, we build a lightweight adapter upon the frozen CLIP to learn social concepts via our novel multi-modal side adapter tuning mechanism.","Further, we construct social-aware descriptive language prompts (e.g., scene, activity, objects, emotions) with social relationships for each image, and then compel ConSoR to concentrate more intensively on the decisive visual social factors via visual-linguistic contrasting.","Impressively, ConSoR outperforms previous methods with a 12.2\\% gain on the People-in-Social-Context (PISC) dataset and a 9.8\\% increase on the People-in-Photo-Album (PIPA) benchmark.","Furthermore, we observe that ConSoR excels at finding critical visual evidence to reveal social relationships."],"url":"http://arxiv.org/abs/2406.08358v1"}
{"created":"2024-06-12 16:02:09","title":"An open dataset of article processing charges from six large scholarly publishers (2019-2023)","abstract":"This paper introduces a dataset of article processing charges (APCs) produced from the price lists of six large scholarly publishers - Elsevier, Frontiers, PLOS, MDPI, Springer Nature and Wiley - between 2019 and 2023. APC price lists were downloaded from publisher websites each year as well as via Wayback Machine snapshots to retrieve fees per journal per year. The dataset includes journal metadata, APC collection method, and annual APC price list information in several currencies (USD, EUR, GBP, CHF, JPY, CAD) for 8,712 unique journals and 36,618 journal-year combinations. The dataset was generated to allow for more precise analysis of APCs and can support library collection development and scientometric analysis estimating APCs paid in gold and hybrid OA journals.","sentences":["This paper introduces a dataset of article processing charges (APCs) produced from the price lists of six large scholarly publishers - Elsevier, Frontiers, PLOS, MDPI, Springer Nature and Wiley - between 2019 and 2023.","APC price lists were downloaded from publisher websites each year as well as via Wayback Machine snapshots to retrieve fees per journal per year.","The dataset includes journal metadata, APC collection method, and annual APC price list information in several currencies (USD, EUR, GBP, CHF, JPY, CAD) for 8,712 unique journals and 36,618 journal-year combinations.","The dataset was generated to allow for more precise analysis of APCs and can support library collection development and scientometric analysis estimating APCs paid in gold and hybrid OA journals."],"url":"http://arxiv.org/abs/2406.08356v1"}
{"created":"2024-06-12 16:00:16","title":"DocSynthv2: A Practical Autoregressive Modeling for Document Generation","abstract":"While the generation of document layouts has been extensively explored, comprehensive document generation encompassing both layout and content presents a more complex challenge. This paper delves into this advanced domain, proposing a novel approach called DocSynthv2 through the development of a simple yet effective autoregressive structured model. Our model, distinct in its integration of both layout and textual cues, marks a step beyond existing layout-generation approaches. By focusing on the relationship between the structural elements and the textual content within documents, we aim to generate cohesive and contextually relevant documents without any reliance on visual components. Through experimental studies on our curated benchmark for the new task, we demonstrate the ability of our model combining layout and textual information in enhancing the generation quality and relevance of documents, opening new pathways for research in document creation and automated design. Our findings emphasize the effectiveness of autoregressive models in handling complex document generation tasks.","sentences":["While the generation of document layouts has been extensively explored, comprehensive document generation encompassing both layout and content presents a more complex challenge.","This paper delves into this advanced domain, proposing a novel approach called DocSynthv2 through the development of a simple yet effective autoregressive structured model.","Our model, distinct in its integration of both layout and textual cues, marks a step beyond existing layout-generation approaches.","By focusing on the relationship between the structural elements and the textual content within documents, we aim to generate cohesive and contextually relevant documents without any reliance on visual components.","Through experimental studies on our curated benchmark for the new task, we demonstrate the ability of our model combining layout and textual information in enhancing the generation quality and relevance of documents, opening new pathways for research in document creation and automated design.","Our findings emphasize the effectiveness of autoregressive models in handling complex document generation tasks."],"url":"http://arxiv.org/abs/2406.08354v1"}
{"created":"2024-06-12 15:55:42","title":"Utilizing Navigation Path to Generate Target Point for Enhanced End-to-End Autonomous Driving Planning","abstract":"In recent years, end-to-end autonomous driving frameworks have been shown to not only enhance perception performance but also improve planning capabilities. However, most previous end-to-end autonomous driving frameworks have primarily focused on enhancing environment perception while neglecting the learning of autonomous vehicle planning intent. Within the end-to-end framework, this paper proposes a method termed NTT, which obtains explicit planning intent through the navigation path. NTT first generates the future target point for the autonomous vehicle based on the navigation path, thereby enhancing planning performance within the end-to-end framework. On one hand, the generation of the target point allows the autonomous vehicle to learn explicit intention from the navigation path, enhancing the practicality of planning. On the other hand, planning trajectory generated based on the target point can adapt more flexibly to environmental changes, thus effectively improving planning safety. We achieved excellent planning performance on the widely used nuScenes dataset and validated the effectiveness of our method through ablation experiments.","sentences":["In recent years, end-to-end autonomous driving frameworks have been shown to not only enhance perception performance but also improve planning capabilities.","However, most previous end-to-end autonomous driving frameworks have primarily focused on enhancing environment perception while neglecting the learning of autonomous vehicle planning intent.","Within the end-to-end framework, this paper proposes a method termed NTT, which obtains explicit planning intent through the navigation path.","NTT first generates the future target point for the autonomous vehicle based on the navigation path, thereby enhancing planning performance within the end-to-end framework.","On one hand, the generation of the target point allows the autonomous vehicle to learn explicit intention from the navigation path, enhancing the practicality of planning.","On the other hand, planning trajectory generated based on the target point can adapt more flexibly to environmental changes, thus effectively improving planning safety.","We achieved excellent planning performance on the widely used nuScenes dataset and validated the effectiveness of our method through ablation experiments."],"url":"http://arxiv.org/abs/2406.08349v1"}
{"created":"2024-06-12 15:55:39","title":"Trajectory optimization of tail-sitter considering speed constraints","abstract":"Tail-sitters combine the advantages of fixed-wing unmanned aerial vehicles (UAVs) and vertical take-off and landing UAVs, and have been widely designed and researched in recent years. With the change in modern UAV application scenarios, it is required that UAVs have fast maneuverable three-dimensional flight capabilities. Due to the highly nonlinear aerodynamics produced by the fuselage and wings of the tail-sitter, how to quickly generate a smooth and executable trajectory is a problem that needs to be solved urgently. We constrain the speed of the tail-sitter, eliminate the differential dynamics constraints in the trajectory generation process of the tail-sitter through differential flatness, and allocate the time variable of the trajectory through the state-of-the-art trajectory generation method named MINCO. Because we discretize the trajectory in time, we convert the speed constraint on the vehicle into a soft constraint, thereby achieving the time-optimal trajectory for the tail-sitter to fly through any given waypoints.","sentences":["Tail-sitters combine the advantages of fixed-wing unmanned aerial vehicles (UAVs) and vertical take-off and landing UAVs, and have been widely designed and researched in recent years.","With the change in modern UAV application scenarios, it is required that UAVs have fast maneuverable three-dimensional flight capabilities.","Due to the highly nonlinear aerodynamics produced by the fuselage and wings of the tail-sitter, how to quickly generate a smooth and executable trajectory is a problem that needs to be solved urgently.","We constrain the speed of the tail-sitter, eliminate the differential dynamics constraints in the trajectory generation process of the tail-sitter through differential flatness, and allocate the time variable of the trajectory through the state-of-the-art trajectory generation method named MINCO.","Because we discretize the trajectory in time, we convert the speed constraint on the vehicle into a soft constraint, thereby achieving the time-optimal trajectory for the tail-sitter to fly through any given waypoints."],"url":"http://arxiv.org/abs/2406.08347v1"}
{"created":"2024-06-12 15:51:39","title":"Blind Image Deblurring using FFT-ReLU with Deep Learning Pipeline Integration","abstract":"Blind image deblurring is the process of deriving a sharp image and a blur kernel from a blurred image. Blurry images are typically modeled as the convolution of a sharp image with a blur kernel, necessitating the estimation of the unknown blur kernel to perform blind image deblurring effectively. Existing approaches primarily focus on domain-specific features of images, such as salient edges, dark channels, and light streaks. These features serve as probabilistic priors to enhance the estimation of the blur kernel. For improved generality, we propose a novel prior (ReLU sparsity prior) that estimates blur kernel effectively across all distributions of images (natural, facial, text, low-light, saturated etc). Our approach demonstrates superior efficiency, with inference times up to three times faster, while maintaining high accuracy in PSNR, SSIM, and error ratio metrics. We also observe noticeable improvement in the performance of the state-of-the-art architectures (in terms of aforementioned metrics) in deep learning based approaches when our method is used as a post-processing unit.","sentences":["Blind image deblurring is the process of deriving a sharp image and a blur kernel from a blurred image.","Blurry images are typically modeled as the convolution of a sharp image with a blur kernel, necessitating the estimation of the unknown blur kernel to perform blind image deblurring effectively.","Existing approaches primarily focus on domain-specific features of images, such as salient edges, dark channels, and light streaks.","These features serve as probabilistic priors to enhance the estimation of the blur kernel.","For improved generality, we propose a novel prior (ReLU sparsity prior) that estimates blur kernel effectively across all distributions of images (natural, facial, text, low-light, saturated etc).","Our approach demonstrates superior efficiency, with inference times up to three times faster, while maintaining high accuracy in PSNR, SSIM, and error ratio metrics.","We also observe noticeable improvement in the performance of the state-of-the-art architectures (in terms of aforementioned metrics) in deep learning based approaches when our method is used as a post-processing unit."],"url":"http://arxiv.org/abs/2406.08344v1"}
{"created":"2024-06-12 15:50:35","title":"Continuous-Time Digital Twin with Analogue Memristive Neural Ordinary Differential Equation Solver","abstract":"Digital twins, the cornerstone of Industry 4.0, replicate real-world entities through computer models, revolutionising fields such as manufacturing management and industrial automation. Recent advances in machine learning provide data-driven methods for developing digital twins using discrete-time data and finite-depth models on digital computers. However, this approach fails to capture the underlying continuous dynamics and struggles with modelling complex system behaviour. Additionally, the architecture of digital computers, with separate storage and processing units, necessitates frequent data transfers and Analogue-Digital (A/D) conversion, thereby significantly increasing both time and energy costs. Here, we introduce a memristive neural ordinary differential equation (ODE) solver for digital twins, which is capable of capturing continuous-time dynamics and facilitates the modelling of complex systems using an infinite-depth model. By integrating storage and computation within analogue memristor arrays, we circumvent the von Neumann bottleneck, thus enhancing both speed and energy efficiency. We experimentally validate our approach by developing a digital twin of the HP memristor, which accurately extrapolates its nonlinear dynamics, achieving a 4.2-fold projected speedup and a 41.4-fold projected decrease in energy consumption compared to state-of-the-art digital hardware, while maintaining an acceptable error margin. Additionally, we demonstrate scalability through experimentally grounded simulations of Lorenz96 dynamics, exhibiting projected performance improvements of 12.6-fold in speed and 189.7-fold in energy efficiency relative to traditional digital approaches. By harnessing the capabilities of fully analogue computing, our breakthrough accelerates the development of digital twins, offering an efficient and rapid solution to meet the demands of Industry 4.0.","sentences":["Digital twins, the cornerstone of Industry 4.0, replicate real-world entities through computer models, revolutionising fields such as manufacturing management and industrial automation.","Recent advances in machine learning provide data-driven methods for developing digital twins using discrete-time data and finite-depth models on digital computers.","However, this approach fails to capture the underlying continuous dynamics and struggles with modelling complex system behaviour.","Additionally, the architecture of digital computers, with separate storage and processing units, necessitates frequent data transfers and Analogue-Digital (A/D) conversion, thereby significantly increasing both time and energy costs.","Here, we introduce a memristive neural ordinary differential equation (ODE) solver for digital twins, which is capable of capturing continuous-time dynamics and facilitates the modelling of complex systems using an infinite-depth model.","By integrating storage and computation within analogue memristor arrays, we circumvent the von Neumann bottleneck, thus enhancing both speed and energy efficiency.","We experimentally validate our approach by developing a digital twin of the HP memristor, which accurately extrapolates its nonlinear dynamics, achieving a 4.2-fold projected speedup and a 41.4-fold projected decrease in energy consumption compared to state-of-the-art digital hardware, while maintaining an acceptable error margin.","Additionally, we demonstrate scalability through experimentally grounded simulations of Lorenz96 dynamics, exhibiting projected performance improvements of 12.6-fold in speed and 189.7-fold in energy efficiency relative to traditional digital approaches.","By harnessing the capabilities of fully analogue computing, our breakthrough accelerates the development of digital twins, offering an efficient and rapid solution to meet the demands of Industry 4.0."],"url":"http://arxiv.org/abs/2406.08343v1"}
{"created":"2024-06-12 15:48:39","title":"Practical, Automated Scenario-based Mobile App Testing","abstract":"The importance of mobile application (app) quality insurance is increasing with the rapid development of the mobile Internet. Automated test generation approaches, as a dominant direction of app quality insurance, follow specific models or strategies, targeting at optimizing the code coverage. Such approaches lead to a huge gap between testing execution and app business logic. Test scripts developed by human testers consider business logic by focusing on testing scenarios. Due to the GUI-intensive feature of mobile apps, human testers always understand app GUI to organize test scripts for scenarios. This inspires us to utilize domain knowledge from app GUI understanding for scenario-based test generation.   In this paper, we propose a novel approach, ScenTest, for scenario-based mobile app testing with event knowledge graph (EKG) via GUI image understanding. ScenTest tries to start automated testing by imitating human practices and integrating domain knowledge into scenario-based mobile app testing, realizing fully automated testing on target testing scenarios for the first time. ScenTest extracts four kinds of entities and five kinds of corresponding relationships from crowdsourced test reports, where the test events and app GUI information are presented, and constructs the EKGs for specific scenarios. Then, ScenTest conducts test generation for specific scenarios on different apps with the guidance of EKG with the combination consideration of app current state and testing context. We conduct an evaluation on ScenTest on different aspects. The results show that the test generation of ScenTest on the basis of EKG is effective, and ScenTest can reveal 80+ distinct real-world bugs in specific scenarios compared with representative baselines.","sentences":["The importance of mobile application (app) quality insurance is increasing with the rapid development of the mobile Internet.","Automated test generation approaches, as a dominant direction of app quality insurance, follow specific models or strategies, targeting at optimizing the code coverage.","Such approaches lead to a huge gap between testing execution and app business logic.","Test scripts developed by human testers consider business logic by focusing on testing scenarios.","Due to the GUI-intensive feature of mobile apps, human testers always understand app GUI to organize test scripts for scenarios.","This inspires us to utilize domain knowledge from app GUI understanding for scenario-based test generation.   ","In this paper, we propose a novel approach, ScenTest, for scenario-based mobile app testing with event knowledge graph (EKG) via GUI image understanding.","ScenTest tries to start automated testing by imitating human practices and integrating domain knowledge into scenario-based mobile app testing, realizing fully automated testing on target testing scenarios for the first time.","ScenTest extracts four kinds of entities and five kinds of corresponding relationships from crowdsourced test reports, where the test events and app GUI information are presented, and constructs the EKGs for specific scenarios.","Then, ScenTest conducts test generation for specific scenarios on different apps with the guidance of EKG with the combination consideration of app current state and testing context.","We conduct an evaluation on ScenTest on different aspects.","The results show that the test generation of ScenTest on the basis of EKG is effective, and ScenTest can reveal 80+ distinct real-world bugs in specific scenarios compared with representative baselines."],"url":"http://arxiv.org/abs/2406.08340v1"}
{"created":"2024-06-12 15:42:52","title":"WMAdapter: Adding WaterMark Control to Latent Diffusion Models","abstract":"Watermarking is crucial for protecting the copyright of AI-generated images. We propose WMAdapter, a diffusion model watermark plugin that takes user-specified watermark information and allows for seamless watermark imprinting during the diffusion generation process. WMAdapter is efficient and robust, with a strong emphasis on high generation quality. To achieve this, we make two key designs: (1) We develop a contextual adapter structure that is lightweight and enables effective knowledge transfer from heavily pretrained post-hoc watermarking models. (2) We introduce an extra finetuning step and design a hybrid finetuning strategy to further improve image quality and eliminate tiny artifacts. Empirical results demonstrate that WMAdapter offers strong flexibility, exceptional image generation quality and competitive watermark robustness.","sentences":["Watermarking is crucial for protecting the copyright of AI-generated images.","We propose WMAdapter, a diffusion model watermark plugin that takes user-specified watermark information and allows for seamless watermark imprinting during the diffusion generation process.","WMAdapter is efficient and robust, with a strong emphasis on high generation quality.","To achieve this, we make two key designs: (1) We develop a contextual adapter structure that is lightweight and enables effective knowledge transfer from heavily pretrained post-hoc watermarking models.","(2) We introduce an extra finetuning step and design a hybrid finetuning strategy to further improve image quality and eliminate tiny artifacts.","Empirical results demonstrate that WMAdapter offers strong flexibility, exceptional image generation quality and competitive watermark robustness."],"url":"http://arxiv.org/abs/2406.08337v1"}
{"created":"2024-06-12 15:42:21","title":"CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal Dysarthric Speech Reconstruction","abstract":"Dysarthric speech reconstruction (DSR) aims to transform dysarthric speech into normal speech. It still suffers from low speaker similarity and poor prosody naturalness. In this paper, we propose a multi-modal DSR model by leveraging neural codec language modeling to improve the reconstruction results, especially for the speaker similarity and prosody naturalness. Our proposed model consists of: (i) a multi-modal content encoder to extract robust phoneme embeddings from dysarthric speech with auxiliary visual inputs; (ii) a speaker codec encoder to extract and normalize the speaker-aware codecs from the dysarthric speech, in order to provide original timbre and normal prosody; (iii) a codec language model based speech decoder to reconstruct the speech based on the extracted phoneme embeddings and normalized codecs. Evaluations on the commonly used UASpeech corpus show that our proposed model can achieve significant improvements in terms of speaker similarity and prosody naturalness.","sentences":["Dysarthric speech reconstruction (DSR) aims to transform dysarthric speech into normal speech.","It still suffers from low speaker similarity and poor prosody naturalness.","In this paper, we propose a multi-modal DSR model by leveraging neural codec language modeling to improve the reconstruction results, especially for the speaker similarity and prosody naturalness.","Our proposed model consists of: (i) a multi-modal content encoder to extract robust phoneme embeddings from dysarthric speech with auxiliary visual inputs; (ii) a speaker codec encoder to extract and normalize the speaker-aware codecs from the dysarthric speech, in order to provide original timbre and normal prosody; (iii) a codec language model based speech decoder to reconstruct the speech based on the extracted phoneme embeddings and normalized codecs.","Evaluations on the commonly used UASpeech corpus show that our proposed model can achieve significant improvements in terms of speaker similarity and prosody naturalness."],"url":"http://arxiv.org/abs/2406.08336v1"}
{"created":"2024-06-12 15:41:06","title":"A Survey of Pipeline Tools for Data Engineering","abstract":"Currently, a variety of pipeline tools are available for use in data engineering. Data scientists can use these tools to resolve data wrangling issues associated with data and accomplish some data engineering tasks from data ingestion through data preparation to utilization as input for machine learning (ML). Some of these tools have essential built-in components or can be combined with other tools to perform desired data engineering operations. While some tools are wholly or partly commercial, several open-source tools are available to perform expert-level data engineering tasks. This survey examines the broad categories and examples of pipeline tools based on their design and data engineering intentions. These categories are Extract Transform Load/Extract Load Transform (ETL/ELT), pipelines for Data Integration, Ingestion, and Transformation, Data Pipeline Orchestration and Workflow Management, and Machine Learning Pipelines. The survey also provides a broad outline of the utilization with examples within these broad groups and finally, a discussion is presented with case studies indicating the usage of pipeline tools for data engineering. The studies present some first-user application experiences with sample data, some complexities of the applied pipeline, and a summary note of approaches to using these tools to prepare data for machine learning.","sentences":["Currently, a variety of pipeline tools are available for use in data engineering.","Data scientists can use these tools to resolve data wrangling issues associated with data and accomplish some data engineering tasks from data ingestion through data preparation to utilization as input for machine learning (ML).","Some of these tools have essential built-in components or can be combined with other tools to perform desired data engineering operations.","While some tools are wholly or partly commercial, several open-source tools are available to perform expert-level data engineering tasks.","This survey examines the broad categories and examples of pipeline tools based on their design and data engineering intentions.","These categories are Extract Transform Load/Extract Load Transform (ETL/ELT), pipelines for Data Integration, Ingestion, and Transformation, Data Pipeline Orchestration and Workflow Management, and Machine Learning Pipelines.","The survey also provides a broad outline of the utilization with examples within these broad groups and finally, a discussion is presented with case studies indicating the usage of pipeline tools for data engineering.","The studies present some first-user application experiences with sample data, some complexities of the applied pipeline, and a summary note of approaches to using these tools to prepare data for machine learning."],"url":"http://arxiv.org/abs/2406.08335v1"}
{"created":"2024-06-12 15:40:06","title":"ProTrain: Efficient LLM Training via Memory-Aware Techniques","abstract":"It is extremely memory-hungry to train Large Language Models (LLM). To solve this problem, existing work exploits the combination of CPU and GPU for the training process, such as ZeRO-Offload. Such a technique largely democratizes billion-scale model training, making it possible to train with few consumer graphics cards. However, based on our observation, existing frameworks often provide coarse-grained memory management and require experienced experts in configuration tuning, leading to suboptimal hardware utilization and performance. This paper proposes ProTrain, a novel training system that intelligently balances memory usage and performance by coordinating memory, computation, and IO. ProTrain achieves adaptive memory management through Chunk-Based Model State Management and Block-Wise Activation Management, guided by a Memory-Aware Runtime Profiler without user intervention. ProTrain does not change the training algorithm and thus does not compromise accuracy. Experiments show that ProTrain improves training throughput by 1.43$\\times$ to 2.71$\\times$ compared to the SOTA training systems.","sentences":["It is extremely memory-hungry to train Large Language Models (LLM).","To solve this problem, existing work exploits the combination of CPU and GPU for the training process, such as ZeRO-Offload.","Such a technique largely democratizes billion-scale model training, making it possible to train with few consumer graphics cards.","However, based on our observation, existing frameworks often provide coarse-grained memory management and require experienced experts in configuration tuning, leading to suboptimal hardware utilization and performance.","This paper proposes ProTrain, a novel training system that intelligently balances memory usage and performance by coordinating memory, computation, and IO.","ProTrain achieves adaptive memory management through Chunk-Based Model State Management and Block-Wise Activation Management, guided by a Memory-Aware Runtime Profiler without user intervention.","ProTrain does not change the training algorithm and thus does not compromise accuracy.","Experiments show that ProTrain improves training throughput by 1.43$\\times$ to 2.71$\\times$ compared to the SOTA training systems."],"url":"http://arxiv.org/abs/2406.08334v1"}
{"created":"2024-06-12 15:39:35","title":"Review of Autonomous Mobile Robots for the Warehouse Environment","abstract":"Autonomous mobile robots (AMRs) have been a rapidly expanding research topic for the past decade. Unlike their counterpart, the automated guided vehicle (AGV), AMRs can make decisions and do not need any previously installed infrastructure to navigate. Recent technological developments in hardware and software have made them more feasible, especially in warehouse environments. Traditionally, most wasted warehouse expenses come from the logistics of moving material from one point to another, and is exhaustive for humans to continuously walk those distances while carrying a load. Here, AMRs can help by working with humans to cut down the time and effort of these repetitive tasks, improving performance and reducing the fatigue of their human collaborators. This literature review covers the recent developments in AMR technology including hardware, robotic control, and system control. This paper also discusses examples of current AMR producers, their robots, and the software that is used to control them. We conclude with future research topics and where we see AMRs developing in the warehouse environment.","sentences":["Autonomous mobile robots (AMRs) have been a rapidly expanding research topic for the past decade.","Unlike their counterpart, the automated guided vehicle (AGV), AMRs can make decisions and do not need any previously installed infrastructure to navigate.","Recent technological developments in hardware and software have made them more feasible, especially in warehouse environments.","Traditionally, most wasted warehouse expenses come from the logistics of moving material from one point to another, and is exhaustive for humans to continuously walk those distances while carrying a load.","Here, AMRs can help by working with humans to cut down the time and effort of these repetitive tasks, improving performance and reducing the fatigue of their human collaborators.","This literature review covers the recent developments in AMR technology including hardware, robotic control, and system control.","This paper also discusses examples of current AMR producers, their robots, and the software that is used to control them.","We conclude with future research topics and where we see AMRs developing in the warehouse environment."],"url":"http://arxiv.org/abs/2406.08333v1"}
{"created":"2024-06-12 15:36:30","title":"UDON: Universal Dynamic Online distillatioN for generic image representations","abstract":"Universal image representations are critical in enabling real-world fine-grained and instance-level recognition applications, where objects and entities from any domain must be identified at large scale. Despite recent advances, existing methods fail to capture important domain-specific knowledge, while also ignoring differences in data distribution across different domains. This leads to a large performance gap between efficient universal solutions and expensive approaches utilising a collection of specialist models, one for each domain. In this work, we make significant strides towards closing this gap, by introducing a new learning technique, dubbed UDON (Universal Dynamic Online DistillatioN). UDON employs multi-teacher distillation, where each teacher is specialized in one domain, to transfer detailed domain-specific knowledge into the student universal embedding. UDON's distillation approach is not only effective, but also very efficient, by sharing most model parameters between the student and all teachers, where all models are jointly trained in an online manner. UDON also comprises a sampling technique which adapts the training process to dynamically allocate batches to domains which are learned slower and require more frequent processing. This boosts significantly the learning of complex domains which are characterised by a large number of classes and long-tail distributions. With comprehensive experiments, we validate each component of UDON, and showcase significant improvements over the state of the art in the recent UnED benchmark. Code: https://github.com/nikosips/UDON .","sentences":["Universal image representations are critical in enabling real-world fine-grained and instance-level recognition applications, where objects and entities from any domain must be identified at large scale.","Despite recent advances, existing methods fail to capture important domain-specific knowledge, while also ignoring differences in data distribution across different domains.","This leads to a large performance gap between efficient universal solutions and expensive approaches utilising a collection of specialist models, one for each domain.","In this work, we make significant strides towards closing this gap, by introducing a new learning technique, dubbed UDON (Universal Dynamic Online DistillatioN).","UDON employs multi-teacher distillation, where each teacher is specialized in one domain, to transfer detailed domain-specific knowledge into the student universal embedding.","UDON's distillation approach is not only effective, but also very efficient, by sharing most model parameters between the student and all teachers, where all models are jointly trained in an online manner.","UDON also comprises a sampling technique which adapts the training process to dynamically allocate batches to domains which are learned slower and require more frequent processing.","This boosts significantly the learning of complex domains which are characterised by a large number of classes and long-tail distributions.","With comprehensive experiments, we validate each component of UDON, and showcase significant improvements over the state of the art in the recent UnED benchmark.","Code: https://github.com/nikosips/UDON ."],"url":"http://arxiv.org/abs/2406.08332v1"}
{"created":"2024-06-12 15:34:28","title":"It's all about PR -- Smart Benchmarking AI Accelerators using Performance Representatives","abstract":"Statistical models are widely used to estimate the performance of commercial off-the-shelf (COTS) AI hardware accelerators. However, training of statistical performance models often requires vast amounts of data, leading to a significant time investment and can be difficult in case of limited hardware availability. To alleviate this problem, we propose a novel performance modeling methodology that significantly reduces the number of training samples while maintaining good accuracy. Our approach leverages knowledge of the target hardware architecture and initial parameter sweeps to identify a set of Performance Representatives (PR) for deep neural network (DNN) layers. These PRs are then used for benchmarking, building a statistical performance model, and making estimations. This targeted approach drastically reduces the number of training samples needed, opposed to random sampling, to achieve a better estimation accuracy. We achieve a Mean Absolute Percentage Error (MAPE) of as low as 0.02% for single-layer estimations and 0.68% for whole DNN estimations with less than 10000 training samples. The results demonstrate the superiority of our method for single-layer estimations compared to models trained with randomly sampled datasets of the same size.","sentences":["Statistical models are widely used to estimate the performance of commercial off-the-shelf (COTS)","AI hardware accelerators.","However, training of statistical performance models often requires vast amounts of data, leading to a significant time investment and can be difficult in case of limited hardware availability.","To alleviate this problem, we propose a novel performance modeling methodology that significantly reduces the number of training samples while maintaining good accuracy.","Our approach leverages knowledge of the target hardware architecture and initial parameter sweeps to identify a set of Performance Representatives (PR) for deep neural network (DNN) layers.","These PRs are then used for benchmarking, building a statistical performance model, and making estimations.","This targeted approach drastically reduces the number of training samples needed, opposed to random sampling, to achieve a better estimation accuracy.","We achieve a Mean Absolute Percentage Error (MAPE) of as low as 0.02% for single-layer estimations and 0.68% for whole DNN estimations with less than 10000 training samples.","The results demonstrate the superiority of our method for single-layer estimations compared to models trained with randomly sampled datasets of the same size."],"url":"http://arxiv.org/abs/2406.08330v1"}
{"created":"2024-06-12 15:33:59","title":"Highly Connected Graph Partitioning: Exact Formulation and Solution Methods","abstract":"Graph partitioning (GP) and vertex connectivity have traditionally been two distinct fields of study. This paper introduces the highly connected graph partitioning (HCGP) problem, which partitions a graph into compact, size balanced, and $Q$-(vertex) connected parts for any $Q\\geq 1$. This problem is valuable in applications that seek cohesion and fault-tolerance within their parts, such as community detection in social networks and resiliency-focused partitioning of power networks. Existing research in this fundamental interconnection primarily focuses on providing theoretical existence guarantees of highly connected partitions for a limited set of dense graphs, and do not include canonical GP considerations such as size balance and compactness. This paper's key contribution is providing a general modeling and algorithmic approach for HCGP, inspired by recent work in the political districting problem, a special case of HCGP with $Q=1$. This approach models $Q$-connectivity constraints as mixed integer programs for any $Q\\geq 1$ and provides an efficient branch-and-cut method to solve HCGP. When solution time is a priority over optimality, this paper provides a heuristic method specifically designed for HCGP with $Q=2$. A computational analysis evaluates these methods using a test bed of instances from various real-world graphs. In this analysis, the branch-and-cut method finds an optimal solution within one hour in $82.8\\%$ of the instances solved. For $Q=2$, small and sparse instances are challenging for the heuristic, whereas large and sparse instances are challenging for the exact method. Furthermore, this study quantifies the computational cost of ensuring higher connectivity using the branch-and-cut approach, compared to a baseline of ensuring $1$-connectivity. Overall, this work serves as an effective tool to partition a graph into resilient and cohesive parts.","sentences":["Graph partitioning (GP) and vertex connectivity have traditionally been two distinct fields of study.","This paper introduces the highly connected graph partitioning (HCGP) problem, which partitions a graph into compact, size balanced, and $Q$-(vertex) connected parts for any $Q\\geq 1$.","This problem is valuable in applications that seek cohesion and fault-tolerance within their parts, such as community detection in social networks and resiliency-focused partitioning of power networks.","Existing research in this fundamental interconnection primarily focuses on providing theoretical existence guarantees of highly connected partitions for a limited set of dense graphs, and do not include canonical GP considerations such as size balance and compactness.","This paper's key contribution is providing a general modeling and algorithmic approach for HCGP, inspired by recent work in the political districting problem, a special case of HCGP with $Q=1$. This approach models $Q$-connectivity constraints as mixed integer programs for any $Q\\geq 1$ and provides an efficient branch-and-cut method to solve HCGP.","When solution time is a priority over optimality, this paper provides a heuristic method specifically designed for HCGP with $Q=2$. A computational analysis evaluates these methods using a test bed of instances from various real-world graphs.","In this analysis, the branch-and-cut method finds an optimal solution within one hour in $82.8\\%$ of the instances solved.","For $Q=2$, small and sparse instances are challenging for the heuristic, whereas large and sparse instances are challenging for the exact method.","Furthermore, this study quantifies the computational cost of ensuring higher connectivity using the branch-and-cut approach, compared to a baseline of ensuring $1$-connectivity.","Overall, this work serves as an effective tool to partition a graph into resilient and cohesive parts."],"url":"http://arxiv.org/abs/2406.08329v1"}
{"created":"2024-06-12 15:24:09","title":"LaMOT: Language-Guided Multi-Object Tracking","abstract":"Vision-Language MOT is a crucial tracking problem and has drawn increasing attention recently. It aims to track objects based on human language commands, replacing the traditional use of templates or pre-set information from training sets in conventional tracking tasks. Despite various efforts, a key challenge lies in the lack of a clear understanding of why language is used for tracking, which hinders further development in this field. In this paper, we address this challenge by introducing Language-Guided MOT, a unified task framework, along with a corresponding large-scale benchmark, termed LaMOT, which encompasses diverse scenarios and language descriptions. Specially, LaMOT comprises 1,660 sequences from 4 different datasets and aims to unify various Vision-Language MOT tasks while providing a standardized evaluation platform. To ensure high-quality annotations, we manually assign appropriate descriptive texts to each target in every video and conduct careful inspection and correction. To the best of our knowledge, LaMOT is the first benchmark dedicated to Language-Guided MOT. Additionally, we propose a simple yet effective tracker, termed LaMOTer. By establishing a unified task framework, providing challenging benchmarks, and offering insights for future algorithm design and evaluation, we expect to contribute to the advancement of research in Vision-Language MOT. We will release the data at https://github.com/Nathan-Li123/LaMOT.","sentences":["Vision-Language MOT is a crucial tracking problem and has drawn increasing attention recently.","It aims to track objects based on human language commands, replacing the traditional use of templates or pre-set information from training sets in conventional tracking tasks.","Despite various efforts, a key challenge lies in the lack of a clear understanding of why language is used for tracking, which hinders further development in this field.","In this paper, we address this challenge by introducing Language-Guided MOT, a unified task framework, along with a corresponding large-scale benchmark, termed LaMOT, which encompasses diverse scenarios and language descriptions.","Specially, LaMOT comprises 1,660 sequences from 4 different datasets and aims to unify various Vision-Language MOT tasks while providing a standardized evaluation platform.","To ensure high-quality annotations, we manually assign appropriate descriptive texts to each target in every video and conduct careful inspection and correction.","To the best of our knowledge, LaMOT is the first benchmark dedicated to Language-Guided MOT.","Additionally, we propose a simple yet effective tracker, termed LaMOTer.","By establishing a unified task framework, providing challenging benchmarks, and offering insights for future algorithm design and evaluation, we expect to contribute to the advancement of research in Vision-Language MOT.","We will release the data at https://github.com/Nathan-Li123/LaMOT."],"url":"http://arxiv.org/abs/2406.08324v1"}
{"created":"2024-06-12 15:23:50","title":"Illustrating the benefits of efficient creation and adaption of behavior models in intelligent Digital Twins over the machine life cycle","abstract":"The concept of the Digital Twin, which in the context of this paper is the virtual representation of a production system or its components, can be used as a \"digital playground\" to master the increasing complexity of these assets. Central subcomponents of the Digital Twin are behavior models that can provide benefits over the entire machine life cycle. However, the creation, adaption and use of behavior models throughout the machine life cycle is very time-consuming, which is why approaches to improve the cost-benefit ratio are needed. Furthermore, there is a lack of specific use cases that illustrate the application and added benefit of behavior models over the machine life cycle, which is why the universal application of behavior models in industry is still lacking compared to research. This paper first presents the fundamentals, challenges and related work on Digital Twins and behavior models in the context of the machine life cycle. Then, concepts for low-effort creation and automatic adaption of Digital Twins are presented, with a focus on behavior models. Finally, the aforementioned gap between research and industry is addressed by demonstrating various realized use cases over the machine life cycle, in which the advantages as well as the application of behavior models in the different life phases are shown.","sentences":["The concept of the Digital Twin, which in the context of this paper is the virtual representation of a production system or its components, can be used as a \"digital playground\" to master the increasing complexity of these assets.","Central subcomponents of the Digital Twin are behavior models that can provide benefits over the entire machine life cycle.","However, the creation, adaption and use of behavior models throughout the machine life cycle is very time-consuming, which is why approaches to improve the cost-benefit ratio are needed.","Furthermore, there is a lack of specific use cases that illustrate the application and added benefit of behavior models over the machine life cycle, which is why the universal application of behavior models in industry is still lacking compared to research.","This paper first presents the fundamentals, challenges and related work on Digital Twins and behavior models in the context of the machine life cycle.","Then, concepts for low-effort creation and automatic adaption of Digital Twins are presented, with a focus on behavior models.","Finally, the aforementioned gap between research and industry is addressed by demonstrating various realized use cases over the machine life cycle, in which the advantages as well as the application of behavior models in the different life phases are shown."],"url":"http://arxiv.org/abs/2406.08323v1"}
{"created":"2024-06-12 15:16:40","title":"Is Programming by Example solved by LLMs?","abstract":"Programming-by-Examples (PBE) aims to generate an algorithm from input-output examples. Such systems are practically and theoretically important: from an end-user perspective, they are deployed to millions of people, and from an AI perspective, PBE corresponds to a very general form of few-shot inductive inference. Given the success of Large Language Models (LLMs) in code-generation tasks, we investigate here the extent to which LLMs can be said to have `solved' PBE. We experiment on classic domains such as lists and strings, and an uncommon graphics programming domain not well represented in typical pretraining data. We find that pretrained models are not effective at PBE, but that they can be fine-tuned for much higher performance, provided the test problems are in-distribution. We analyze empirically what causes these models to succeed and fail, and take steps toward understanding how to achieve better out-of-distribution generalization. Collectively these results suggest that LLMs make strong progress toward solving the typical suite of PBE tasks, potentially increasing the flexibility and applicability of PBE systems, while also identifying ways in which LLMs still fall short.","sentences":["Programming-by-Examples (PBE) aims to generate an algorithm from input-output examples.","Such systems are practically and theoretically important: from an end-user perspective, they are deployed to millions of people, and from an AI perspective, PBE corresponds to a very general form of few-shot inductive inference.","Given the success of Large Language Models (LLMs) in code-generation tasks, we investigate here the extent to which LLMs can be said to have `solved' PBE.","We experiment on classic domains such as lists and strings, and an uncommon graphics programming domain not well represented in typical pretraining data.","We find that pretrained models are not effective at PBE, but that they can be fine-tuned for much higher performance, provided the test problems are in-distribution.","We analyze empirically what causes these models to succeed and fail, and take steps toward understanding how to achieve better out-of-distribution generalization.","Collectively these results suggest that LLMs make strong progress toward solving the typical suite of PBE tasks, potentially increasing the flexibility and applicability of PBE systems, while also identifying ways in which LLMs still fall short."],"url":"http://arxiv.org/abs/2406.08316v1"}
{"created":"2024-06-12 15:16:26","title":"Improving Policy Optimization via $\\varepsilon$-Retrain","abstract":"We present $\\varepsilon$-retrain, an exploration strategy designed to encourage a behavioral preference while optimizing policies with monotonic improvement guarantees. To this end, we introduce an iterative procedure for collecting retrain areas -- parts of the state space where an agent did not follow the behavioral preference. Our method then switches between the typical uniform restart state distribution and the retrain areas using a decaying factor $\\varepsilon$, allowing agents to retrain on situations where they violated the preference. Experiments over hundreds of seeds across locomotion, navigation, and power network tasks show that our method yields agents that exhibit significant performance and sample efficiency improvements. Moreover, we employ formal verification of neural networks to provably quantify the degree to which agents adhere to behavioral preferences.","sentences":["We present $\\varepsilon$-retrain, an exploration strategy designed to encourage a behavioral preference while optimizing policies with monotonic improvement guarantees.","To this end, we introduce an iterative procedure for collecting retrain areas -- parts of the state space where an agent did not follow the behavioral preference.","Our method then switches between the typical uniform restart state distribution and the retrain areas using a decaying factor $\\varepsilon$, allowing agents to retrain on situations where they violated the preference.","Experiments over hundreds of seeds across locomotion, navigation, and power network tasks show that our method yields agents that exhibit significant performance and sample efficiency improvements.","Moreover, we employ formal verification of neural networks to provably quantify the degree to which agents adhere to behavioral preferences."],"url":"http://arxiv.org/abs/2406.08315v1"}
{"created":"2024-06-12 15:12:49","title":"Causality for Tabular Data Synthesis: A High-Order Structure Causal Benchmark Framework","abstract":"Tabular synthesis models remain ineffective at capturing complex dependencies, and the quality of synthetic data is still insufficient for comprehensive downstream tasks, such as prediction under distribution shifts, automated decision-making, and cross-table understanding. A major challenge is the lack of prior knowledge about underlying structures and high-order relationships in tabular data. We argue that a systematic evaluation on high-order structural information for tabular data synthesis is the first step towards solving the problem. In this paper, we introduce high-order structural causal information as natural prior knowledge and provide a benchmark framework for the evaluation of tabular synthesis models. The framework allows us to generate benchmark datasets with a flexible range of data generation processes and to train tabular synthesis models using these datasets for further evaluation. We propose multiple benchmark tasks, high-order metrics, and causal inference tasks as downstream tasks for evaluating the quality of synthetic data generated by the trained models. Our experiments demonstrate to leverage the benchmark framework for evaluating the model capability of capturing high-order structural causal information. Furthermore, our benchmarking results provide an initial assessment of state-of-the-art tabular synthesis models. They have clearly revealed significant gaps between ideal and actual performance and how baseline methods differ. Our benchmark framework is available at URL https://github.com/TURuibo/CauTabBench.","sentences":["Tabular synthesis models remain ineffective at capturing complex dependencies, and the quality of synthetic data is still insufficient for comprehensive downstream tasks, such as prediction under distribution shifts, automated decision-making, and cross-table understanding.","A major challenge is the lack of prior knowledge about underlying structures and high-order relationships in tabular data.","We argue that a systematic evaluation on high-order structural information for tabular data synthesis is the first step towards solving the problem.","In this paper, we introduce high-order structural causal information as natural prior knowledge and provide a benchmark framework for the evaluation of tabular synthesis models.","The framework allows us to generate benchmark datasets with a flexible range of data generation processes and to train tabular synthesis models using these datasets for further evaluation.","We propose multiple benchmark tasks, high-order metrics, and causal inference tasks as downstream tasks for evaluating the quality of synthetic data generated by the trained models.","Our experiments demonstrate to leverage the benchmark framework for evaluating the model capability of capturing high-order structural causal information.","Furthermore, our benchmarking results provide an initial assessment of state-of-the-art tabular synthesis models.","They have clearly revealed significant gaps between ideal and actual performance and how baseline methods differ.","Our benchmark framework is available at URL https://github.com/TURuibo/CauTabBench."],"url":"http://arxiv.org/abs/2406.08311v1"}
{"created":"2024-06-12 15:10:44","title":"GraphFM: A Comprehensive Benchmark for Graph Foundation Model","abstract":"Foundation Models (FMs) serve as a general class for the development of artificial intelligence systems, offering broad potential for generalization across a spectrum of downstream tasks. Despite extensive research into self-supervised learning as the cornerstone of FMs, several outstanding issues persist in Graph Foundation Models that rely on graph self-supervised learning, namely: 1) Homogenization. The extent of generalization capability on downstream tasks remains unclear. 2) Scalability. It is unknown how effectively these models can scale to large datasets. 3) Efficiency. The training time and memory usage of these models require evaluation. 4) Training Stop Criteria. Determining the optimal stopping strategy for pre-training across multiple tasks to maximize performance on downstream tasks. To address these questions, we have constructed a rigorous benchmark that thoroughly analyzes and studies the generalization and scalability of self-supervised Graph Neural Network (GNN) models. Regarding generalization, we have implemented and compared the performance of various self-supervised GNN models, trained to generate node representations, across tasks such as node classification, link prediction, and node clustering. For scalability, we have compared the performance of various models after training using full-batch and mini-batch strategies. Additionally, we have assessed the training efficiency of these models by conducting experiments to test their GPU memory usage and throughput. Through these experiments, we aim to provide insights to motivate future research. The code for this benchmark is publicly available at https://github.com/NYUSHCS/GraphFM.","sentences":["Foundation Models (FMs) serve as a general class for the development of artificial intelligence systems, offering broad potential for generalization across a spectrum of downstream tasks.","Despite extensive research into self-supervised learning as the cornerstone of FMs, several outstanding issues persist in Graph Foundation Models that rely on graph self-supervised learning, namely: 1) Homogenization.","The extent of generalization capability on downstream tasks remains unclear.","2) Scalability.","It is unknown how effectively these models can scale to large datasets.","3) Efficiency.","The training time and memory usage of these models require evaluation.","4) Training Stop Criteria.","Determining the optimal stopping strategy for pre-training across multiple tasks to maximize performance on downstream tasks.","To address these questions, we have constructed a rigorous benchmark that thoroughly analyzes and studies the generalization and scalability of self-supervised Graph Neural Network (GNN) models.","Regarding generalization, we have implemented and compared the performance of various self-supervised GNN models, trained to generate node representations, across tasks such as node classification, link prediction, and node clustering.","For scalability, we have compared the performance of various models after training using full-batch and mini-batch strategies.","Additionally, we have assessed the training efficiency of these models by conducting experiments to test their GPU memory usage and throughput.","Through these experiments, we aim to provide insights to motivate future research.","The code for this benchmark is publicly available at https://github.com/NYUSHCS/GraphFM."],"url":"http://arxiv.org/abs/2406.08310v1"}
{"created":"2024-06-12 15:09:03","title":"FSH: 3D Representation via Fibonacci Spherical Harmonics","abstract":"Spherical harmonics are a favorable technique for 3D representation, employing a frequency-based approach through the spherical harmonic transform (SHT). Typically, SHT is performed using equiangular sampling grids. However, these grids are non-uniform on spherical surfaces and exhibit local anisotropy, a common limitation in existing spherical harmonic decomposition methods. This paper proposes a 3D representation method using Fibonacci Spherical Harmonics (FSH). We introduce a spherical Fibonacci grid (SFG), which is more uniform than equiangular grids for SHT in the frequency domain. Our method employs analytical weights for SHT on SFG, effectively assigning sampling errors to spherical harmonic degrees higher than the recovered band-limited function. This provides a novel solution for spherical harmonic transformation on non-equiangular grids. The key advantages of our FSH method include: 1) With the same number of sampling points, SFG captures more features without bias compared to equiangular grids; 2) The root mean square error of 32-degree spherical harmonic coefficients is reduced by approximately 34.6\\% for SFG compared to equiangular grids; and 3) FSH offers more stable frequency domain representations, especially for rotating functions. FSH enhances the stability of frequency domain representations under rotational transformations. Its application in 3D shape reconstruction and 3D shape classification results in more accurate and robust representations.","sentences":["Spherical harmonics are a favorable technique for 3D representation, employing a frequency-based approach through the spherical harmonic transform (SHT).","Typically, SHT is performed using equiangular sampling grids.","However, these grids are non-uniform on spherical surfaces and exhibit local anisotropy, a common limitation in existing spherical harmonic decomposition methods.","This paper proposes a 3D representation method using Fibonacci Spherical Harmonics (FSH).","We introduce a spherical Fibonacci grid (SFG), which is more uniform than equiangular grids for SHT in the frequency domain.","Our method employs analytical weights for SHT on SFG, effectively assigning sampling errors to spherical harmonic degrees higher than the recovered band-limited function.","This provides a novel solution for spherical harmonic transformation on non-equiangular grids.","The key advantages of our FSH method include: 1) With the same number of sampling points, SFG captures more features without bias compared to equiangular grids; 2) The root mean square error of 32-degree spherical harmonic coefficients is reduced by approximately 34.6\\% for SFG compared to equiangular grids; and 3) FSH offers more stable frequency domain representations, especially for rotating functions.","FSH enhances the stability of frequency domain representations under rotational transformations.","Its application in 3D shape reconstruction and 3D shape classification results in more accurate and robust representations."],"url":"http://arxiv.org/abs/2406.08308v1"}
{"created":"2024-06-12 15:04:50","title":"Large Language Model(LLM) assisted End-to-End Network Health Management based on Multi-Scale Semanticization","abstract":"Network device and system health management is the foundation of modern network operations and maintenance. Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the dynamic heterogeneous networks (DHNs) environment. Moreover, current state-of-the-art distributed anomaly detection methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for DHNs. In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework. The framework first proposes a Multi-Scale Semanticized Anomaly Detection Model (MSADM), incorporating semantic rule trees with an attention mechanism to address the multi-scale anomaly detection problem in DHNs. Secondly, a chain-of-thought-based large language model is embedded in downstream to adaptively analyze the fault detection results and produce an analysis report with detailed fault information and optimization strategies. Experimental results show that the accuracy of our proposed MSADM for heterogeneous network entity anomaly detection is as high as 91.31\\%.","sentences":["Network device and system health management is the foundation of modern network operations and maintenance.","Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the dynamic heterogeneous networks (DHNs) environment.","Moreover, current state-of-the-art distributed anomaly detection methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for DHNs.","In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework.","The framework first proposes a Multi-Scale Semanticized Anomaly Detection Model (MSADM), incorporating semantic rule trees with an attention mechanism to address the multi-scale anomaly detection problem in DHNs.","Secondly, a chain-of-thought-based large language model is embedded in downstream to adaptively analyze the fault detection results and produce an analysis report with detailed fault information and optimization strategies.","Experimental results show that the accuracy of our proposed MSADM for heterogeneous network entity anomaly detection is as high as 91.31\\%."],"url":"http://arxiv.org/abs/2406.08305v1"}
{"created":"2024-06-12 15:00:05","title":"Dynamical evolution of social network polarization and its impact on the propagation of a virus","abstract":"The COVID-19 pandemic that emerged in 2020 has highlighted the complex interplay between vaccine hesitancy and societal polarization. In this study, we analyse the dynamical polarization within a social network as well as the network properties before and after a vaccine was made available. Our results show that as the network evolves from a less structured state to one with more clustered communities. Then using an agent-based modeling approach, we simulate the propagation of a virus in a polarized society by assigning vaccines to pro-vaccine individuals and none to the anti-vaccine individuals. We compare this propagation to the case where the same number of vaccines is distributed homogeneously across the population. In polarized networks, we observe a significantly more widespread diffusion of the virus, highlighting the importance of considering polarization for epidemic forecasting.","sentences":["The COVID-19 pandemic that emerged in 2020 has highlighted the complex interplay between vaccine hesitancy and societal polarization.","In this study, we analyse the dynamical polarization within a social network as well as the network properties before and after a vaccine was made available.","Our results show that as the network evolves from a less structured state to one with more clustered communities.","Then using an agent-based modeling approach, we simulate the propagation of a virus in a polarized society by assigning vaccines to pro-vaccine individuals and none to the anti-vaccine individuals.","We compare this propagation to the case where the same number of vaccines is distributed homogeneously across the population.","In polarized networks, we observe a significantly more widespread diffusion of the virus, highlighting the importance of considering polarization for epidemic forecasting."],"url":"http://arxiv.org/abs/2406.08299v1"}
{"created":"2024-06-12 14:59:12","title":"AdaNCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer","abstract":"Vision Transformers (ViTs) have demonstrated remarkable performance in image classification tasks, particularly when equipped with local information via region attention or convolutions. While such architectures improve the feature aggregation from different granularities, they often fail to contribute to the robustness of the networks. Neural Cellular Automata (NCA) enables the modeling of global cell representations through local interactions, with its training strategies and architecture design conferring strong generalization ability and robustness against noisy inputs. In this paper, we propose Adaptor Neural Cellular Automata (AdaNCA) for Vision Transformer that uses NCA as plug-in-play adaptors between ViT layers, enhancing ViT's performance and robustness against adversarial samples as well as out-of-distribution inputs. To overcome the large computational overhead of standard NCAs, we propose Dynamic Interaction for more efficient interaction learning. Furthermore, we develop an algorithm for identifying the most effective insertion points for AdaNCA based on our analysis of AdaNCA placement and robustness improvement. With less than a 3% increase in parameters, AdaNCA contributes to more than 10% absolute improvement in accuracy under adversarial attacks on the ImageNet1K benchmark. Moreover, we demonstrate with extensive evaluations across 8 robustness benchmarks and 4 ViT architectures that AdaNCA, as a plug-in-play module, consistently improves the robustness of ViTs.","sentences":["Vision Transformers (ViTs) have demonstrated remarkable performance in image classification tasks, particularly when equipped with local information via region attention or convolutions.","While such architectures improve the feature aggregation from different granularities, they often fail to contribute to the robustness of the networks.","Neural Cellular Automata (NCA) enables the modeling of global cell representations through local interactions, with its training strategies and architecture design conferring strong generalization ability and robustness against noisy inputs.","In this paper, we propose Adaptor Neural Cellular Automata (AdaNCA) for Vision Transformer that uses NCA as plug-in-play adaptors between ViT layers, enhancing ViT's performance and robustness against adversarial samples as well as out-of-distribution inputs.","To overcome the large computational overhead of standard NCAs, we propose Dynamic Interaction for more efficient interaction learning.","Furthermore, we develop an algorithm for identifying the most effective insertion points for AdaNCA based on our analysis of AdaNCA placement and robustness improvement.","With less than a 3% increase in parameters, AdaNCA contributes to more than 10% absolute improvement in accuracy under adversarial attacks on the ImageNet1K benchmark.","Moreover, we demonstrate with extensive evaluations across 8 robustness benchmarks and 4 ViT architectures that AdaNCA, as a plug-in-play module, consistently improves the robustness of ViTs."],"url":"http://arxiv.org/abs/2406.08298v1"}
{"created":"2024-06-12 14:57:37","title":"Vessel Re-identification and Activity Detection in Thermal Domain for Maritime Surveillance","abstract":"Maritime surveillance is vital to mitigate illegal activities such as drug smuggling, illegal fishing, and human trafficking. Vision-based maritime surveillance is challenging mainly due to visibility issues at night, which results in failures in re-identifying vessels and detecting suspicious activities. In this paper, we introduce a thermal, vision-based approach for maritime surveillance with object tracking, vessel re-identification, and suspicious activity detection capabilities. For vessel re-identification, we propose a novel viewpoint-independent algorithm which compares features of the sides of the vessel separately (separate side-spaces) leveraging shape information in the absence of color features. We propose techniques to adapt tracking and activity detection algorithms for the thermal domain and train them using a thermal dataset we created. This dataset will be the first publicly available benchmark dataset for thermal maritime surveillance. Our system is capable of re-identifying vessels with an 81.8% Top1 score and identifying suspicious activities with a 72.4\\% frame mAP score; a new benchmark for each task in the thermal domain.","sentences":["Maritime surveillance is vital to mitigate illegal activities such as drug smuggling, illegal fishing, and human trafficking.","Vision-based maritime surveillance is challenging mainly due to visibility issues at night, which results in failures in re-identifying vessels and detecting suspicious activities.","In this paper, we introduce a thermal, vision-based approach for maritime surveillance with object tracking, vessel re-identification, and suspicious activity detection capabilities.","For vessel re-identification, we propose a novel viewpoint-independent algorithm which compares features of the sides of the vessel separately (separate side-spaces) leveraging shape information in the absence of color features.","We propose techniques to adapt tracking and activity detection algorithms for the thermal domain and train them using a thermal dataset we created.","This dataset will be the first publicly available benchmark dataset for thermal maritime surveillance.","Our system is capable of re-identifying vessels with an 81.8% Top1 score and identifying suspicious activities with a 72.4\\% frame mAP score; a new benchmark for each task in the thermal domain."],"url":"http://arxiv.org/abs/2406.08294v1"}
{"created":"2024-06-12 14:56:56","title":"Outdoor Scene Extrapolation with Hierarchical Generative Cellular Automata","abstract":"We aim to generate fine-grained 3D geometry from large-scale sparse LiDAR scans, abundantly captured by autonomous vehicles (AV). Contrary to prior work on AV scene completion, we aim to extrapolate fine geometry from unlabeled and beyond spatial limits of LiDAR scans, taking a step towards generating realistic, high-resolution simulation-ready 3D street environments. We propose hierarchical Generative Cellular Automata (hGCA), a spatially scalable conditional 3D generative model, which grows geometry recursively with local kernels following, in a coarse-to-fine manner, equipped with a light-weight planner to induce global consistency. Experiments on synthetic scenes show that hGCA generates plausible scene geometry with higher fidelity and completeness compared to state-of-the-art baselines. Our model generalizes strongly from sim-to-real, qualitatively outperforming baselines on the Waymo-open dataset. We also show anecdotal evidence of the ability to create novel objects from real-world geometric cues even when trained on limited synthetic content. More results and details can be found on https://research.nvidia.com/labs/toronto-ai/hGCA/.","sentences":["We aim to generate fine-grained 3D geometry from large-scale sparse LiDAR scans, abundantly captured by autonomous vehicles (AV).","Contrary to prior work on AV scene completion, we aim to extrapolate fine geometry from unlabeled and beyond spatial limits of LiDAR scans, taking a step towards generating realistic, high-resolution simulation-ready 3D street environments.","We propose hierarchical Generative Cellular Automata (hGCA), a spatially scalable conditional 3D generative model, which grows geometry recursively with local kernels following, in a coarse-to-fine manner, equipped with a light-weight planner to induce global consistency.","Experiments on synthetic scenes show that hGCA generates plausible scene geometry with higher fidelity and completeness compared to state-of-the-art baselines.","Our model generalizes strongly from sim-to-real, qualitatively outperforming baselines on the Waymo-open dataset.","We also show anecdotal evidence of the ability to create novel objects from real-world geometric cues even when trained on limited synthetic content.","More results and details can be found on https://research.nvidia.com/labs/toronto-ai/hGCA/."],"url":"http://arxiv.org/abs/2406.08292v1"}
{"created":"2024-06-12 14:56:28","title":"Unlabeled Compressed Sensing from Multiple Measurement Vectors","abstract":"This paper introduces an algorithmic solution to a broader class of unlabeled sensing problems with multiple measurement vectors (MMV). The goal is to recover an unknown structured signal matrix, $\\mathbf{X}$, from its noisy linear observation matrix, $\\mathbf{Y}$, whose rows are further randomly shuffled by an unknown permutation matrix $\\mathbf{U}$. A new Bayes-optimal unlabeled compressed sensing (UCS) recovery algorithm is developed from the bilinear approximate message passing (Bi-VAMP) framework using non-separable and coupled priors on the rows and columns of the permutation matrix $\\mathbf{U}$. In particular, standard unlabeled sensing is a special case of the proposed framework, and UCS further generalizes it by neither assuming a partially shuffled signal matrix $\\mathbf{X}$ nor a small-sized permutation matrix $\\mathbf{U}$. For the sake of theoretical performance prediction, we also conduct a state evolution (SE) analysis of the proposed algorithm and show its consistency with the asymptotic empirical mean-squared error (MSE). Numerical results demonstrate the effectiveness of the proposed UCS algorithm and its advantage over state-of-the-art baseline approaches in various applications. We also numerically examine the phase transition diagrams of UCS, thereby characterizing the detectability region as a function of the signal-to-noise ratio (SNR).","sentences":["This paper introduces an algorithmic solution to a broader class of unlabeled sensing problems with multiple measurement vectors (MMV).","The goal is to recover an unknown structured signal matrix, $\\mathbf{X}$, from its noisy linear observation matrix, $\\mathbf{Y}$, whose rows are further randomly shuffled by an unknown permutation matrix $\\mathbf{U}$. A new Bayes-optimal unlabeled compressed sensing (UCS) recovery algorithm is developed from the bilinear approximate message passing (Bi-VAMP) framework using non-separable and coupled priors on the rows and columns of the permutation matrix $\\mathbf{U}$. In particular, standard unlabeled sensing is a special case of the proposed framework, and UCS further generalizes it by neither assuming a partially shuffled signal matrix $\\mathbf{X}$ nor a small-sized permutation matrix $\\mathbf{U}$. For the sake of theoretical performance prediction, we also conduct a state evolution (SE) analysis of the proposed algorithm and show its consistency with the asymptotic empirical mean-squared error (MSE).","Numerical results demonstrate the effectiveness of the proposed UCS algorithm and its advantage over state-of-the-art baseline approaches in various applications.","We also numerically examine the phase transition diagrams of UCS, thereby characterizing the detectability region as a function of the signal-to-noise ratio (SNR)."],"url":"http://arxiv.org/abs/2406.08290v1"}
{"created":"2024-06-12 14:53:30","title":"Decoupling the Class Label and the Target Concept in Machine Unlearning","abstract":"Machine unlearning as an emerging research topic for data regulations, aims to adjust a trained model to approximate a retrained one that excludes a portion of training data. Previous studies showed that class-wise unlearning is successful in forgetting the knowledge of a target class, through gradient ascent on the forgetting data or fine-tuning with the remaining data. However, while these methods are useful, they are insufficient as the class label and the target concept are often considered to coincide. In this work, we decouple them by considering the label domain mismatch and investigate three problems beyond the conventional all matched forgetting, e.g., target mismatch, model mismatch, and data mismatch forgetting. We systematically analyze the new challenges in restrictively forgetting the target concept and also reveal crucial forgetting dynamics in the representation level to realize these tasks. Based on that, we propose a general framework, namely, TARget-aware Forgetting (TARF). It enables the additional tasks to actively forget the target concept while maintaining the rest part, by simultaneously conducting annealed gradient ascent on the forgetting data and selected gradient descent on the hard-to-affect remaining data. Empirically, various experiments under the newly introduced settings are conducted to demonstrate the effectiveness of our TARF.","sentences":["Machine unlearning as an emerging research topic for data regulations, aims to adjust a trained model to approximate a retrained one that excludes a portion of training data.","Previous studies showed that class-wise unlearning is successful in forgetting the knowledge of a target class, through gradient ascent on the forgetting data or fine-tuning with the remaining data.","However, while these methods are useful, they are insufficient as the class label and the target concept are often considered to coincide.","In this work, we decouple them by considering the label domain mismatch and investigate three problems beyond the conventional all matched forgetting, e.g., target mismatch, model mismatch, and data mismatch forgetting.","We systematically analyze the new challenges in restrictively forgetting the target concept and also reveal crucial forgetting dynamics in the representation level to realize these tasks.","Based on that, we propose a general framework, namely, TARget-aware Forgetting (TARF).","It enables the additional tasks to actively forget the target concept while maintaining the rest part, by simultaneously conducting annealed gradient ascent on the forgetting data and selected gradient descent on the hard-to-affect remaining data.","Empirically, various experiments under the newly introduced settings are conducted to demonstrate the effectiveness of our TARF."],"url":"http://arxiv.org/abs/2406.08288v1"}
{"created":"2024-06-12 14:53:23","title":"Pre-Training Identification of Graph Winning Tickets in Adaptive Spatial-Temporal Graph Neural Networks","abstract":"In this paper, we present a novel method to significantly enhance the computational efficiency of Adaptive Spatial-Temporal Graph Neural Networks (ASTGNNs) by introducing the concept of the Graph Winning Ticket (GWT), derived from the Lottery Ticket Hypothesis (LTH). By adopting a pre-determined star topology as a GWT prior to training, we balance edge reduction with efficient information propagation, reducing computational demands while maintaining high model performance. Both the time and memory computational complexity of generating adaptive spatial-temporal graphs is significantly reduced from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$. Our approach streamlines the ASTGNN deployment by eliminating the need for exhaustive training, pruning, and retraining cycles, and demonstrates empirically across various datasets that it is possible to achieve comparable performance to full models with substantially lower computational costs. Specifically, our approach enables training ASTGNNs on the largest scale spatial-temporal dataset using a single A6000 equipped with 48 GB of memory, overcoming the out-of-memory issue encountered during original training and even achieving state-of-the-art performance. {Furthermore, we delve into the effectiveness of the GWT from the perspective of spectral graph theory, providing substantial theoretical support.} This advancement not only proves the existence of efficient sub-networks within ASTGNNs but also broadens the applicability of the LTH in resource-constrained settings, marking a significant step forward in the field of graph neural networks. Code is available at https://anonymous.4open.science/r/paper-1430.","sentences":["In this paper, we present a novel method to significantly enhance the computational efficiency of Adaptive Spatial-Temporal Graph Neural Networks (ASTGNNs) by introducing the concept of the Graph Winning Ticket (GWT), derived from the Lottery Ticket Hypothesis (LTH).","By adopting a pre-determined star topology as a GWT prior to training, we balance edge reduction with efficient information propagation, reducing computational demands while maintaining high model performance.","Both the time and memory computational complexity of generating adaptive spatial-temporal graphs is significantly reduced from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$. Our approach streamlines the ASTGNN deployment by eliminating the need for exhaustive training, pruning, and retraining cycles, and demonstrates empirically across various datasets that it is possible to achieve comparable performance to full models with substantially lower computational costs.","Specifically, our approach enables training ASTGNNs on the largest scale spatial-temporal dataset using a single A6000 equipped with 48 GB of memory, overcoming the out-of-memory issue encountered during original training and even achieving state-of-the-art performance.","{Furthermore, we delve into the effectiveness of the GWT from the perspective of spectral graph theory, providing substantial theoretical support.}","This advancement not only proves the existence of efficient sub-networks within ASTGNNs but also broadens the applicability of the LTH in resource-constrained settings, marking a significant step forward in the field of graph neural networks.","Code is available at https://anonymous.4open.science/r/paper-1430."],"url":"http://arxiv.org/abs/2406.08287v1"}
